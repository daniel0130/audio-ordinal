<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>? ? ? ? ? ? ?</title>


<window.seed>
<script>
window.seed = 0;  // Default seed
</script>
</window.seed>

<style>
body, html {
    height: 100%;
    margin: 0;
    display: flex;
    align-items: center;
    justify-content: center;
    background-color: #000000;
    position: relative;
    transform: scale(0.7);
}

body {
    margin: 0;
    padding: 0;
    width: 100%;
    height: 100%;
    overflow: hidden;
    display: flex;
    justify-content: center;
    align-items: center;
}

#canvas-container {
    width: 50vmin;
    height: 50vmin;
    display: flex;
    justify-content: center;
    align-items: center;
    background-color: white;
    position: relative;
    z-index: 10; /* Ensure the canvas has a higher z-index than the mixer */
}

canvas#cv {
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    z-index: 9999; /* Keep it above other content but below text elements */
    pointer-events: none;
}

.text-element, .play-text {
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    text-align: center;
    z-index: 10001;
    opacity: 1;
    transition: opacity 5s ease-in-out;
}

.play-text {
    font-size: 125px;
    font-style: bold;
    font-weight: 700;
    color: #ff00bf;
    z-index: 10001;
    opacity: 1;
    transition: opacity 30s ease-in-out;
}

.sqyzy {
    font-family: Arial, bold, sans-serif;
    font-size: 96px;
    font-weight: 500;
    color: #000000;
}

.freedom {
    font-size: 125px;
    font-weight: 700;
    font-style: bold;
}

.melophonic {
    font-family: "Trebuchet MS", bold, sans-serif;
    font-size: 65px;
    color: #000;
}

.fade-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: #000;
    z-index: 10000;
    opacity: 1;
    transition: opacity 10s ease-in-out;
}

#continue-button, #reset-button {
    position: fixed;
    right: 10px;
    padding: 10px 20px;
    font-size: 18px;
    font-weight: bold;
    color: white;
    border: none;
    cursor: pointer;
    z-index: 10002;
    transition: background-color 0.3s;
}

#continue-button {
    top: 60px;
    background-color: #ff00bf;
}

#reset-button {
    top: 10px;
    background-color: #2200ff;
}

#continue-button:hover {
    background-color: #ff33c9;
}

#seed-display {
    position: fixed;
    bottom: 10px;
    left: 50%;
    transform: translateX(-50%);
    background-color: rgba(255, 255, 255, 0.8);
    padding: 10px 20px;
    border-radius: 8px;
    font-size: 20px;
    color: #000;
    opacity: 0; /* Initially hidden */
    transition: opacity 2s ease-in-out;
    z-index: 10002;
}
/* Mixer Overlay Styles */
#mixer-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 35vw;  /* Limit mixer to 35% of the viewport width */
    height: 70vh; /* Limit mixer to 70% of the viewport height */
    background: rgba(0, 0, 0, 0.8);
    display: none; /* Initially hidden */
    z-index: 12999; /* Higher than canvas, lower than buttons */
}

/* Mixer Container Styles */
.mixer-container {
    position: relative; /* Keep it relative to the mixer overlay */
    width: 100%;
    height: 100%;
    padding: 20px;
    background-color: #1e1e1e;
    border: 2px solid #444;
    border-radius: 10px;
    overflow-y: auto;
}

.channel-group {
    display: flex;
    justify-content: space-around;
    flex-wrap: wrap;
    gap: 10px;
}

.channel {
    display: flex;
    flex-direction: column;
    align-items: center;
    width: 60px;
    padding: 10px;
    background-color: #333;
    border: 1px solid #555;
    border-radius: 5px;
}

.channel-label {
    display: flex;
    flex-direction: column;
    align-items: center;
    margin-bottom: 10px;
    font-size: 14px;
    text-align: center;
    line-height: 1.2;
}

.channel-label .ch {
    font-weight: bold;
}

.channel-label .number {
    margin-top: 2px;
}

.fader-container {
    position: relative;
    height: 200px;
    width: 30px;
}

.fader {
    -webkit-appearance: none;
    appearance: none;
    width: 200px;
    height: 30px;
    background: transparent;
    transform: rotate(-90deg);
    position: absolute;
    top: 85px;
    left: -85px;
}

.fader::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 20px;
    height: 20px;
    background: #ff5722;
    cursor: pointer;
    border-radius: 50%;
    border: 2px solid #fff;
}

.fader::-moz-range-thumb {
    width: 20px;
    height: 20px;
    background: #ff5722;
    cursor: pointer;
    border-radius: 50%;
    border: 2px solid #fff;
}

.fader::-webkit-slider-runnable-track {
    width: 100%;
    height: 6px;
    background: #555;
    border-radius: 3px;
}

.fader::-moz-range-track {
    width: 100%;
    height: 6px;
    background: #555;
    border-radius: 3px;
}

.volume-level {
    margin-top: 10px;
    font-size: 12px;
    text-align: center;
}

/* Responsive Design */
@media (max-width: 1200px) {
    .channel {
        width: 50px;
    }

    .fader-container {
        height: 150px;
        width: 25px;
    }

    .fader {
        width: 150px;
        left: -65px;
        top: 60px;
    }

    .volume-level {
        font-size: 10px;
    }

    .channel-label {
        font-size: 12px;
    }
}

@media (max-width: 768px) {
    .channel-group {
        justify-content: center;
    }

    .channel {
        width: 40px;
    }

    .fader-container {
        height: 120px;
        width: 20px;
    }

    .fader {
        width: 120px;
        left: -50px;
        top: 40px;
    }

    .volume-level {
        font-size: 8px;
    }

    .channel-label {
        font-size: 10px;
    }
}

@media (max-width: 480px) {
    .channel {
        width: 35px;
    }

    .fader-container {
        height: 100px;
        width: 18px;
    }

    .fader {
        width: 100px;
        left: -40px;
        top: 30px;
    }

    .volume-level {
        font-size: 7px;
    }

    .channel-label {
        font-size: 9px;
    }
}

</style>

<htmlElements>
<!-- Continue button to resume code execution -->
<!-- <button id="reset-button">Reset</button> -->
<button id="continue-button">Continue</button>
<!-- Div to Display Seed -->
<div id="seed-display">Seed: 0</div>

<!-- Mixer Overlay -->
<div id="mixer-overlay">
  <div class="mixer-container">
      <div class="channel-group" id="group1">
          <!-- Channels 1-16 -->
      </div>
      <div class="channel-group" id="group2">
          <!-- Channels 17-32 -->
      </div>
  </div>
</div>

</htmlElements>

<script id="song-and-sound-inputs">
    // Init function, which contains the main application logic
    const init = () => {
        log('Init function called. Preparing to process song data URLs...');

        const songDataUrls = [
            "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH
            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE
            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA
            "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP
            "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress
            "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY
            "/content/3359ce42359274ddbd2184d9f75a38b7e59b1d5f24512959e29c377fc8ca604ai0", // MintyFresh Vibes
            "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE
            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240
            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch
            "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60
        ];

        log(`Found ${songDataUrls.length} song data URLs to process.`);

        // Modify the first URL using seeded random
        const seed = window.seed; // Assuming the seed has been generated earlier in the process
        songDataUrls[0] += `?v=${Math.floor(seededRandom(seed) * 1000)}`;

        log(`First song URL has been modified using seeded random. New URL: ${songDataUrls[0]}`);

        if (songDataUrls.length) {
            log('Beginning processing of songDataUrls...');
            processSerializedData(songDataUrls, VOLUME_CONTROLS, SPEED_CONTROLS);
        } else {
            console.warn('songDataUrls array is empty. No data to process.');
        }

        log('Init function execution complete.');
    };
</script>

<constants-and-variables>
<script id="constants-and-variables">
const VOLUME_CONTROLS = [
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // TRUTH
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // On-Chain in the Membrane
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHEESE
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // KORA
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHOPPIN' IT UP
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // MLK I HAVE A DREAM
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // ModernProgress
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // HUMANITY
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // MintyFresh Vibes
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // ON DAY ONE
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Rhythm and Bass 240
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Crazy Ass Bitch (Channel 12 muted)
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Rhythm and Bass 60 
];




SPEED_CONTROLS=[[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,.5,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],scheduleMultiplierOnOff=[1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0];let seedSet=!1,arraysInitialized=!1,audioElements=[];function applyScheduleMultiplier(e,l){try{e.channelPlaybackSpeed=e.channelPlaybackSpeed.map(((e,c)=>c<l.length&&l[c]?1.1*e:e)),console.log("Schedule multiplier applied successfully.")}catch(e){console.error("Error in applyScheduleMultiplier:",e)}}
</script>
</constants-and-variables>


<helperFunctions>
<script id="helper-functions">
const applyScheduleMultiplier=(e,t,n)=>{for(const[o,r]of Object.entries(e.projectSequences))for(const[e,s]of Object.entries(r)){const r=s?.source;if(!r||"string"!=typeof r)continue;const i=parseInt(r.replace("data",""),10)-1;if(isNaN(i)||i<0)console.warn(`Invalid song index for ${e} in sequence ${o}`);else if(1===t[i]){if(!n.some((e=>e.source===r&&e.index===s.globalIndex)))continue;const t=Array.isArray(s.steps)?s.steps.filter((e=>"number"==typeof e)):[];if(!t.length){console.log(`No valid steps data for channel ${e} in sequence ${o}. Skipping.`);continue}console.log(`Before multiplier: Channel ${e}, Song ${r}, Steps:`,t),s.steps=redistributeSteps(t,"half"),console.log(`After multiplier: Channel ${e}, Song ${r}, New Steps:`,s.steps)}}},redistributeSteps=(e,t)=>{const n={half:2,quarter:4}[t];if(!n)throw new Error("Unsupported multiplier type");return e.filter(((e,t)=>t%n==0))},generateRandomSeed=()=>Math.floor(1e16*Math.random()),log=e=>console.log(`[${(new Date).toISOString()}] ${e}`);
</script>
</helperFunctions>

<seedMgmt>
<script id="seed-management">
function generateRandomSeed(){return Math.floor(1e16*Math.random())}function log(e){console.log(`[${(new Date).toISOString()}] ${e}`)}async function setSeed(){return log("Starting seed generation..."),0===window.seed?(window.seed=generateRandomSeed(),log(`New seed generated: ${window.seed}`)):log(`Using existing seed: ${window.seed}`),seedSet=!0,window.seed}
</script>
</seedMgmt>


<initArraysAndLogs>
<script id="initArraysAndLogs">
async function initializeMultiplierArrays(){return log("Multiplier arrays initialized."),arraysInitialized=!0,!0}
const pauseBeforeContinue=()=>new Promise((e=>{const o=document.getElementById("continue-button");if(!o)return console.error("Continue button not found."),void e();o.style.display="block",log("Pausing before continuing..."),log(`AudioContext state: ${audioCtx.state}`),log(`Current seed: ${window.seed}`),log(`Multiplier arrays initialized: ${arraysInitialized}`),log(`Is Ready to Play: ${isReadyToPlay}`),log(`Current step: ${currentStep}`),log(`Bar count: ${barCount}`),log(`Current sequence: ${currentSequence}`),activeSources.length?(log("Active audio sources:"),activeSources.forEach(((e,o)=>console.log(`Source ${o}:`,e)))):log("No active audio sources at this moment."),o.addEventListener("click",(()=>{o.style.display="none",log("Continue button clicked. Resuming execution."),e()}),{once:!0})}));
</script>
</initArraysAndLogs>

<script id="main-initialization">
    // Main initialization function
    const initApp = async () => {
        await setSeed();
        await initializeMultiplierArrays();
        await pauseBeforeContinue();
        init(); // Call the main app logic here after the Continue button is pressed
    };

    // Execute the initialization function
    initApp();
</script>

<!-- Script 5: Audio Control Functions -->
<script id="audio-control-functions">
async function safeSuspendAudioContext(){log(`[safeSuspendAudioContext] AudioContext state: ${audioCtx.state}`),"running"===audioCtx.state?(log("Suspending AudioContext..."),await audioCtx.suspend(),log(`AudioContext suspended. State: ${audioCtx.state}`)):"suspended"===audioCtx.state?log("AudioContext is already suspended."):console.warn("AudioContext is closed, cannot suspend.")}async function stopPlayback(){Object.keys(activeSources).forEach((e=>{activeSources[e].forEach((({source:e,gainNode:t})=>{t.gain.cancelScheduledValues(audioCtx.currentTime),t.gain.setValueAtTime(t.gain.value,audioCtx.currentTime),t.gain.linearRampToValueAtTime(0,audioCtx.currentTime+fadeDuration),e.stop(audioCtx.currentTime+fadeDuration),e.disconnect(),t.disconnect()})),activeSources[e]=[]})),setTimeout((async()=>{"closed"!==audioCtx.state&&await safeSuspendAudioContext(),resetPlaybackState()}),50)}
</script>
</init>

<audioContext>
<script id="audio-context-manager">
!function(){if(!window.AudioContextManager){class t{constructor(){return t.instance||(window.audioCtx=null,log("AudioContextManager initialized with no AudioContext."),t.instance=this),t.instance}initCtx(){window.audioCtx&&"closed"!==window.audioCtx.state||(window.audioCtx=new(window.AudioContext||window.webkitAudioContext),window.audioCtx.onstatechange=()=>log(`AudioContext state change. New state: ${window.audioCtx.state}`),log(`AudioContext created. State: ${window.audioCtx.state}`))}getAudioContext(){return window.audioCtx||this.initCtx(),window.audioCtx}async resume(){this.initCtx();const t=window.audioCtx.state;"suspended"===t?(log("Resuming AudioContext..."),await window.audioCtx.resume(),log(`AudioContext resumed. State: ${window.audioCtx.state}`)):"running"===t?log("AudioContext already running."):"closed"===t&&(log("Resetting closed AudioContext..."),await this.resetCtx())}async suspend(){const t=window.audioCtx?.state;log(`Attempting to suspend AudioContext. Current state: ${t}`),"running"===t?(await window.audioCtx.suspend(),log(`AudioContext suspended. State: ${window.audioCtx.state}`)):"suspended"===t?log("AudioContext already suspended."):console.warn("Cannot suspend AudioContext.")}async resetCtx(){log(`Current AudioContext state: ${window.audioCtx?.state}`),window.audioCtx&&"closed"!==window.audioCtx.state&&(await window.audioCtx.close(),log("AudioContext closed.")),this.initCtx(),log(`AudioContext reset. State: ${window.audioCtx.state}`),"suspended"===window.audioCtx.state&&(log("Resuming new AudioContext..."),await window.audioCtx.resume(),log(`AudioContext resumed. State: ${window.audioCtx.state}`))}async resetApp(){log("Resetting application."),window.seed+=1,log(`New seed: ${window.seed}`),await this.resetCtx(),window.audioElements=[],window.activeSources=[],window.arraysInitialized=!1,window.isReadyToPlay=!1,log("Application reset complete."),await initApp()}}window.AudioContextManager=new t}}();
</script>

</audioContext>

</seedAndInitialise>

<globalDefinitions>
<script>
window.enableVisualizerScripts = false; // Set to true to enable, false to disable

let globalVolumeMultiplier=1,globalJsonData=null,bpm=0;const sourceChannelMap=new Map;let globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},activeSources=[],globalGainNodes=new Map,globalAudioBuffers=[],globalReversedAudioBuffers={},isReversePlay=!1;const gainNodes={},audioCtx=window.AudioContextManager.getAudioContext();let preprocessedSequences={},isReadyToPlay=!1,currentStep=0,beatCount=0,barCount=0,currentSequence=0,playbackTimeoutId=null,nextNoteTime=0,totalSequences=0;const fadeDuration=.01,defaultVolume=1;let isToggleInProgress=!1,isPlaying=!1;const AudionalPlayerMessages=new BroadcastChannel("channel_playback");
</script>
</globalDefinitions>

<audioDataProcessing>
<script>
const fetchAndProcessAudioData=async e=>{await Promise.all(e.map(((e,r)=>processAudioUrl(e,r+1)))),createReversedBuffers()},getOrCreateGainNode=e=>{if(!gainNodes[e]){const r=audioCtx.createGain();r.connect(audioCtx.destination),gainNodes[e]=r}return gainNodes[e]},processAudioUrl=async(e,r)=>{const a=`Channel ${r}`;try{const r=await fetch(e);if(!r.ok)throw new Error(`Fetch failed: ${e}, Status: ${r.status}`);const o=r.headers.get("Content-Type"),t=await fetchAndDecodeAudio(r,o);if(t){const e=getOrCreateGainNode(a);e.gain.value=parseVolumeLevel(globalVolumeLevels[a])*globalVolumeMultiplier,globalAudioBuffers.push({buffer:t,gainNode:e,channel:a})}else console.error(`Decoding failed for ${a}: ${e}`)}catch(e){console.error(`Error processing ${a}:`,e)}},setGlobalVolumeMultiplier=e=>{globalVolumeMultiplier=Math.max(0,e),globalAudioBuffers.forEach((({gainNode:e,channel:r})=>{e.gain.value=parseVolumeLevel(globalVolumeLevels[r])*globalVolumeMultiplier}))},fetchAndDecodeAudio=async(e,r)=>{try{if(/audio\/(wav|mpeg|mp4)|video\/mp4/.test(r)){const r=await e.arrayBuffer();return audioCtx.decodeAudioData(r)}const a=await e.text();let o=null;if(/application\/json/.test(r)?o=JSON.parse(a).audioData:/text\/html/.test(r)&&(o=extractBase64FromHTML(a)),o){const e=base64ToArrayBuffer(o.split(",")[1]);return audioCtx.decodeAudioData(e)}if(/audio\//.test(r)){const r=await e.arrayBuffer();return audioCtx.decodeAudioData(r)}}catch(e){console.error("[fetchAndDecodeAudio] Decoding error:",e)}return null},createReversedBuffers=()=>{const e=new Set;Object.values(globalJsonData.projectSequences).forEach((r=>Object.entries(r).forEach((([r,a])=>{if(a.steps.some((e=>e.reverse))){const a=`Channel ${parseInt(r.slice(2))+1}`;e.add(a)}})))),globalAudioBuffers.forEach((({buffer:r,channel:a})=>{e.has(a)&&(globalReversedAudioBuffers[a]=reverseBuffer(r))}))},reverseBuffer=e=>{const r=audioCtx.createBuffer(e.numberOfChannels,e.length,e.sampleRate);for(let a=0;a<e.numberOfChannels;a++){const o=e.getChannelData(a),t=r.getChannelData(a);for(let e=0;e<o.length;e++)t[e]=o[o.length-e-1]}return r},base64ToArrayBuffer=e=>{try{const r=atob(e),a=new Uint8Array(r.length);for(let e=0;e<r.length;e++)a[e]=r.charCodeAt(e);return a.buffer}catch(e){return console.error("[base64ToArrayBuffer] Conversion error:",e),null}},extractBase64FromHTML=e=>{try{const r=(new DOMParser).parseFromString(e,"text/html").querySelector("audio[data-audionalSampleName] source")?.getAttribute("src");if(/^data:audio\/(wav|mp3|mp4);base64,/.test(r?.toLowerCase())||/audio\//.test(r?.toLowerCase()))return r;console.error("[extractBase64FromHTML] Invalid audio source format.")}catch(e){console.error("[extractBase64FromHTML] Parsing error:",e)}return null};console.log("Audio processing script loaded.");
</script>
</audioDataProcessing>

<jsonLoadingAndPlayback>
<script>
const loadJsonFromUrl=async e=>{try{const s=await fetch(e);if(!s.ok)throw new Error(`HTTP error: ${s.status}`);globalJsonData=await s.json();const t={channelsWithUrls:0,sequencesCount:0,activeStepsPerSequence:{},activeChannelsPerSequence:{},types:{}};analyzeJsonStructure(globalJsonData,t);const n=prepareForPlayback(globalJsonData,t);await fetchAndProcessAudioData(n.channelURLs),preprocessAndSchedulePlayback(n)}catch(e){console.error("Failed to load JSON:",e)}},analyzeJsonStructure=(e,s)=>{e.projectSequences&&"object"==typeof e.projectSequences&&Object.entries(e.projectSequences).forEach((([e,t])=>{s.activeStepsPerSequence[e]=0,s.activeChannelsPerSequence[e]=[],Object.entries(t).forEach((([t,n])=>{const r=`Channel ${parseInt(t.slice(2))+1}`;s.activeStepsPerSequence[e]+=n.steps.length,s.activeChannelsPerSequence[e].push(r)}))})),Object.entries(e).forEach((([e,t])=>{if("projectSequences"!==e){const e=Array.isArray(t)?"array":typeof t;s.types[e]=(s.types[e]||0)+1,"object"!==e&&"array"!==e||analyzeJsonStructure(t,s)}}))},findAndSetEndSequence=e=>{if(e?.sequences){let s=null;for(const[t,n]of Object.entries(e.sequences)){const t=Object.values(n.normalSteps).every((e=>!e.length));if(t&&s){e.endSequence=s;break}t||(s=n)}!e.endSequence&&s&&(e.endSequence=s)}},prepareForPlayback=(e,s)=>{const{channelURLs:t,trimSettings:n=[],channelVolume:r=[],channelPlaybackSpeed:c=[],projectSequences:a,projectName:o,projectBPM:l,currentSequence:p}=e;bpm=l,totalSequences=p,globalTrimTimes={},globalVolumeLevels={},globalPlaybackSpeeds={},t.forEach(((e,s)=>{const t=`Channel ${s+1}`,a=n[s]||{};globalTrimTimes[t]={startTrim:+(a.startSliderValue||0)/100,endTrim:+(a.endSliderValue||100)/100},globalVolumeLevels[t]=+parseVolumeLevel(r[s]||1).toFixed(3),globalPlaybackSpeeds[t]=+Math.min(Math.max(c[s]||1,.1),100).toFixed(3)}));const i=Object.entries(a).reduce(((e,[s,t])=>{const n={},r={};return Object.entries(t).forEach((([e,s])=>{const t=`Channel ${parseInt(e.slice(2))+1}`;n[t]=[],r[t]=[],s.steps.forEach((e=>{const s="object"==typeof e?e.index:e;e.reverse?r[t].push(s):n[t].push(s)}))})),e[s]={normalSteps:n,reverseSteps:r},e}),{}),u={projectName:o,bpm:l,channels:t.length,channelURLs:t,trimTimes:globalTrimTimes,stats:s,sequences:i};return findAndSetEndSequence(u),u},preprocessAndSchedulePlayback=e=>{if(!e?.sequences)return console.error("Playback data missing.");bpm=e.bpm,preprocessedSequences=Object.fromEntries(Object.entries(e.sequences).map((([e,s])=>[e,{normalSteps:processSteps(s.normalSteps),reverseSteps:processSteps(s.reverseSteps)}]))),isReadyToPlay=Object.values(preprocessedSequences).some((e=>Object.keys(e.normalSteps).length||Object.keys(e.reverseSteps).length))},processSteps=e=>Object.fromEntries(Object.entries(e).filter((([e,s])=>s.length)).map((([e,s])=>[e,s.map((e=>({step:e,timing:+(e*(60/bpm)).toFixed(3)})))])));
</script>
</jsonLoadingAndPlayback>

<dataProcessingUtilities>
<script>
const hashString=e=>{const r=parseInt(e.split("i")[1],10);return(e.slice(r)+e.slice(0,r)).split("").reduce(((e,r)=>(31*e+r.charCodeAt(0))%Number.MAX_SAFE_INTEGER),0)%14e8},seededRandom=e=>{const r=1e4*Math.sin(e);return r-Math.floor(r)},setPlaybackStatus=e=>{window.playbackStarted=e},keyMap={0:"projectName",1:"artistName",2:"projectBPM",3:"currentSequence",4:"channelURLs",5:"channelVolume",6:"channelPlaybackSpeed",7:"trimSettings",8:"projectChannelNames",9:"startSliderValue",10:"endSliderValue",11:"totalSampleDuration",12:"start",13:"end",14:"projectSequences",15:"steps"},reverseKeyMap=Object.fromEntries(Object.entries(keyMap).map((([e,r])=>[r,+e]))),channelMap=Array.from({length:26},((e,r)=>String.fromCharCode(65+r))),reverseChannelMap=Object.fromEntries(channelMap.map(((e,r)=>[e,r]))),decompressSteps=e=>e.flatMap((e=>{if("number"==typeof e)return e;if(e&&"object"==typeof e&&"r"in e){const[r,t]=e.r;return Array.from({length:t-r+1},((e,t)=>r+t))}return"string"==typeof e&&e.endsWith("r")?{index:parseInt(e.slice(0,-1),10),reverse:!0}:[]})),deserialize=e=>{const r=e=>Array.isArray(e)?e.map((e=>"object"==typeof e?r(e):e)):e&&"object"==typeof e?Object.entries(e).reduce(((e,[t,n])=>{const a=keyMap[t]||t;return e[a]="projectSequences"===a?Object.entries(n).reduce(((e,[r,t])=>(e[`${r.replace(/^s/,"Sequence")}`]=Object.entries(t).reduce(((e,[r,t])=>{var n;return e[`ch${reverseChannelMap[r]}`]={steps:(n=t[reverseKeyMap.steps]||[],n.flatMap((e=>{if("number"==typeof e)return e;if(e&&"object"==typeof e&&"r"in e){const[r,t]=e.r;return Array.from({length:t-r+1},((e,t)=>r+t))}return"string"==typeof e&&e.endsWith("r")?{index:parseInt(e.slice(0,-1),10),reverse:!0}:[]})))},e}),{}),e)),{}):r(n),e}),{}):e;return r(e)};initializePlayback();const seedValue=hashString("4482324585393f1523e8c28a02605c0b1c95d2779510921da0f131a5e6da5843i0");console.log(`Seed value: ${seedValue}`),console.log("ProcessingUtilities initialized."),window.onload=()=>{console.log("window.onload triggered.")};
</script>
</dataProcessingUtilities>

<dataLoadingAndDeserialisation>
<script>
const loadPako=async()=>{try{const e=await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0"),r=await e.text(),t=(new DOMParser).parseFromString(r,"text/html").querySelector("script")?.textContent;if(!t?.includes("pako"))throw new Error("Pako library not found in the fetched content.");const a=document.createElement("script");a.textContent=t,document.head.appendChild(a),console.log("Pako library loaded successfully.")}catch(e){throw console.error("Error occurred during Pako loading:",e),e}},fetchAndDeserialize=async e=>{try{const r=await fetch(e);if(!r.ok)throw new Error(`Network response was not ok for URL: ${e}`);const t=await r.arrayBuffer(),a=pako.inflate(new Uint8Array(t)),o=new TextDecoder("utf-8").decode(a);return deserialize(JSON.parse(o))}catch(e){throw console.error("Error in fetchAndDeserialize:",e),e}},fetchAndProcessData=async e=>{try{const r=(await Promise.all(e.map((async e=>{try{const r=await fetchAndDeserialize(e);if(!r?.projectSequences)throw new Error(`Invalid data at URL ${e}`);return r}catch{return console.error(`Error processing URL: ${e}`),null}})))).filter(Boolean);if(!r.length)throw new Error("No valid data was processed.");return r}catch(e){throw console.error("Error in fetchAndProcessData:",e),e}},selectBPM=e=>{const r=[80,100,120,140,160,180,240];return r[Math.floor(seededRandom(e)*r.length)]},processSerializedDataPart1=async(e,r,t)=>{try{await loadPako();const a=await fetchAndProcessData(e),o=selectBPM(window.seed);window.processedData={deserializedData:a,selectedBPM:o,VOLUME_CONTROLS:r,SPEED_CONTROLS:t,songDataUrls:e},console.log("Data loading and deserialization complete."),document.dispatchEvent(new CustomEvent("dataLoadingComplete"))}catch(e){console.error("Error in processSerializedDataPart1:",e)}};window.processSerializedData=processSerializedDataPart1,console.log("DataLoadingAndDeserializationScript initialized.");
</script>
</dataLoadingAndDeserialisation>


<localDataProcessing>
<script>
const shuffleArray = (e, a) => {
    for (let n = e.length - 1; n > 0; n--) {
        const t = Math.floor(seededRandom(a++) * (n + 1));
        [e[n], e[t]] = [e[t], e[n]];
    }
    return e;
};

const adjustChannelData = (e, a, n, t, l) => {
    const s = n / e.projectBPM;
    e.channelPlaybackSpeed = e.channelPlaybackSpeed.map((e, n) => {
        let t = e * s * (l[a]?.[n] || 1);
        return Math.max(isNaN(t) ? 0.1 : t, 0.1);
    });
    const o = t[a] || [], c = o[0] || 1;
    e.channelVolume = e.channelVolume.map((e, a) => e * c * (o[a + 1] || 1));
};

// Global variable to store audio channels and their gain nodes
window.audioChannels = [];

// Function to initialize 24 gain nodes and map them to the first 24 channels
const createAndAssignGainNodes = (audioContext, channels) => {
    const gainNodes = [];
    for (let i = 0; i < 24; i++) {
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 0.5; // Set the default gain value to 0.5
        gainNodes.push(gainNode);

        // If there is a corresponding channel, connect it to the gain node
        if (channels[i]) {
            channels[i].gainNode = gainNode;
            channels[i].audioContext = audioContext;
            // Add the channel and its gainNode to the global audioChannels array
            window.audioChannels.push({ channel: channels[i], gainNode });
            console.log(`Channel ${i} assigned to GainNode with default value 0.5`);
        }
    }

    // Return the created gain nodes
    return gainNodes;
};

const assembleProcessedSong = (e, a) => {
    const n = e.flatMap((e, a) =>
        e.channelURLs.map((n, t) => ({
            url: n,
            volume: e.channelVolume[t],
            speed: e.channelPlaybackSpeed[t],
            trim: e.trimSettings[t],
            source: `data${a + 1}`,
            index: t
        }))
    );
    const t = shuffleArray(n, window.seed).slice(0, 28);
    t.forEach((e, a) => {
        e.globalIndex = a;
    });

    const l = [t.slice(0, 20), t.slice(20, 24), t.slice(24, 28)];
    const s = { ...e[0], projectBPM: a, channelURLs: t.map(e => e.url), channelVolume: t.map(e => e.volume), channelPlaybackSpeed: t.map(e => e.speed), trimSettings: t.map(e => e.trim), projectSequences: {} };
    const o = e.reduce((e, a, n) => (e[`data${n + 1}`] = a, e), {});
    let c = [], r = 0;
    const i = [];

    // Initialize Web Audio API
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();

    // Assign each channel to a gain node
    const gainNodes = createAndAssignGainNodes(audioContext, t);

    for (const a in e[0].projectSequences) {
        s.projectSequences[a] = {};
        const e = parseInt(a.replace(/\D/g, ""), 10);
        e <= 1 ? c = l[0] : e <= 3 ? c = [...l[0], ...l[1]] : e <= 11 && (c = [...l[0], ...l[1], ...l[2]]);
        c.length > r && i.push({ sequenceNumber: e, channelsAdded: c.length - r, totalChannels: c.length }), r = c.length;
        c.forEach((e, n) => {
            const t = (o[e.source]?.projectSequences[a] || {})[`ch${e.index}`] || { steps: [] };
            s.projectSequences[a][`ch${n}`] = { ...t, steps: Array.isArray(t.steps) ? t.steps : [], globalIndex: e.globalIndex };
        });
    }

    s.channelAdditionLog = i;

    // Connect channels to the destination (if necessary)
    gainNodes.forEach(gainNode => gainNode.connect(audioContext.destination));

    return s;
};

const processSerializedDataPart2 = async () => {
    try {
        const { deserializedData: e, selectedBPM: a, VOLUME_CONTROLS: n, SPEED_CONTROLS: t } = window.processedData;
        e.forEach((e, l) => adjustChannelData(e, l, a, n, t));
        const l = assembleProcessedSong(e, a);

        // If there is a function to apply schedule multiplier, call it
        if (typeof applyScheduleMultiplier === 'function') {
            applyScheduleMultiplier(l, window.scheduleMultiplierOnOff);
        } else {
            console.warn("applyScheduleMultiplier is not defined.");
        }

        window.globalJsonData = l;
        window.jsonDataUrl = URL.createObjectURL(new Blob([JSON.stringify(l)], { type: "application/json" }));
        document.dispatchEvent(new CustomEvent("dataProcessingComplete"));
        console.log("Local data processing complete.");
    } catch (e) {
        console.error("Error in processSerializedDataPart2:", e);
    }
};

// Event listener to start processing after data is loaded
document.addEventListener("dataLoadingComplete", processSerializedDataPart2);

console.log("LocalDataProcessingScript initialized and awaiting data.");
</script>
</localDataProcessing>



<audioMixer>
  <script>
       
        // Listen for messages from the mixer
        window.addEventListener('message', (event) => {
            if (event.data.type === 'requestInitialVolumes') {
                sendInitialVolumes();
            } else if (event.data.type === 'volumeChange') {
                const { channel, volume } = event.data;
                handleMixerVolumeChange(channel, volume);
            }
        });

        // Function to toggle the mixer visibility
        function toggleMixer() {
            const mixerIframe = document.getElementById('mixer-iframe');
            const mixerOverlay = document.getElementById('mixer-overlay');
            const isVisible = mixerIframe.style.display === 'block';

            if (isVisible) {
                mixerIframe.style.display = 'none';
                mixerOverlay.style.display = 'none';
            } else {
                mixerIframe.style.display = 'block';
                mixerOverlay.style.display = 'block';
            }
        }

        // Listen for 'M' key press to toggle mixer
        document.addEventListener('keydown', (e) => {
            if (e.key === 'm' || e.key === 'M') {
                toggleMixer();
            }
        });


        // Initialize: If you want to send initial volumes on load
        // Uncomment the line below if necessary
        // sendInitialVolumes();

        // Example: Update volume when VOLUME_CONTROLS changes elsewhere in your sequencer
        // Ensure that any function that modifies VOLUME_CONTROLS also sends updates to the mixer
        function updateMixerVolume(channel, volume) {
            const mixerIframe = document.getElementById('mixer-iframe');
            mixerIframe.contentWindow.postMessage({
                type: 'updateVolume',
                channel: channel,
                volume: volume
            }, '*');
        }

        // Example: Modify the 'handleMixerVolumeChange' to call 'updateMixerVolume' if necessary
        // This depends on how your sequencer manages audio nodes
    </script>
  </audioMixer>

<playback>
<script>
function startPlaybackLoop(){globalJsonData&&(bpm=globalJsonData.projectBPM)}async function initializePlayback(){await resumeAudioContext(),startPlaybackLoop(),startWorker()}async function stopPlayback(){for(const a in activeSources)activeSources[a].forEach((({source:a,gainNode:i})=>{const e=audioCtx.currentTime;i.gain.cancelScheduledValues(e),i.gain.setValueAtTime(i.gain.value,e),i.gain.linearRampToValueAtTime(0,e+fadeDuration),a.stop(e+fadeDuration),a.disconnect(),i.disconnect()})),activeSources[a]=[];setTimeout((async()=>{await audioCtx.suspend(),resetPlaybackState()}),50)}async function togglePlayback(){if(!isToggleInProgress){isToggleInProgress=!0;try{isPlaying?await stopPlayback():await initializePlayback(),isPlaying=!isPlaying}catch(a){console.error("Error during playback toggle:",a)}finally{isToggleInProgress=!1}}}
</script>
</playback>

<audioBuffering>
<script>
function clampVolume(e){return Math.max(0,Math.min(e,3))}function parseVolumeLevel(e){const t="number"==typeof e?e:parseFloat(e);return clampVolume(isNaN(t)?defaultVolume:t)}function calculateReversedTrimTimes(e){return{startTrim:1-e.endTrim,endTrim:1-e.startTrim}}async function resumeAudioContext(){try{await audioCtx.resume(),console.log("AudioContext resumed:",audioCtx.state)}catch(e){console.error("Failed to resume AudioContext:",e)}}async function ensureAudioContextState(){"running"!==audioCtx.state&&await resumeAudioContext(),console.log("AudioContext state:",audioCtx.state)}function resetPlaybackState(){currentSequence=0,currentStep=0,isReversePlay=!1,nextNoteTime=0}function normalizeBuffer(e,t=.9){if(!(e instanceof AudioBuffer))return console.error("Invalid buffer provided to normalizeBuffer."),e;const o=e.numberOfChannels;let a=0;for(let t=0;t<o;t++){const o=e.getChannelData(t);for(let e=0;e<o.length;e++){const t=Math.abs(o[e]);t>a&&(a=t)}}const r=t/a;if(1!==r)for(let t=0;t<o;t++){const o=e.getChannelData(t);for(let e=0;e<o.length;e++)o[e]*=r}return e}async function loadAndNormalizeAudio(e){try{const t=await fetch(e);if(!t.ok)throw new Error(`Network response was not ok for ${e}: ${t.statusText}`);const o=await t.arrayBuffer();return normalizeBuffer(await audioCtx.decodeAudioData(o))}catch(t){throw console.error(`Error loading or decoding audio from ${e}:`,t),t}}async function waitForAudioContext(){if("running"!==audioCtx.state)return new Promise(((e,t)=>{const o=()=>{"running"===audioCtx.state?(audioCtx.removeEventListener("statechange",o),e()):"closed"===audioCtx.state&&(audioCtx.removeEventListener("statechange",o),t(new Error("AudioContext was closed.")))};audioCtx.addEventListener("statechange",o)}))}function playBuffer(e,{startTrim:t,endTrim:o},a,r){if(!e)return void console.error("Invalid audio buffer provided.");if(!(e instanceof AudioBuffer))return void console.error("Provided buffer is not an instance of AudioBuffer.");t=Math.max(0,Math.min(t,1)),o=Math.max(t,Math.min(o,1));const n=normalizeBuffer(e),i=t*n.duration,u=(o-t)*n.duration,c=audioCtx.createBufferSource();c.buffer=n,c.playbackRate.value=globalPlaybackSpeeds[a]||1;const s=audioCtx.createGain(),d=parseVolumeLevel(globalVolumeLevels[a]||defaultVolume)*globalVolumeMultiplier,l=audioCtx.currentTime;s.gain.cancelScheduledValues(l),s.gain.setValueAtTime(0,l),s.gain.linearRampToValueAtTime(d,l+fadeDuration),c.connect(s),s.connect(audioCtx.destination),c.start(r,i,u),activeSources[a]=activeSources[a]||[],activeSources[a].push({source:c,gainNode:s}),c.onended=()=>{activeSources[a]=activeSources[a].filter((e=>e.source!==c))}}const audioBuffers={};async function loadMultipleAudio(e){const t=e.map((async(e,t)=>{try{const o=await loadAndNormalizeAudio(e);audioBuffers[t]=o}catch(e){console.error(`Failed to load audio at index ${t}:`,e)}}));await Promise.all(t)}(async()=>{try{await waitForAudioContext();playBuffer(await loadAndNormalizeAudio(audioUrl),{startTrim:0,endTrim:1},0,audioCtx.currentTime)}catch(e){console.error("Failed to load and play audio:",e)}})();
</script>
</audioBuffering>

<eventListeners>
<script>
    // Function to toggle the mixer visibility on one side of the screen
    function toggleMixer() {
        const mixerOverlay = document.getElementById('mixer-overlay');
        const isVisible = mixerOverlay.style.display === 'block';

        if (isVisible) {
            mixerOverlay.style.right = '-50%';  // Slide mixer out
            setTimeout(() => {
                mixerOverlay.style.display = 'none';  // Hide mixer after sliding out
            }, 300);  // Adjust timing to match CSS transition
        } else {
            mixerOverlay.style.display = 'block';  // Make mixer visible
            setTimeout(() => {
                mixerOverlay.style.right = '0';  // Slide mixer in from the right
            }, 10);  // Slight delay to allow the transition to apply
        }
    }

    // Listen for 'M' key press to toggle mixer
    document.addEventListener('keydown', (e) => {
        if (e.key === 'm' || e.key === 'M') {
            toggleMixer();
        }
    });

    // Ensure that clicking outside the mixer closes it
    const mixerOverlay = document.getElementById('mixer-overlay');
    mixerOverlay.addEventListener('click', (e) => {
        if (e.target === mixerOverlay) {
            toggleMixer();
        }
    });

    // Stop propagation of clicks inside the mixer container
    const mixerContainer = document.querySelector('.mixer-container');
    mixerContainer.addEventListener('click', (e) => {
        e.stopPropagation();
    });

    // Existing event listeners
    document.addEventListener("click", async () => {
        if (typeof window.ensureAudioContextState === "function") {
            try {
                await window.ensureAudioContextState();
                await togglePlayback();
                document.dispatchEvent(new CustomEvent("playbackStarted"));
            } catch (e) {
                console.error("[eventListeners] Error during playback toggle:", e);
            }
        } else {
            console.error("[eventListeners] ensureAudioContextState is not defined or not a function");
        }
    });

    document.addEventListener("playbackStarted", () => {
        log("Playback started. Displaying seed.");
        const seedDisplay = document.getElementById("seed-display");
        if (seedDisplay) {
            seedDisplay.textContent = `Seed: ${window.seed}`;
            seedDisplay.style.opacity = "1";
            setTimeout(() => {
                seedDisplay.style.opacity = "0";
            }, 10000);
        }
        window.psTime = Date.now();
        setPlaybackStatus(true);
        if (typeof displayPlayText === "function") {
            displayPlayText();
        }
    });

    document.addEventListener("playbackStopped", () => setPlaybackStatus(false));

    document.addEventListener("dataLoadingComplete", () => {
        console.log("Received dataLoadingComplete event. Starting local data processing.");
        processSerializedDataPart2();
    });

    window.addEventListener("load", async () => {
        log("Window load event triggered. Starting app initialization.");
        try {
            await initApp();
            log("initApp function execution complete.");
        } catch (e) {
            console.error("[eventListeners] Error during app initialization:", e);
        }
    });

    document.addEventListener("sequenceUpdated", ({ detail: { currentSequence, currentStep } }) => {
        // Handle sequence updates
    });
</script>
</eventListeners>

<resetVisualState>
<script>
function resetVisualState(){"undefined"!=typeof cci2&&"undefined"!=typeof initialCCI2&&(cci2=initialCCI2),isChannel11Active=!1,isPlaybackActive=!1,activeChannelIndex=null,activeArrayIndex={},renderingState={},"function"==typeof immediateVisualUpdate&&immediateVisualUpdate()}function resetAllStates(){resetPlaybackState(),resetVisualState()}
</script>
</resetVisualState>

<notifyVisualiser>
<script>
    function notifyVisualizer(channelIndex, step) {
        const message = { action: "activeStep", channelIndex, step };
        AudionalPlayerMessages.postMessage(message);
        document.dispatchEvent(new CustomEvent("internalAudioPlayback", { detail: message }));
    }
</script>
</notifyVisualiser>

<prcoessSteps>
<script>
function dispatchSequenceEvent(e,t){document.dispatchEvent(new CustomEvent(e,{detail:t}))}function playSequenceStep(e){if(!isReadyToPlay||!Object.keys(preprocessedSequences).length)return void console.error("Sequence data is not ready or empty.");const t=Object.keys(preprocessedSequences);currentSequence%=t.length;const n=t[currentSequence],o=preprocessedSequences[n];if(0===currentStep&&(console.log(`[${(new Date).toISOString()}] Now playing sequence ${currentSequence}`),globalJsonData&&globalJsonData.channelAdditionLog)){const e=globalJsonData.channelAdditionLog.find((e=>e.sequenceNumber===currentSequence));if(e){const{channelsAdded:t,totalChannels:n}=e;console.log(`Added ${t} channel(s) at sequence ${currentSequence} (total ${n} channels).`)}}o&&Object.keys(o).length&&(playSteps(o.normalSteps,e),playSteps(o.reverseSteps,e,!0)),incrementStepAndSequence(t.length)}function playSteps(e,t,n=!1){if(e&&"object"==typeof e)for(const[o,r]of Object.entries(e))if(Array.isArray(r)){const e=r.find((e=>e.step===currentStep));e&&playChannelStep(o,e,t,n)}else console.error(`[playSteps] Expected steps to be an array for channel "${o}", but got:`,r);else console.error("[playSteps] Invalid steps data:",e)}function playChannelStep(e,t,n,o){const r=globalAudioBuffers.find((t=>t.channel===e)),c=globalTrimTimes[e];if(r?.buffer&&c){const s=o?globalReversedAudioBuffers[e]:r.buffer,u=o?calculateReversedTrimTimes(c):c;playBuffer(s,u,e,n),notifyVisualizer(parseInt(e.slice(8))-1,t.step)}else console.error(`No audio buffer or trim times found for ${e}`)}function scheduleNotes(){const e=audioCtx.currentTime;for(nextNoteTime=Math.max(nextNoteTime,e);nextNoteTime<e+.1;)playSequenceStep(nextNoteTime),audioCtx.currentTime>nextNoteTime&&console.warn(`[scheduleNotes] Note scheduled for ${nextNoteTime.toFixed(3)} missed at ${audioCtx.currentTime.toFixed(3)}.`),nextNoteTime+=getStepDuration()}function incrementStepAndSequence(e){currentStep=(currentStep+1)%64,0===currentStep&&(currentSequence=(currentSequence+1)%e),dispatchSequenceEvent("sequenceUpdated",{currentSequence:currentSequence,currentStep:currentStep})}
</script>
</prcoessSteps>

<audioWebWorkers>
<script>
const LOOKAHEAD=.1,SCHEDULE_INTERVAL=25;let workerUrl,audioWorker,lastBPM;const debounce=(e,o)=>{let r;return(...t)=>{clearTimeout(r),r=setTimeout((()=>e(...t)),o)}},initializeWorker=()=>{if(!window.Worker)return void console.error("[AudioWorker] Web Workers not supported.");if(audioWorker)return void console.warn("[AudioWorker] Worker already initialized.");workerUrl=URL.createObjectURL(new Blob(["\n                self.onmessage = e => {\n                    const { action, stepDuration, lookahead, scheduleInterval } = e.data;\n                    try {\n                        if (action === 'start') {\n                            startScheduling(stepDuration, lookahead, scheduleInterval);\n                        } else if (action === 'stop') {\n                            stopScheduling();\n                        } else if (action === 'updateStepDuration') {\n                            stepDuration = stepDuration;\n                        } else {\n                            console.warn(\"[Worker] Unknown action:\", action);\n                        }\n                    } catch (error) {\n                        self.postMessage({ action: 'error', message: error.message });\n                    }\n                };\n                let stepDuration = 0.25, lookahead = 0.1, scheduleInterval = 25, timerID = null;\n                const startScheduling = (sd, la, si) => {\n                    stepDuration = sd; lookahead = la; scheduleInterval = si;\n                    stopScheduling();\n                    timerID = setInterval(() => self.postMessage({ action: 'scheduleNotes' }), scheduleInterval);\n                };\n                const stopScheduling = () => {\n                    if (timerID) { clearInterval(timerID); timerID = null; }\n                };\n            "],{type:"application/javascript"}));try{audioWorker=new Worker(workerUrl),audioWorker.onmessage=handleWorkerMessage,window.addEventListener("bpmChanged",debounce(updateWorkerStepDuration,100)),console.log("[AudioWorker] Worker initialized.")}catch(e){console.error("[AudioWorker] Initialization failed:",e)}},handleWorkerMessage=e=>{const{action:o,message:r}=e.data;"scheduleNotes"===o?"function"==typeof scheduleNotes?scheduleNotes():console.error("[AudioWorker] 'scheduleNotes' is not defined."):"error"===o?console.error("[AudioWorker] Worker Error:",r):console.warn("[AudioWorker] Unknown action from worker:",o)},startWorker=()=>{if(!audioWorker)return void console.error("[AudioWorker] Initialize worker first.");const e=getStepDuration();audioWorker.postMessage({action:"start",stepDuration:e,lookahead:.1,scheduleInterval:25})},stopWorker=()=>{audioWorker?audioWorker.postMessage({action:"stop"}):console.warn("[AudioWorker] Worker not initialized.")},getStepDuration=()=>{const e=window.globalJsonData?.projectBPM||120;return e!==lastBPM&&(lastBPM=e),60/(4*lastBPM)},cleanUpWorker=async()=>{if(audioWorker&&(audioWorker.postMessage({action:"stop"}),audioWorker.terminate(),audioWorker=null),workerUrl&&(URL.revokeObjectURL(workerUrl),workerUrl=null),"undefined"!=typeof audioCtx&&"closed"!==audioCtx.state)try{await audioCtx.close()}catch(e){console.error("[AudioWorker] Closing AudioContext failed:",e)}window.removeEventListener("bpmChanged",updateWorkerStepDuration),console.log("[AudioWorker] Cleanup completed.")},updateWorkerStepDuration=()=>{if(audioWorker){const e=getStepDuration();audioWorker.postMessage({action:"updateStepDuration",stepDuration:e})}else console.error("[AudioWorker] Initialize worker first.")};window.addEventListener("beforeunload",cleanUpWorker),document.getElementById("loadVisualizerButton")?.addEventListener("click",initializeWorker),document.getElementById("visualizerCanvas")?.addEventListener("click",startWorker);
</script>
</audioWebWorkers>


<AudioMixer>
    <!-- Integrated Mixer Script -->
    <script>
        // Define total channels in the mixer
        const TOTAL_CHANNELS = 32;

        // Reference to the channel groups (e.g., UI elements for fader groups)
        const group1 = document.getElementById('group1');
        const group2 = document.getElementById('group2');

        // Assuming VOLUME_CONTROLS and audioChannels are globally available
        const REQUIRED_CHANNELS = 24; // We will only patch 24 channels to the first 24 faders
        const tracks = VOLUME_CONTROLS.length; // Number of tracks, derived from your sequencer
        const channelsPerTrack = Math.ceil(REQUIRED_CHANNELS / tracks);

        // Extend each track's channel list to REQUIRED_CHANNELS if necessary
        VOLUME_CONTROLS.forEach(track => {
            while (track.length < channelsPerTrack) {
                track.push(1); // Default volume
            }
        });

        // Function to initialize mixer faders and assign them to channels
        function initializeMixer() {
            for (let i = 1; i <= TOTAL_CHANNELS; i++) {
                const channel = document.createElement('div');
                channel.classList.add('channel');

                const label = document.createElement('div');
                label.classList.add('channel-label');

                const chText = document.createElement('div');
                chText.classList.add('ch');
                chText.textContent = 'CH';

                const numberText = document.createElement('div');
                numberText.classList.add('number');
                numberText.textContent = `${i}`;

                label.appendChild(chText);
                label.appendChild(numberText);

                const faderContainer = document.createElement('div');
                faderContainer.classList.add('fader-container');

                const fader = document.createElement('input');
                fader.type = 'range';
                fader.min = 0;
                fader.max = 100;

                // Initialize fader value based on VOLUME_CONTROLS
                const trackIndex = Math.floor((i - 1) / channelsPerTrack);
                const channelIndex = (i - 1) % channelsPerTrack;
                const initialVolume = VOLUME_CONTROLS[trackIndex][channelIndex] !== undefined 
                    ? VOLUME_CONTROLS[trackIndex][channelIndex] * 100 
                    : 50;
                fader.value = initialVolume;
                fader.classList.add('fader');
                fader.id = `fader-${i}`;

                const volumeLevel = document.createElement('div');
                volumeLevel.classList.add('volume-level');
                volumeLevel.id = `volume-${i}`;
                volumeLevel.textContent = `${initialVolume}%`;

                fader.addEventListener('input', (e) => {
                    const volume = e.target.value;
                    volumeLevel.textContent = `${volume}%`;
                    updateVolume(i, volume / 100);
                });

                faderContainer.appendChild(fader);
                channel.appendChild(label);
                channel.appendChild(faderContainer);
                channel.appendChild(volumeLevel);

                if (i <= 16) {
                    group1.appendChild(channel);  // First group of faders (1-16)
                } else {
                    group2.appendChild(channel);  // Second group of faders (17-32)
                }
            }
        }

        // Function to update VOLUME_CONTROLS and corresponding gain nodes
        function updateVolume(channelNumber, volume) {
            const trackIndex = Math.floor((channelNumber - 1) / channelsPerTrack);
            const channelIndex = (channelNumber - 1) % channelsPerTrack;

            if (VOLUME_CONTROLS[trackIndex] && VOLUME_CONTROLS[trackIndex][channelIndex] !== undefined) {
                VOLUME_CONTROLS[trackIndex][channelIndex] = volume;
                updateGainNode(trackIndex, channelIndex, volume);
            } else {
                console.warn(`Channel ${channelNumber} does not exist in VOLUME_CONTROLS.`);
            }
        }

        // Function to update the gain node for the specific channel
        function updateGainNode(trackIndex, channelIndex, volume) {
            // Assuming audioChannels are globally available and hold the gain nodes for each track
            console.log(`Updating Track ${trackIndex + 1}, Channel ${channelIndex + 1} to volume ${volume}`);
            if (audioChannels[trackIndex] && audioChannels[trackIndex][channelIndex]) {
                audioChannels[trackIndex][channelIndex].gainNode.gain.value = volume;
            } else {
                console.warn(`Gain node not found for Track ${trackIndex + 1}, Channel ${channelIndex + 1}`);
            }
        }

        // Initialize the Mixer UI on Page Load
        window.addEventListener('DOMContentLoaded', () => {
            initializeMixer();
        });

        // Function to toggle the mixer visibility (for UI purposes)
        function toggleMixer() {
            const mixerOverlay = document.getElementById('mixer-overlay');
            const isVisible = mixerOverlay.style.display === 'block';

            if (isVisible) {
                mixerOverlay.style.display = 'none';
            } else {
                mixerOverlay.style.display = 'block';
            }
        }

        // Listen for 'M' key press to toggle mixer visibility
        document.addEventListener('keydown', (e) => {
            if (e.key === 'm' || e.key === 'M') {
                toggleMixer();
            }
        });
    </script>
</AudioMixer>


<loadVisualiserScripts>
<script>
function loadScript(e){return new Promise(((c,t)=>{const a=document.createElement("script");a.src=e,a.onload=c,a.onerror=t,document.body.appendChild(a)}))}async function loadAllScripts(){const e=["/content/c7c92a81d5279950be7d0bd3e755ad620551bc65e6e514d6f7c29b4c24465d0ai0","/content/305829e076d38130be65851c79241929983f16d679822015ff237029f67d5d9ei0","/content/0d8309856ec04e8ab5bd6aa4689429102378fb45368ad0e2787f0dfc72c66152i0","/content/287c837ecffc5b80d8e3c92c22b6dbf0447a3d916b95ee314c66909f6f2b2f3ci0","/content/97c042112c29d9a9ca1da99890542befdbffaec6ff17798897c187a617a62f79i0","/content/3ab9dda407f9c7f62b46401e2664bc1496247c8950620a11a36a8601267cb42fi0","/content/4a6164e05aee1d4ed77585bc85e4d4530801ef71e1c277c868ce374c4a7b9902i0","/content/0505ae5cebbe9513648fc8e4ecee22d9969764f3cdac9cd6ec33be083c77ae96i0","/content/87bb49f5617a241e29512850176e53169c3da4a76444d5d8fcd6c1e41489a4b3i0","/content/cea34b6ad754f3a4e992976125bbd1dd59213aab3de03c9fe2eb10ddbe387f76i0","/content/bcee9a2e880510772f0129c735a4ecea5bb45277f3b99ff640c1bd393dddd6dfi0","/content/90d910fe4088c53a16eb227ec2fe59802091dc4ea51564b2665090403c34f59ci0","/content/916fd1731cdecf82706a290d03448c6dc505c01d6ec44bbca20281a19723d617i0","/content/6a5e5c8b42793dd35512dfddd81dbbe211f052ac79839dd54b53461f5783a390i0","/content/c0ee69121238f6438be8398038301cf5b1d876cce30a0d45a3a5e0b927826940i0","/content/6f1def70a3290c50793773a8b1712c9a1b0561b3674ee50a06c13bc4e492f459i0","/content/99ecc0668e27f03cf202f9ebc49d0332ac8f594bc9b5483969108b83723a0e9di0","/content/214457a4f832847565746ecb0b9460ec7dc8ad93549a00a69f18b3d492c0e005i0"];for(const c of e)await loadScript(c),console.log(`Loaded: ${c}`);console.log("All scripts loaded successfully.")}!async function(){const e=document.createElement("canvas");e.id="cv",document.body.append(e),Object.assign(document.body.style,{display:"flex",justifyContent:"center",alignItems:"center",height:"100vh",margin:"0"});const c=async()=>{window.cci2=0,window.initialCCI2=0,resetAllStates(),loadJsonFromUrl(window.jsonDataUrl),initializeWorker(),await loadAllScripts()};try{await new Promise((e=>{const c=()=>window.jsonDataUrl?e():setTimeout(c,100);c()})),console.log("Fetching from URL:",window.jsonDataUrl);const e=await fetch(window.jsonDataUrl);if(!e.ok)throw new Error(`HTTP error! status: ${e.status}`);window.settings=await e.json(),console.log("Settings loaded:",window.settings),await ensureAudioContextState(),"loading"===document.readyState?document.addEventListener("DOMContentLoaded",c):c()}catch(e){console.error("Error initializing the app:",e)}console.log(`[${(new Date).toISOString()}] [debugScriptLoading] ScriptLoader initialized.`)}();
</script>
</loadVisualiserScripts>
   
<visualizerScripts>
<script>
    // visualizerScript.js

// Define the array of scripts to load globally
window.visualizerScripts = [
  "/content/c7c92a81d5279950be7d0bd3e755ad620551bc65e6e514d6f7c29b4c24465d0ai0",
  "/content/305829e076d38130be65851c79241929983f16d679822015ff237029f67d5d9ei0",
  "/content/0d8309856ec04e8ab5bd6aa4689429102378fb45368ad0e2787f0dfc72c66152i0",
  "/content/287c837ecffc5b80d8e3c92c22b6dbf0447a3d916b95ee314c66909f6f2b2f3ci0",
  "/content/97c042112c29d9a9ca1da99890542befdbffaec6ff17798897c187a617a62f79i0",
  "/content/3ab9dda407f9c7f62b46401e2664bc1496247c8950620a11a36a8601267cb42fi0",
  "/content/4a6164e05aee1d4ed77585bc85e4d4530801ef71e1c277c868ce374c4a7b9902i0",
  "/content/0505ae5cebbe9513648fc8e4ecee22d9969764f3cdac9cd6ec33be083c77ae96i0",
  "/content/87bb49f5617a241e29512850176e53169c3da4a76444d5d8fcd6c1e41489a4b3i0",
  "/content/cea34b6ad754f3a4e992976125bbd1dd59213aab3de03c9fe2eb10ddbe387f76i0",
  "/content/bcee9a2e880510772f0129c735a4ecea5bb45277f3b99ff640c1bd393dddd6dfi0",
  "/content/90d910fe4088c53a16eb227ec2fe59802091dc4ea51564b2665090403c34f59ci0",
  "/content/916fd1731cdecf82706a290d03448c6dc505c01d6ec44bbca20281a19723d617i0",
  "/content/6a5e5c8b42793dd35512dfddd81dbbe211f052ac79839dd54b53461f5783a390i0",
  "/content/c0ee69121238f6438be8398038301cf5b1d876cce30a0d45a3a5e0b927826940i0",
  "/content/6f1def70a3290c50793773a8b1712c9a1b0561b3674ee50a06c13bc4e492f459i0",
  "/content/99ecc0668e27f03cf202f9ebc49d0332ac8f594bc9b5483969108b83723a0e9di0",
  "/content/214457a4f832847565746ecb0b9460ec7dc8ad93549a00a69f18b3d492c0e005i0"
];

/**
 * Dynamically loads a single script.
 * @param {string} src - The source URL of the script to load.
 * @returns {Promise<void>}
 */
function loadScript(src) {
  return new Promise((resolve, reject) => {
    const script = document.createElement("script");
    script.src = src;
    script.async = true; // Optional: Load scripts asynchronously
    script.onload = () => {
      console.log(`Loaded: ${src}`);
      resolve();
    };
    script.onerror = () => {
      console.error(`Failed to load script: ${src}`);
      reject(new Error(`Failed to load script: ${src}`));
    };
    document.body.appendChild(script);
  });
}

/**
 * Loads all required visualizer scripts sequentially.
 * @returns {Promise<void>}
 */
async function loadAllScripts() {
  const scriptUrls = window.visualizerScripts || [];
  for (const url of scriptUrls) {
    try {
      await loadScript(url);
    } catch (error) {
      console.error(`Error loading script ${url}:`, error);
      // Optionally, decide whether to continue loading other scripts or abort
    }
  }
  console.log("All scripts loaded successfully.");
}

/**
 * Initializes the visualizer application.
 */
(async function initializeVisualizer() {
  // Create and configure the canvas element
  const canvas = document.createElement("canvas");
  canvas.id = "cv";
  document.body.appendChild(canvas);
  Object.assign(document.body.style, {
    display: "flex",
    justifyContent: "center",
    alignItems: "center",
    height: "100vh",
    margin: "0"
  });

  /**
   * Core initialization function.
   */
  const coreInit = async () => {
    window.cci2 = 0;
    window.initialCCI2 = 0;

    // Ensure these functions are defined elsewhere in your project
    if (typeof resetAllStates === "function") {
      resetAllStates();
    } else {
      console.warn("Function resetAllStates is not defined.");
    }

    if (typeof loadJsonFromUrl === "function") {
      loadJsonFromUrl(window.jsonDataUrl);
    } else {
      console.warn("Function loadJsonFromUrl is not defined.");
    }

    if (typeof initializeWorker === "function") {
      initializeWorker();
    } else {
      console.warn("Function initializeWorker is not defined.");
    }

    // Load all scripts
    await loadAllScripts();
  };

  try {
    // Wait until window.jsonDataUrl is available
    await new Promise((resolve) => {
      const checkJsonDataUrl = () => {
        if (window.jsonDataUrl) {
          resolve();
        } else {
          setTimeout(checkJsonDataUrl, 100);
        }
      };
      checkJsonDataUrl();
    });

    console.log("Fetching from URL:", window.jsonDataUrl);

    // Fetch and load settings
    const response = await fetch(window.jsonDataUrl);
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    window.settings = await response.json();
    console.log("Settings loaded:", window.settings);

    // Ensure the AudioContext is in the correct state
    if (typeof ensureAudioContextState === "function") {
      await ensureAudioContextState();
    } else {
      console.warn("Function ensureAudioContextState is not defined.");
    }

    // Initialize when the document is ready
    if (document.readyState === "loading") {
      document.addEventListener("DOMContentLoaded", coreInit);
    } else {
      await coreInit();
    }
  } catch (error) {
    console.error("Error initializing the app:", error);
  }

  console.log(`[${new Date().toISOString()}] [debugScriptLoading] ScriptLoader initialized.`);
})();

</script>
</visualizerScripts>

<visualizerLoader>
<script>
// visualizerLoader.js
/**
 * Loader Checker Script
 * 
 * This script checks if there are visualizer scripts to load.
 * If the `window.visualizerScripts` array exists and contains scripts,
 * it ensures that the Visualizer Script (Script A) is loaded
 * before proceeding with initialization.
 * 
 * If no scripts are present, it gracefully skips the visualizer.
 */

// Function to check if the visualizerScripts array exists and is non-empty
function shouldLoadVisualizer() {
  return Array.isArray(window.visualizerScripts) && window.visualizerScripts.length > 0;
}

// Function to dynamically load a script
function loadScript(src) {
  return new Promise((resolve, reject) => {
    const script = document.createElement("script");
    script.src = src;
    script.async = true; // Optional: Load scripts asynchronously
    script.onload = () => {
      console.log(`Loader Checker: Loaded script ${src}`);
      resolve();
    };
    script.onerror = () => {
      console.error(`Loader Checker: Failed to load script ${src}`);
      reject(new Error(`Failed to load script: ${src}`));
    };
    document.body.appendChild(script);
  });
}

// Function to initialize the visualizer if needed
async function initializeVisualizerIfNeeded() {
  if (shouldLoadVisualizer()) {
    console.log("Loader Checker: Visualizer scripts detected. Initializing visualizer...");
    
    // Path to Script A (Visualizer Script)
    const visualizerScriptPath = "/path/to/visualizerScript.js"; // Update this path accordingly

    try {
      await loadScript(visualizerScriptPath);
      console.log("Loader Checker: Visualizer initialized successfully.");
    } catch (error) {
      console.error("Loader Checker: Error initializing visualizer:", error);
    }
  } else {
    console.log("Loader Checker: No visualizer scripts to load. Skipping visualizer initialization.");
  }
}

// Execute the checker once the DOM is fully loaded
if (document.readyState === "loading") {
  document.addEventListener("DOMContentLoaded", initializeVisualizerIfNeeded);
} else {
  initializeVisualizerIfNeeded();
}

</script>
</visualizerLoader>
</body>
</html>