<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>? ? ? ? ? ? ?</title>

<style>
  body, html {
      height: 100%;
      margin: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      background-color: #000000;
      position: relative;
      transform: scale(0.7);
  }
  
  body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
      overflow: hidden;
      display: flex;
      justify-content: center;
      align-items: center;
  }
  
  #canvas-container {
      width: 50vmin;
      height: 50vmin;
      display: flex;
      justify-content: center;
      align-items: center;
      background-color: white;
      position: relative;
      z-index: 10; /* Ensure the canvas has a higher z-index than the mixer */
  }
  
  canvas#cv {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      z-index: 9999; /* Keep it above other content but below text elements */
      pointer-events: none;
  }
  
  .text-element, .play-text {
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      text-align: center;
      z-index: 10001;
      opacity: 1;
      transition: opacity 5s ease-in-out;
  }
  
  .play-text {
      font-size: 125px;
      font-style: bold;
      font-weight: 700;
      color: #ff00bf;
      z-index: 10001;
      opacity: 1;
      transition: opacity 30s ease-in-out;
  }
  
  .sqyzy {
      font-family: Arial, bold, sans-serif;
      font-size: 96px;
      font-weight: 500;
      color: #000000;
  }
  
  .freedom {
      font-size: 125px;
      font-weight: 700;
      font-style: bold;
  }
  
  .melophonic {
      font-family: "Trebuchet MS", bold, sans-serif;
      font-size: 65px;
      color: #000;
  }
  
  .fade-overlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: #000;
      z-index: 10000;
      opacity: 1;
      transition: opacity 10s ease-in-out;
  }
   /* Button Container Styles */
#button-container {
    position: fixed;
    right: 10px;
    top: 60px; /* Starting position */
    display: flex;
    flex-direction: column;
    gap: 10px; /* Space between buttons */
    z-index: 10002; /* Ensure container is above other elements */
}

/* Continue, Play, and Next Button Styles */
#continue-button,
#play-button,
#next-seed-button {
    padding: 10px 20px;
    font-size: 18px;
    font-weight: bold;
    color: white;
    border: none;
    cursor: pointer;
    transition: background-color 0.3s;
    border-radius: 5px; /* Optional: Adds rounded corners */
}

/* Specific Styles for Continue Button */
#continue-button {
    background-color: #ff00bf;
}

#continue-button:hover {
    background-color: #ff33c9;
}

/* Specific Styles for Play Button */
#play-button {
    background-color: #00bfff; /* Blue */
}

#play-button.playing {
    background-color: #ff0000; /* Red */
}

#play-button:hover {
    /* Change hover color based on state */
    background-color: #33c9ff;
}

#play-button.playing:hover {
    background-color: #ff4d4d; /* Lighter red on hover */
}

/* Specific Styles for Next Seed Button */
#next-seed-button {
    background-color: #32cd32; /* LimeGreen for differentiation */
}

#next-seed-button:hover {
    background-color: #45d645;
}

/* Optional: Style for Playback Message */
#playback-message {
    position: fixed;
    bottom: 20px;
    right: 10px;
    background-color: rgba(0, 0, 0, 0.7);
    color: white;
    padding: 10px 20px;
    border-radius: 5px;
    opacity: 0;
    transition: opacity 0.5s;
    z-index: 10003;
}

  
  #seed-display {
      position: fixed;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      background-color: rgba(255, 255, 255, 0.8);
      padding: 10px 20px;
      border-radius: 8px;
      font-size: 20px;
      color: #000;
      opacity: 0; /* Initially hidden */
      transition: opacity 2s ease-in-out;
      z-index: 10002;
  }
  /* Mixer Overlay Styles */
  #mixer-overlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 35vw;  /* Limit mixer to 35% of the viewport width */
      height: 70vh; /* Limit mixer to 70% of the viewport height */
      background: rgba(0, 0, 0, 0.8);
      display: none; /* Initially hidden */
      z-index: 12999; /* Higher than canvas, lower than buttons */
  }
  
  /* Mixer Container Styles */
  .mixer-container {
      position: relative; /* Keep it relative to the mixer overlay */
      width: 100%;
      height: 100%;
      padding: 20px;
      background-color: #1e1e1e;
      border: 2px solid #444;
      border-radius: 10px;
      overflow-y: auto;
  }
  
  .channel-group {
      display: flex;
      justify-content: space-around;
      flex-wrap: wrap;
      gap: 10px;
  }
  
  .channel {
      display: flex;
      flex-direction: column;
      align-items: center;
      width: 60px;
      padding: 10px;
      background-color: #333;
      border: 1px solid #555;
      border-radius: 5px;
  }
  
  .channel-label {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin-bottom: 10px;
      font-size: 14px;
      text-align: center;
      line-height: 1.2;
  }
  
  .channel-label .ch {
      font-weight: bold;
  }
  
  .channel-label .number {
      margin-top: 2px;
  }
  
  .fader-container {
      position: relative;
      height: 200px;
      width: 30px;
  }
  
  .fader {
      -webkit-appearance: none;
      appearance: none;
      width: 200px;
      height: 30px;
      background: transparent;
      transform: rotate(-90deg);
      position: absolute;
      top: 85px;
      left: -85px;
  }
  
  .fader::-webkit-slider-thumb {
      -webkit-appearance: none;
      appearance: none;
      width: 20px;
      height: 20px;
      background: #ff5722;
      cursor: pointer;
      border-radius: 50%;
      border: 2px solid #fff;
  }
  
  .fader::-moz-range-thumb {
      width: 20px;
      height: 20px;
      background: #ff5722;
      cursor: pointer;
      border-radius: 50%;
      border: 2px solid #fff;
  }
  
  .fader::-webkit-slider-runnable-track {
      width: 100%;
      height: 6px;
      background: #555;
      border-radius: 3px;
  }
  
  .fader::-moz-range-track {
      width: 100%;
      height: 6px;
      background: #555;
      border-radius: 3px;
  }
  
  .volume-level {
      margin-top: 10px;
      font-size: 12px;
      text-align: center;
  }
  
  /* Responsive Design */
  @media (max-width: 1200px) {
      .channel {
          width: 50px;
      }
  
      .fader-container {
          height: 150px;
          width: 25px;
      }
  
      .fader {
          width: 150px;
          left: -65px;
          top: 60px;
      }
  
      .volume-level {
          font-size: 10px;
      }
  
      .channel-label {
          font-size: 12px;
      }
  }
  
  @media (max-width: 768px) {
      .channel-group {
          justify-content: center;
      }
  
      .channel {
          width: 40px;
      }
  
      .fader-container {
          height: 120px;
          width: 20px;
      }
  
      .fader {
          width: 120px;
          left: -50px;
          top: 40px;
      }
  
      .volume-level {
          font-size: 8px;
      }
  
      .channel-label {
          font-size: 10px;
      }
  }
  
  @media (max-width: 480px) {
      .channel {
          width: 35px;
      }
  
      .fader-container {
          height: 100px;
          width: 18px;
      }
  
      .fader {
          width: 100px;
          left: -40px;
          top: 30px;
      }
  
      .volume-level {
          font-size: 7px;
      }
  
      .channel-label {
          font-size: 9px;
      }
  }
  
  </style>


<window.seed>
  <script>
    /**
     * Seed Initialization and BPM Selection with Logging
     */

    // Default seed initialization
    window.seed = '63';
    let selectedGroup = 'random'; // To keep track of the selected BPM group

    // Logs the user's BPM group selection
    console.log(`Initial Seed: ${window.seed}`);

    /**
     * Generates a seed that maps to the desired BPM.
     * @param {number} desiredBpm - The desired BPM value.
     * @returns {string} A 20-digit seed that maps to the desired BPM.
     */
    function generateSeedForBpm(desiredBpm) {
      const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
      const index = bpmOptions.indexOf(desiredBpm);
      if (index === -1) {
        throw new Error('Invalid BPM');
      }

      // Generate a random seed and adjust it to map to the desired BPM
      const maxSeedValue = BigInt('9'.repeat(20)); // Maximum 20-digit number as BigInt
      let seedNumber;

      while (true) {
        // Generate a random 20-digit seed as a BigInt
        const randomDigits = Array.from({ length: 20 }, () => Math.floor(Math.random() * 10)).join('');
        seedNumber = BigInt(randomDigits);

        // Calculate the hash as in mapSeedToBpm
        const hash = seedNumber.toString().split('').reduce((acc, digit) => {
          return (acc * 10 + parseInt(digit, 10)) % 1000000007;
        }, 0);

        // Check if the hash modulo bpmOptions.length equals the desired index
        if (hash % bpmOptions.length === index) {
          break;
        }
      }

      // Convert the seed number back to a 20-digit string
      const seed = seedNumber.toString().padStart(20, '0');
      return seed;
    }

    /**
     * Sets the BPM value and generates a seed that maps to the desired BPM.
     * Logs the selection process and updates the seed accordingly.
     * @param {string} value - The selected BPM value.
     */
    function setBpm(value) {
      const selectedBpm = parseInt(value);
      console.log(`User selected BPM: ${selectedBpm}`);

      try {
        window.seed = generateSeedForBpm(selectedBpm); // Generate a seed that maps to the desired BPM
        document.getElementById('seed-display').innerText = `Seed: ${window.seed}`;
        console.log(`Generated seed for BPM ${selectedBpm}: ${window.seed}`);
      } catch (error) {
        console.error(error.message);
      }
    }

    /**
     * Maps a seed to a specific BPM based on a pseudo-random method using the seed.
     * @param {string} seed - A 20-digit seed string.
     * @returns {number} The selected BPM.
     */
    function mapSeedToBpm(seed) {
      const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
      const hash = seed.split('').reduce((acc, digit) => {
        return (acc * 10 + parseInt(digit, 10)) % 1000000007;
      }, 0);
      const selectedBpm = bpmOptions[hash % bpmOptions.length];

      console.log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${selectedBpm}`);
      return selectedBpm;
    }

    /**
     * Selects a BPM based on the current seed or a random selection if default.
     * @returns {number} The selected BPM.
     */
    function selectBpmFromSeed() {
      const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
      return window.seed === '00000000000000000000'
        ? bpmOptions[Math.floor(Math.random() * bpmOptions.length)]
        : mapSeedToBpm(window.seed);
    }

    /**
     * Handles the 'Continue' button click by selecting and validating the BPM.
     * Logs the selected BPM and continues the process.
     */
    function handleContinue() {
      const bpm = selectBpmFromSeed();
      console.log('Selected BPM:', bpm);
      // Continue with application logic using the selected BPM
    }
  </script>
</window.seed>



<htmlElements>
  <!-- BPM Selector -->
  <select id="bpmSelector" onchange="setBpm(this.value)">
    <option value="80">BPM: 80</option>
    <option value="100">BPM: 100</option>
    <option value="120">BPM: 120</option>
    <option value="140">BPM: 140</option>
    <option value="160">BPM: 160</option>
    <option value="180">BPM: 180</option>
    <option value="240">BPM: 240</option>
  </select>



  <div id="loading-spinner" style="display: none;">Loading...</div>

 <!-- Button Container -->
 <div id="button-container">
  <button id="continue-button">Continue</button>
  <button id="play-button">Play</button>
  <button id="next-seed-button">Next</button> <!-- Next Seed Button -->
</div>

<!-- Playback Message (Optional) -->
<div id="playback-message"></div>

<!-- Mixer Overlay -->
<div id="mixer-overlay">
  <div class="mixer-container">
      <div class="channel-group" id="group1">
          <!-- Channels 1-16 -->
      </div>
      <div class="channel-group" id="group2">
          <!-- Channels 17-32 -->
      </div>
  </div>

   <!-- Seed Display (From Event Listeners Script) -->
   <div id="seed-display" style="opacity: 0;"></div>

</div>

</htmlElements>

<script id="song-and-sound-inputs">
  const init = () => {
      log('Init function called. Preparing to process song data URLs...');

        const songDataUrls = [
            "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH
            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE
            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA
            "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP
            "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress
            "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY
            "/content/3359ce42359274ddbd2184d9f75a38b7e59b1d5f24512959e29c377fc8ca604ai0", // MintyFresh Vibes
            "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE
            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240
            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch
            "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60
        ];

        log(`Found ${songDataUrls.length} song data URLs to process.`);

        // Modify the first URL using seeded random and the selected BPM seed
        const seed = window.seed; // The seed is set based on the BPM group
        songDataUrls[0] += `?v=${Math.floor(seededRandom(seed) * 1000)}`;

        log(`First song URL has been modified using seeded random. New URL: ${songDataUrls[0]}`);

        if (songDataUrls.length) {
            log('Beginning processing of songDataUrls...');
            processSerializedData(songDataUrls, VOLUME_CONTROLS, SPEED_CONTROLS);
        } else {
            console.warn('songDataUrls array is empty. No data to process.');
        }

        log('Init function execution complete.');
    };
</script>

<constants-and-variables>
<script id="constants-and-variables">
  // All Song Files contain 16 channels. Volume controls below represent a master volume for the song 
  // and then a volume multiplier for every channel. These must be mapped into the new songs that are generated
  // Then the chosen 24 channels for the generative mix can be correctly mapped to the audio mixer faders.

const VOLUME_CONTROLS = [
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // TRUTH
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // On-Chain in the Membrane
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHEESE
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // KORA
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHOPPIN' IT UP
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // MLK I HAVE A DREAM
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // ModernProgress
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // HUMANITY
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // MintyFresh Vibes
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // ON DAY ONE
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Rhythm and Bass 240
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Crazy Ass Bitch (Channel 12 muted)
    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Rhythm and Bass 60 
];




SPEED_CONTROLS=[[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,.5,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],scheduleMultiplierOnOff=[1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0];let seedSet=!1,arraysInitialized=!1,audioElements=[];function applyScheduleMultiplier(e,l){try{e.channelPlaybackSpeed=e.channelPlaybackSpeed.map(((e,c)=>c<l.length&&l[c]?1.1*e:e)),console.log("Schedule multiplier applied successfully.")}catch(e){console.error("Error in applyScheduleMultiplier:",e)}}
</script>
</constants-and-variables>


<helperFunctions>
<script id="helper-functions">
const applyScheduleMultiplier=(e,t,n)=>{for(const[o,r]of Object.entries(e.projectSequences))for(const[e,s]of Object.entries(r)){const r=s?.source;if(!r||"string"!=typeof r)continue;const i=parseInt(r.replace("data",""),10)-1;if(isNaN(i)||i<0)console.warn(`Invalid song index for ${e} in sequence ${o}`);else if(1===t[i]){if(!n.some((e=>e.source===r&&e.index===s.globalIndex)))continue;const t=Array.isArray(s.steps)?s.steps.filter((e=>"number"==typeof e)):[];if(!t.length){console.log(`No valid steps data for channel ${e} in sequence ${o}. Skipping.`);continue}console.log(`Before multiplier: Channel ${e}, Song ${r}, Steps:`,t),s.steps=redistributeSteps(t,"half"),console.log(`After multiplier: Channel ${e}, Song ${r}, New Steps:`,s.steps)}}},redistributeSteps=(e,t)=>{const n={half:2,quarter:4}[t];if(!n)throw new Error("Unsupported multiplier type");return e.filter(((e,t)=>t%n==0))},generateRandomSeed=()=>Math.floor(1e16*Math.random()),log=e=>console.log(`[${(new Date).toISOString()}] ${e}`);
</script>
</helperFunctions>

<!-- Seed Management -->
<script id="seed-management">
  window.generateRandomSeed = function() {
      return Math.floor(1e16 * Math.random());
  };

  function log(e) {
      console.log(`[${(new Date).toISOString()}] ${e}`);
  }

  async function setSeed() {
      log("Starting seed generation...");
      if (window.seed === 0 || !window.seed) {
          window.seed = window.generateRandomSeed();
          log(`New seed generated: ${window.seed}`);
      } else {
          log(`Using existing seed: ${window.seed}`);
      }
      seedSet = true;
      return window.seed;
  }
</script>


    <!-- Initialize Arrays and Logs -->
    <initArraysAndLogs>
        <script id="initArraysAndLogs">
            async function initializeMultiplierArrays() {
                log("Multiplier arrays initialized.");
                arraysInitialized = true;
                return true;
            }

            const pauseBeforeContinue = () => new Promise((resolve) => {
                const continueButton = document.getElementById("continue-button");
                if (!continueButton) {
                    console.error("Continue button not found.");
                    resolve();
                    return;
                }
                continueButton.style.display = "block";
                log("Pausing before continuing...");
                log(`AudioContext state: ${audioCtx.state}`);
                log(`Current seed: ${window.seed}`);
                log(`Multiplier arrays initialized: ${arraysInitialized}`);
                log(`Is Ready to Play: ${isReadyToPlay}`);
                log(`Current step: ${currentStep}`);
                log(`Bar count: ${barCount}`);
                log(`Current sequence: ${currentSequence}`);
                if (activeSources.length > 0) {
                    log("Active audio sources:");
                    activeSources.forEach((source, index) => console.log(`Source ${index}:`, source));
                } else {
                    log("No active audio sources at this moment.");
                }
                continueButton.addEventListener("click", () => {
                    continueButton.style.display = "none";
                    log("Continue button clicked. Resuming execution.");
                    resolve();
                }, { once: true });
            });
        </script>
    </initArraysAndLogs>

    <!-- Main Initialization -->
    <script id="main-initialization">
        // Main initialization function
        const initApp = async (autoStart = false) => {
            await setSeed();
            await initializeMultiplierArrays();
            if (autoStart) {
                // Start playback immediately without pausing
                init(); // Call the main app logic here after the Continue button is pressed
            } else {
                await pauseBeforeContinue();
                init(); // Call the main app logic here after the Continue button is pressed
            }
        };

        // Execute the initialization function
        initApp(false); // Pass 'false' to prevent auto-start
      </script>

<!-- Script 5: Audio Control Functions -->
<script id="audio-control-functions">
async function safeSuspendAudioContext(){log(`[safeSuspendAudioContext] AudioContext state: ${audioCtx.state}`),"running"===audioCtx.state?(log("Suspending AudioContext..."),await audioCtx.suspend(),log(`AudioContext suspended. State: ${audioCtx.state}`)):"suspended"===audioCtx.state?log("AudioContext is already suspended."):console.warn("AudioContext is closed, cannot suspend.")}
async function stopPlayback() {
    // Display message indicating playback has stopped because the last sequence has been reached
    console.log("Playback is stopping because it has reached the end of the last sequence.");

    // You can add additional UI notification here, for example:
    const playbackMessage = document.getElementById('playback-message');
    if (playbackMessage) {
        playbackMessage.textContent = "Playback has stopped: Reached the end of the last sequence.";
        playbackMessage.style.opacity = "1";
        setTimeout(() => {
            playbackMessage.style.opacity = "0";  // Fade out the message after 5 seconds
        }, 5000);
    }

    // Stop all active audio sources with fade-out effect
    for (const a in activeSources) {
        activeSources[a].forEach(({ source, gainNode }) => {
            const currentTime = audioCtx.currentTime;
            gainNode.gain.cancelScheduledValues(currentTime);
            gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
            gainNode.gain.linearRampToValueAtTime(0, currentTime + fadeDuration);
            source.stop(currentTime + fadeDuration);
            source.disconnect();
            gainNode.disconnect();
        });
        activeSources[a] = [];
    }

    // Suspend the audio context and reset playback state
    setTimeout(async () => {
        await audioCtx.suspend();
        resetPlaybackState();
    }, 50);
}</script>
</init>

<audioContext>
<script id="audio-context-manager">
!function(){if(!window.AudioContextManager){class t{constructor(){return t.instance||(window.audioCtx=null,log("AudioContextManager initialized with no AudioContext."),t.instance=this),t.instance}initCtx(){window.audioCtx&&"closed"!==window.audioCtx.state||(window.audioCtx=new(window.AudioContext||window.webkitAudioContext),window.audioCtx.onstatechange=()=>log(`AudioContext state change. New state: ${window.audioCtx.state}`),log(`AudioContext created. State: ${window.audioCtx.state}`))}getAudioContext(){return window.audioCtx||this.initCtx(),window.audioCtx}async resume(){this.initCtx();const t=window.audioCtx.state;"suspended"===t?(log("Resuming AudioContext..."),await window.audioCtx.resume(),log(`AudioContext resumed. State: ${window.audioCtx.state}`)):"running"===t?log("AudioContext already running."):"closed"===t&&(log("Resetting closed AudioContext..."),await this.resetCtx())}async suspend(){const t=window.audioCtx?.state;log(`Attempting to suspend AudioContext. Current state: ${t}`),"running"===t?(await window.audioCtx.suspend(),log(`AudioContext suspended. State: ${window.audioCtx.state}`)):"suspended"===t?log("AudioContext already suspended."):console.warn("Cannot suspend AudioContext.")}async resetCtx(){log(`Current AudioContext state: ${window.audioCtx?.state}`),window.audioCtx&&"closed"!==window.audioCtx.state&&(await window.audioCtx.close(),log("AudioContext closed.")),this.initCtx(),log(`AudioContext reset. State: ${window.audioCtx.state}`),"suspended"===window.audioCtx.state&&(log("Resuming new AudioContext..."),await window.audioCtx.resume(),log(`AudioContext resumed. State: ${window.audioCtx.state}`))}
async resetApp() {
                log("Resetting application.");
                // Remove or comment out the next line
                // window.seed +=1; // We will handle seed generation separately
                log(`New seed: ${window.seed}`);
                await this.resetCtx();
                window.audioElements = [];
                window.activeSources = [];
                window.arraysInitialized = !1;
                window.isReadyToPlay = !1;
                log("Application reset complete.");
                await initApp();
            }
          }
        window.AudioContextManager = new t();
    }
}();</script>

</audioContext>

</seedAndInitialise>

<!-- Include Global Definitions -->
    <globalDefinitions>
        <script>
            window.enableVisualizerScripts = false; // Set to true to enable, false to disable

            let globalVolumeMultiplier = 1,
                globalJsonData = null,
                bpm = 0;
            const sourceChannelMap = new Map();
            let globalTrimTimes = {},
                globalVolumeLevels = {},
                globalPlaybackSpeeds = {},
                activeSources = [],
                globalGainNodes = new Map(),
                globalAudioBuffers = [],
                globalReversedAudioBuffers = {},
                isReversePlay = false;
            const gainNodes = {},
                audioCtx = window.AudioContextManager.getAudioContext();
            let preprocessedSequences = {},
                isReadyToPlay = false,
                currentStep = 0,
                beatCount = 0,
                barCount = 0,
                currentSequence = 0,
                playbackTimeoutId = null,
                nextNoteTime = 0,
                totalSequences = 0;
            const fadeDuration = 0.01,
                defaultVolume = 1;
            let isToggleInProgress = false,
                isPlaying = false;
            // let isFirstLoopCompleted = false; // **Global flag**
            const AudionalPlayerMessages = new BroadcastChannel("channel_playback");
        </script>
    </globalDefinitions>



<audioDataProcessing>
<script>
const fetchAndProcessAudioData=async e=>{await Promise.all(e.map(((e,r)=>processAudioUrl(e,r+1)))),createReversedBuffers()},getOrCreateGainNode=e=>{if(!gainNodes[e]){const r=audioCtx.createGain();r.connect(audioCtx.destination),gainNodes[e]=r}return gainNodes[e]},processAudioUrl=async(e,r)=>{const a=`Channel ${r}`;try{const r=await fetch(e);if(!r.ok)throw new Error(`Fetch failed: ${e}, Status: ${r.status}`);const o=r.headers.get("Content-Type"),t=await fetchAndDecodeAudio(r,o);if(t){const e=getOrCreateGainNode(a);e.gain.value=parseVolumeLevel(globalVolumeLevels[a])*globalVolumeMultiplier,globalAudioBuffers.push({buffer:t,gainNode:e,channel:a})}else console.error(`Decoding failed for ${a}: ${e}`)}catch(e){console.error(`Error processing ${a}:`,e)}},setGlobalVolumeMultiplier=e=>{globalVolumeMultiplier=Math.max(0,e),globalAudioBuffers.forEach((({gainNode:e,channel:r})=>{e.gain.value=parseVolumeLevel(globalVolumeLevels[r])*globalVolumeMultiplier}))},fetchAndDecodeAudio=async(e,r)=>{try{if(/audio\/(wav|mpeg|mp4)|video\/mp4/.test(r)){const r=await e.arrayBuffer();return audioCtx.decodeAudioData(r)}const a=await e.text();let o=null;if(/application\/json/.test(r)?o=JSON.parse(a).audioData:/text\/html/.test(r)&&(o=extractBase64FromHTML(a)),o){const e=base64ToArrayBuffer(o.split(",")[1]);return audioCtx.decodeAudioData(e)}if(/audio\//.test(r)){const r=await e.arrayBuffer();return audioCtx.decodeAudioData(r)}}catch(e){console.error("[fetchAndDecodeAudio] Decoding error:",e)}return null},createReversedBuffers=()=>{const e=new Set;Object.values(globalJsonData.projectSequences).forEach((r=>Object.entries(r).forEach((([r,a])=>{if(a.steps.some((e=>e.reverse))){const a=`Channel ${parseInt(r.slice(2))+1}`;e.add(a)}})))),globalAudioBuffers.forEach((({buffer:r,channel:a})=>{e.has(a)&&(globalReversedAudioBuffers[a]=reverseBuffer(r))}))},reverseBuffer=e=>{const r=audioCtx.createBuffer(e.numberOfChannels,e.length,e.sampleRate);for(let a=0;a<e.numberOfChannels;a++){const o=e.getChannelData(a),t=r.getChannelData(a);for(let e=0;e<o.length;e++)t[e]=o[o.length-e-1]}return r},base64ToArrayBuffer=e=>{try{const r=atob(e),a=new Uint8Array(r.length);for(let e=0;e<r.length;e++)a[e]=r.charCodeAt(e);return a.buffer}catch(e){return console.error("[base64ToArrayBuffer] Conversion error:",e),null}},extractBase64FromHTML=e=>{try{const r=(new DOMParser).parseFromString(e,"text/html").querySelector("audio[data-audionalSampleName] source")?.getAttribute("src");if(/^data:audio\/(wav|mp3|mp4);base64,/.test(r?.toLowerCase())||/audio\//.test(r?.toLowerCase()))return r;console.error("[extractBase64FromHTML] Invalid audio source format.")}catch(e){console.error("[extractBase64FromHTML] Parsing error:",e)}return null};console.log("Audio processing script loaded.");
</script>
</audioDataProcessing>

<jsonLoadingAndPlayback>
<script>
    const loadJsonFromUrl = async (url) => {
        try {
            const response = await fetch(url);
            if (!response.ok) throw new Error(`HTTP error: ${response.status}`);
            
            globalJsonData = await response.json();
            
            const stats = {
                channelsWithUrls: 0,
                sequencesCount: 0,
                activeStepsPerSequence: {},
                activeChannelsPerSequence: {},
                types: {}
            };

            analyzeJsonStructure(globalJsonData, stats);
            const playbackData = prepareForPlayback(globalJsonData, stats);

            await fetchAndProcessAudioData(playbackData.channelURLs);
            preprocessAndSchedulePlayback(playbackData);
        } catch (error) {
            console.error("Failed to load JSON:", error);
        }
    };

    const analyzeJsonStructure = (json, stats) => {
        if (json.projectSequences && typeof json.projectSequences === "object") {
            Object.entries(json.projectSequences).forEach(([sequenceId, sequenceData]) => {
                stats.activeStepsPerSequence[sequenceId] = 0;
                stats.activeChannelsPerSequence[sequenceId] = [];

                Object.entries(sequenceData).forEach(([channelId, channelData]) => {
                    const channelName = `Channel ${parseInt(channelId.slice(2)) + 1}`;
                    stats.activeStepsPerSequence[sequenceId] += channelData.steps.length;
                    stats.activeChannelsPerSequence[sequenceId].push(channelName);
                });
            });
        }

        Object.entries(json).forEach(([key, value]) => {
            if (key !== "projectSequences") {
                const type = Array.isArray(value) ? "array" : typeof value;
                stats.types[type] = (stats.types[type] || 0) + 1;
                
                if (["object", "array"].includes(type)) {
                    analyzeJsonStructure(value, stats);
                }
            }
        });
    };

    const findAndSetEndSequence = (playbackData) => {
        if (playbackData?.sequences) {
            let lastNonEmptySequence = null;
            
            for (const [sequenceId, sequence] of Object.entries(playbackData.sequences)) {
                const isEmpty = Object.values(sequence.normalSteps).every(steps => !steps.length);
                
                if (isEmpty && lastNonEmptySequence) {
                    playbackData.endSequence = lastNonEmptySequence;
                    break;
                }
                
                if (!isEmpty) {
                    lastNonEmptySequence = sequence;
                }
            }

            if (!playbackData.endSequence && lastNonEmptySequence) {
                playbackData.endSequence = lastNonEmptySequence;
            }
        }
    };

    const prepareForPlayback = (json, stats) => {
        const {
            channelURLs,
            trimSettings = [],
            channelVolume = [],
            channelPlaybackSpeed = [],
            projectSequences,
            projectName,
            projectBPM,
            currentSequence
        } = json;

        bpm = projectBPM;
        totalSequences = currentSequence;
        globalTrimTimes = {};
        globalVolumeLevels = {};
        globalPlaybackSpeeds = {};

        channelURLs.forEach((url, index) => {
            const channelName = `Channel ${index + 1}`;
            const trim = trimSettings[index] || {};

            globalTrimTimes[channelName] = {
                startTrim: +(trim.startSliderValue || 0) / 100,
                endTrim: +(trim.endSliderValue || 100) / 100
            };

            globalVolumeLevels[channelName] = +parseVolumeLevel(channelVolume[index] || 1).toFixed(3);
            globalPlaybackSpeeds[channelName] = +Math.min(Math.max(channelPlaybackSpeed[index] || 1, 0.1), 100).toFixed(3);
        });

        const sequences = Object.entries(projectSequences).reduce((acc, [sequenceId, sequenceData]) => {
            const normalSteps = {};
            const reverseSteps = {};

            Object.entries(sequenceData).forEach(([channelId, channelSteps]) => {
                const channelName = `Channel ${parseInt(channelId.slice(2)) + 1}`;
                normalSteps[channelName] = [];
                reverseSteps[channelName] = [];

                channelSteps.steps.forEach((stepData) => {
                    const stepIndex = typeof stepData === "object" ? stepData.index : stepData;
                    if (stepData.reverse) {
                        reverseSteps[channelName].push(stepIndex);
                    } else {
                        normalSteps[channelName].push(stepIndex);
                    }
                });
            });

            acc[sequenceId] = { normalSteps, reverseSteps };
            return acc;
        }, {});

        const playbackData = {
            projectName,
            bpm: projectBPM,
            channels: channelURLs.length,
            channelURLs,
            trimTimes: globalTrimTimes,
            stats,
            sequences
        };

        findAndSetEndSequence(playbackData);

        return playbackData;
    };

    const preprocessAndSchedulePlayback = (playbackData) => {
        if (!playbackData?.sequences) {
            return console.error("Playback data missing.");
        }

        bpm = playbackData.bpm;
        preprocessedSequences = Object.fromEntries(
            Object.entries(playbackData.sequences).map(([sequenceId, sequence]) => [
                sequenceId,
                {
                    normalSteps: processSteps(sequence.normalSteps),
                    reverseSteps: processSteps(sequence.reverseSteps)
                }
            ])
        );

        isReadyToPlay = Object.values(preprocessedSequences).some(
            sequence => Object.keys(sequence.normalSteps).length || Object.keys(sequence.reverseSteps).length
        );
    };

    const processSteps = (steps) => {
        return Object.fromEntries(
            Object.entries(steps).filter(([, stepArray]) => stepArray.length).map(([channelName, stepArray]) => [
                channelName,
                stepArray.map(step => ({
                    step,
                    timing: +(step * (60 / bpm)).toFixed(3)
                }))
            ])
        );
    };
</script>
</jsonLoadingAndPlayback>


<dataProcessingUtilities>
<script>
// Function to hash a string based on a specific algorithm involving shifting parts of the string
const hashString = (inputString) => {
    const shiftIndex = parseInt(inputString.split("i")[1], 10);  // Extract the shift index
    const shiftedString = inputString.slice(shiftIndex) + inputString.slice(0, shiftIndex);  // Shift the string
    return shiftedString
        .split("")
        .reduce((hash, char) => (31 * hash + char.charCodeAt(0)) % Number.MAX_SAFE_INTEGER, 0) % 1400000000;
};

// Function that generates a seeded random number based on input
const seededRandom = (seed) => {
    const randomValue = 10000 * Math.sin(seed);
    return randomValue - Math.floor(randomValue);  // Returns the fractional part
};

// Function to set the global playback status
const setPlaybackStatus = (status) => {
    window.playbackStarted = status;
};

// Key map to translate between keys and indices
const keyMap = {
    0: "projectName",
    1: "artistName",
    2: "projectBPM",
    3: "currentSequence",
    4: "channelURLs",
    5: "channelVolume",
    6: "channelPlaybackSpeed",
    7: "trimSettings",
    8: "projectChannelNames",
    9: "startSliderValue",
    10: "endSliderValue",
    11: "totalSampleDuration",
    12: "start",
    13: "end",
    14: "projectSequences",
    15: "steps"
};

// Reverse key map to translate from field names to their corresponding index
const reverseKeyMap = Object.fromEntries(Object.entries(keyMap).map(([index, key]) => [key, +index]));

// Channel map to assign letters A-Z to channel indices
const channelMap = Array.from({ length: 26 }, (_, index) => String.fromCharCode(65 + index));

// Reverse channel map to translate letters back to their indices
const reverseChannelMap = Object.fromEntries(channelMap.map((letter, index) => [letter, index]));

// Function to decompress step data
const decompressSteps = (stepData) => {
    return stepData.flatMap((step) => {
        if (typeof step === "number") {
            return step;  // If it's just a number, return it directly
        }
        if (step && typeof step === "object" && "r" in step) {
            const [start, end] = step.r;  // Extract range
            return Array.from({ length: end - start + 1 }, (_, i) => start + i);  // Return array for range
        }
        if (typeof step === "string" && step.endsWith("r")) {
            return { index: parseInt(step.slice(0, -1), 10), reverse: true };  // Reverse step
        }
        return [];
    });
};

// Function to deserialize JSON data into a readable structure
const deserialize = (data) => {
    const parseData = (input) => {
        if (Array.isArray(input)) {
            return input.map((item) => (typeof item === "object" ? parseData(item) : item));
        }
        if (input && typeof input === "object") {
            return Object.entries(input).reduce((accumulator, [key, value]) => {
                const mappedKey = keyMap[key] || key;
                if (mappedKey === "projectSequences") {
                    // Process project sequences
                    accumulator[mappedKey] = Object.entries(value).reduce((sequenceAccumulator, [sequenceKey, sequenceValue]) => {
                        const sequenceId = sequenceKey.replace(/^s/, "Sequence");  // Change 's0' to 'Sequence0'
                        sequenceAccumulator[sequenceId] = Object.entries(sequenceValue).reduce((channelAccumulator, [channelKey, channelData]) => {
                            const channelName = `ch${reverseChannelMap[channelKey]}`;
                            const steps = channelData[reverseKeyMap.steps] || [];
                            channelAccumulator[channelName] = {
                                steps: decompressSteps(steps)  // Decompress the steps
                            };
                            return channelAccumulator;
                        }, {});
                        return sequenceAccumulator;
                    }, {});
                } else {
                    accumulator[mappedKey] = parseData(value);
                }
                return accumulator;
            }, {});
        }
        return input;
    };
    return parseData(data);
};

// Initialize playback (assumed to be defined elsewhere in your codebase)
initializePlayback();

// Hash the string to generate a seed value
const seedValue = hashString("4482324585393f1523e8c28a02605c0b1c95d2779510921da0f131a5e6da5843i0");
console.log(`Seed value: ${seedValue}`);

// Initialize processing utilities when the window loads
console.log("ProcessingUtilities initialized.");
window.onload = () => {
    console.log("window.onload triggered.");
};
</script>
</dataProcessingUtilities>

<dataLoadingAndDeserialisation>
<script>
const loadPako = async () => {
  try {
    const response = await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0");
    const text = await response.text();
    const scriptContent = (new DOMParser).parseFromString(text, "text/html").querySelector("script")?.textContent;
    if (!scriptContent?.includes("pako")) throw new Error("Pako library not found in the fetched content.");
    const scriptElement = document.createElement("script");
    scriptElement.textContent = scriptContent;
    document.head.appendChild(scriptElement);
    console.log("Pako library loaded successfully.");
  } catch (error) {
    console.error("Error occurred during Pako loading:", error);
    throw error;
  }
};

const fetchAndDeserialize = async (url) => {
  try {
    const response = await fetch(url);
    if (!response.ok) throw new Error(`Network response was not ok for URL: ${url}`);
    const arrayBuffer = await response.arrayBuffer();
    const inflated = pako.inflate(new Uint8Array(arrayBuffer));
    const decoded = new TextDecoder("utf-8").decode(inflated);
    return deserialize(JSON.parse(decoded));
  } catch (error) {
    console.error("Error in fetchAndDeserialize:", error);
    throw error;
  }
};

const fetchAndProcessData = async (urls) => {
  try {
    const dataArray = (await Promise.all(urls.map(async (url) => {
      try {
        const data = await fetchAndDeserialize(url);
        if (!data?.projectSequences) throw new Error(`Invalid data at URL ${url}`);
        return data;
      } catch {
        console.error(`Error processing URL: ${url}`);
        return null;
      }
    }))).filter(Boolean);

    if (!dataArray.length) throw new Error("No valid data was processed.");
    return dataArray;
  } catch (error) {
    console.error("Error in fetchAndProcessData:", error);
    throw error;
  }
};

/**
 * Maps a seed to a specific BPM based on a pseudo-random method using the seed.
 * @param {string} seed - The seed value.
 * @returns {number} The selected BPM.
 */
function mapSeedToBpm(seed) {
  const bpmOptions = [80, 100, 120, 140, 160, 180, 240];
  const hash = seed.split('').reduce((acc, digit) => {
    return (acc * 10 + parseInt(digit, 10)) % 1000000007;
  }, 0);
  const selectedBpm = bpmOptions[hash % bpmOptions.length];

  console.log(`Seed: ${seed}, Hash: ${hash}, Selected BPM: ${selectedBpm}`);
  return selectedBpm;
}

const processSerializedDataPart1 = async (songDataUrls, volumeControls, speedControls) => {
  try {
    await loadPako();
    const deserializedData = await fetchAndProcessData(songDataUrls);
    const selectedBPM = mapSeedToBpm(window.seed);
    window.processedData = {
      deserializedData,
      selectedBPM,
      VOLUME_CONTROLS: volumeControls,
      SPEED_CONTROLS: speedControls,
      songDataUrls,
    };
    console.log("Data loading and deserialization complete.");
    document.dispatchEvent(new CustomEvent("dataLoadingComplete"));
  } catch (error) {
    console.error("Error in processSerializedDataPart1:", error);
  }
};

window.processSerializedData = processSerializedDataPart1;
console.log("DataLoadingAndDeserializationScript initialized.");
</script>
</dataLoadingAndDeserialisation>


<localDataProcessing>
<script>
const shuffleArray = (e, a) => {
    for (let n = e.length - 1; n > 0; n--) {
        const t = Math.floor(seededRandom(a++) * (n + 1));
        [e[n], e[t]] = [e[t], e[n]];
    }
    return e;
};

const adjustChannelData = (e, a, n, t, l) => {
    const s = n / e.projectBPM;
    e.channelPlaybackSpeed = e.channelPlaybackSpeed.map((e, n) => {
        let t = e * s * (l[a]?.[n] || 1);
        return Math.max(isNaN(t) ? 0.1 : t, 0.1);
    });
    const o = t[a] || [], c = o[0] || 1;
    e.channelVolume = e.channelVolume.map((e, a) => e * c * (o[a + 1] || 1));
};

// Global variable to store audio channels and their gain nodes
window.audioChannels = [];

// Function to initialize 24 gain nodes and map them to the first 24 channels
const createAndAssignGainNodes = (audioContext, channels) => {
    const gainNodes = [];
    for (let i = 0; i < 24; i++) {
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 0.5; // Set the default gain value to 0.5
        gainNodes.push(gainNode);

        // If there is a corresponding channel, connect it to the gain node
        if (channels[i]) {
            channels[i].gainNode = gainNode;
            channels[i].audioContext = audioContext;
            // Add the channel and its gainNode to the global audioChannels array
            window.audioChannels.push({ channel: channels[i], gainNode });
            console.log(`Channel ${i} assigned to GainNode with default value 0.5`);
        }
    }

    // Return the created gain nodes
    return gainNodes;
};

const assembleProcessedSong = (e, a) => {
    console.log("Starting to assemble the processed song...");

    const n = e.flatMap((e, a) =>
        e.channelURLs.map((n, t) => ({
            url: n,
            volume: e.channelVolume[t],
            speed: e.channelPlaybackSpeed[t],
            trim: e.trimSettings[t],
            source: `data${a + 1}`,
            index: t
        }))
    );
    const t = shuffleArray(n, window.seed).slice(0, 28);
    t.forEach((e, a) => {
        e.globalIndex = a;
    });

    const l = [t.slice(0, 20), t.slice(20, 24), t.slice(24, 28)];
    const s = { ...e[0], projectBPM: a, channelURLs: t.map(e => e.url), channelVolume: t.map(e => e.volume), channelPlaybackSpeed: t.map(e => e.speed), trimSettings: t.map(e => e.trim), projectSequences: {} };
    const o = e.reduce((e, a, n) => (e[`data${n + 1}`] = a, e), {});
    let c = [], r = 0;
    const i = [];

    // Initialize Web Audio API
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();

    // Assign each channel to a gain node
    const gainNodes = createAndAssignGainNodes(audioContext, t);

    for (const a in e[0].projectSequences) {
        s.projectSequences[a] = {};
        const e = parseInt(a.replace(/\D/g, ""), 10);
        e <= 1 ? c = l[0] : e <= 3 ? c = [...l[0], ...l[1]] : e <= 11 && (c = [...l[0], ...l[1], ...l[2]]);
        c.length > r && i.push({ sequenceNumber: e, channelsAdded: c.length - r, totalChannels: c.length }), r = c.length;
        c.forEach((e, n) => {
            const t = (o[e.source]?.projectSequences[a] || {})[`ch${e.index}`] || { steps: [] };
            s.projectSequences[a][`ch${n}`] = { ...t, steps: Array.isArray(t.steps) ? t.steps : [], globalIndex: e.globalIndex };
        });
    }

    s.channelAdditionLog = i;

    // Log the total number of sequences after song assembly
    const totalSequences = Object.keys(s.projectSequences).length;
    console.log(`Total number of sequences in the new generative song: ${totalSequences}`);

    // Log more detailed information about the sequences
    Object.keys(s.projectSequences).forEach(seqKey => {
        console.log(`Sequence ${seqKey} contains ${Object.keys(s.projectSequences[seqKey]).length} channels.`);
    });

    // Connect channels to the destination (if necessary)
    gainNodes.forEach(gainNode => gainNode.connect(audioContext.destination));

    return s;
};

const processSerializedDataPart2 = async () => {
    try {
        const { deserializedData: e, selectedBPM: a, VOLUME_CONTROLS: n, SPEED_CONTROLS: t } = window.processedData;
        e.forEach((e, l) => adjustChannelData(e, l, a, n, t));
        const l = assembleProcessedSong(e, a);

        // If there is a function to apply schedule multiplier, call it
        if (typeof applyScheduleMultiplier === 'function') {
            applyScheduleMultiplier(l, window.scheduleMultiplierOnOff);
        } else {
            console.warn("applyScheduleMultiplier is not defined.");
        }

        window.globalJsonData = l;
        window.jsonDataUrl = URL.createObjectURL(new Blob([JSON.stringify(l)], { type: "application/json" }));
        document.dispatchEvent(new CustomEvent("dataProcessingComplete"));
        console.log("Local data processing complete.");
    } catch (e) {
        console.error("Error in processSerializedDataPart2:", e);
    }
};

// Event listener to start processing after data is loaded
document.addEventListener("dataLoadingComplete", processSerializedDataPart2);

console.log("LocalDataProcessingScript initialized and awaiting data.");
</script>
</localDataProcessing>

<AudioMixer>
        <!-- Integrated Mixer Script -->
        <script>
            // === Global Configuration ===
            const TOTAL_CHANNELS = 32;       // Total number of mixer faders
            const REQUIRED_CHANNELS = 24;    // Number of channels to be patched to faders
            const GROUP1_LIMIT = 16;         // First 16 faders in group1, next 16 in group2
            const DEFAULT_VOLUME = 1.0;      // Default volume value (range 0.0 to 1.0)

            // === Global Variables ===
            let audioChannels = [];            // Array to hold gain nodes for each channel
            const Channel_Volume_Controls = initializeVolumeControls(); // Initialize Channel_Volume_Controls based on tracks

            // === Initialization Functions ===

            /**
             * Initializes the Channel_Volume_Controls array based on the number of tracks.
             * Each track can have multiple channels.
             */
            function initializeVolumeControls() {
                // Example: Initialize Channel_Volume_Controls for 12 tracks, 2 channels each
                const numberOfTracks = 12;
                const channelsPerTrack = Math.ceil(REQUIRED_CHANNELS / numberOfTracks); // e.g., 2 channels per track
                const volumeControls = [];

                for (let track = 0; track < numberOfTracks; track++) {
                    volumeControls[track] = [];
                    for (let channel = 0; channel < channelsPerTrack; channel++) {
                        volumeControls[track][channel] = DEFAULT_VOLUME; // Initialize with default volume
                    }
                }

                return volumeControls;
            }

            /**
             * Initializes the audioChannels array with gain nodes for each track and channel.
             */
            async function initializeAudioChannels() {
                try {
                    // Access the singleton AudioContext via AudioContextManager
                    const audioContext = AudioContextManager.getAudioContext();

                    const numberOfTracks = Channel_Volume_Controls.length;
                    const channelsPerTrack = Math.ceil(REQUIRED_CHANNELS / numberOfTracks);

                    for (let track = 0; track < numberOfTracks; track++) {
                        audioChannels[track] = [];
                        for (let channel = 0; channel < channelsPerTrack; channel++) {
                            const gainNode = audioContext.createGain();
                            gainNode.gain.value = Channel_Volume_Controls[track][channel];
                            audioChannels[track][channel] = { gainNode };

                            // Connect gain node to the destination (speakers)
                            gainNode.connect(audioContext.destination);

                            // Debugging Log
                            console.log(`[AudioMixer]: Initialized Gain node for Track ${track + 1}, Channel ${channel + 1}`);
                        }
                    }

                    // Handle additional channels if REQUIRED_CHANNELS > tracks * channelsPerTrack
                    const totalInitializedChannels = numberOfTracks * channelsPerTrack;
                    if (REQUIRED_CHANNELS > totalInitializedChannels) {
                        const extraChannels = REQUIRED_CHANNELS - totalInitializedChannels;
                        const extraTrack = numberOfTracks; // Zero-based index
                        audioChannels[extraTrack] = [];
                        for (let i = 0; i < extraChannels; i++) {
                            const gainNode = audioContext.createGain();
                            gainNode.gain.value = DEFAULT_VOLUME;
                            audioChannels[extraTrack][i] = { gainNode };
                            gainNode.connect(audioContext.destination);
                            console.log(`[AudioMixer]: Initialized Gain node for Extra Track ${extraTrack + 1}, Channel ${i + 1}`);
                        }
                    }
                } catch (error) {
                    console.error(`[AudioMixer Error]: Failed to initialize audio channels - ${error}`);
                }
            }

            /**
             * Initializes the Mixer UI with faders and links them to audio channels.
             */
            async function initializeMixer() {
                const group1 = document.getElementById('group1');
                const group2 = document.getElementById('group2');

                if (!group1 || !group2) {
                    console.error('[AudioMixer]: Mixer groups (group1 or group2) not found in the DOM.');
                    return;
                }

                const channelsPerTrack = Math.ceil(REQUIRED_CHANNELS / Channel_Volume_Controls.length);

                for (let i = 1; i <= TOTAL_CHANNELS; i++) {
                    const channel = document.createElement('div');
                    channel.classList.add('channel');

                    // === Channel Label ===
                    const label = document.createElement('div');
                    label.classList.add('channel-label');

                    const chText = document.createElement('div');
                    chText.classList.add('ch');
                    chText.textContent = 'CH';

                    const numberText = document.createElement('div');
                    numberText.classList.add('number');
                    numberText.textContent = `${i}`;

                    label.appendChild(chText);
                    label.appendChild(numberText);

                    // === Fader ===
                    const faderContainer = document.createElement('div');
                    faderContainer.classList.add('fader-container');

                    const fader = document.createElement('input');
                    fader.type = 'range';
                    fader.min = 0;
                    fader.max = 100;
                    fader.step = 0.1; // Allows finer volume adjustments

                    // Calculate track and channel indices
                    const trackIndex = Math.floor((i - 1) / channelsPerTrack);
                    const channelIndex = (i - 1) % channelsPerTrack;

                    // Retrieve initial volume from Channel_Volume_Controls
                    const initialVolume = (Channel_Volume_Controls[trackIndex] && Channel_Volume_Controls[trackIndex][channelIndex] !== undefined)
                        ? Channel_Volume_Controls[trackIndex][channelIndex] * 100
                        : 50; // Default to 50% if undefined

                    fader.value = initialVolume;
                    fader.classList.add('fader');
                    fader.id = `fader-${i}`;

                    // === Volume Level Display ===
                    const volumeLevel = document.createElement('div');
                    volumeLevel.classList.add('volume-level');
                    volumeLevel.id = `volume-${i}`;
                    volumeLevel.textContent = `${initialVolume}%`;

                    // === Event Listener for Fader ===
                    fader.addEventListener('input', (e) => {
                        const volume = parseFloat(e.target.value);
                        volumeLevel.textContent = `${volume.toFixed(1)}%`;
                        updateVolume(i, volume / 100);
                    });

                    faderContainer.appendChild(fader);
                    channel.appendChild(label);
                    channel.appendChild(faderContainer);
                    channel.appendChild(volumeLevel);

                    // Append channel to the appropriate group
                    if (i <= GROUP1_LIMIT) {
                        group1.appendChild(channel);  // First group of faders (1-16)
                    } else {
                        group2.appendChild(channel);  // Second group of faders (17-32)
                    }
                }
            }

            // === Volume Update Functions ===

            /**
             * Updates the volume in Channel_Volume_Controls and adjusts the corresponding gain node.
             * @param {number} channelNumber - The channel number (1-based index).
             * @param {number} volume - The new volume level (0.0 to 1.0).
             */
            function updateVolume(channelNumber, volume) {
                const channelsPerTrack = Math.ceil(REQUIRED_CHANNELS / Channel_Volume_Controls.length);
                const trackIndex = Math.floor((channelNumber - 1) / channelsPerTrack);
                const channelIndex = (channelNumber - 1) % channelsPerTrack;

                if (Channel_Volume_Controls[trackIndex] && Channel_Volume_Controls[trackIndex][channelIndex] !== undefined) {
                    Channel_Volume_Controls[trackIndex][channelIndex] = volume;
                    updateGainNode(trackIndex, channelIndex, volume);
                } else {
                    console.warn(`[AudioMixer Warning]: Channel ${channelNumber} does not exist in Channel_Volume_Controls.`);
                }
            }

            /**
             * Updates the gain node for a specific track and channel.
             * @param {number} trackIndex - Zero-based track index.
             * @param {number} channelIndex - Zero-based channel index within the track.
             * @param {number} volume - The new volume level (0.0 to 1.0).
             */
            function updateGainNode(trackIndex, channelIndex, volume) {
                console.log(`[AudioMixer]: Updating Track ${trackIndex + 1}, Channel ${channelIndex + 1} to volume ${volume}`);
                if (audioChannels[trackIndex] && audioChannels[trackIndex][channelIndex] && audioChannels[trackIndex][channelIndex].gainNode) {
                    audioChannels[trackIndex][channelIndex].gainNode.gain.value = volume;
                } else {
                    console.warn(`[AudioMixer Warning]: Gain node not found for Track ${trackIndex + 1}, Channel ${channelIndex + 1}`);
                }
            }

            // === Mixer Visibility Toggle ===

            /**
             * Toggles the visibility of the mixer overlay.
             */
            function toggleMixer() {
                const mixerOverlay = document.getElementById('mixer-overlay');
                if (!mixerOverlay) {
                    console.error('[AudioMixer]: Mixer overlay element not found.');
                    return;
                }

                const isVisible = mixerOverlay.style.display === 'block';
                mixerOverlay.style.display = isVisible ? 'none' : 'block';
            }

            // === Event Listeners ===

            /**
             * Initializes the audio channels and mixer UI once the DOM is fully loaded.
             */
            window.addEventListener('DOMContentLoaded', async () => {
                console.log('[AudioMixer]: DOM fully loaded. Initializing Audio Channels and Mixer UI...');
                await initializeAudioChannels();
                await initializeMixer();
                console.log('[AudioMixer]: Audio Mixer Initialized Successfully.');
            });

            /**
             * Listens for the 'M' key press to toggle the mixer visibility.
             */
            document.addEventListener('keydown', (e) => {
                if (e.key.toLowerCase() === 'm') {
                    toggleMixer();
                }
            });

            // === Utility Functions ===

            /**
             * Logs messages to the console with a consistent prefix.
             * @param {string} message - The message to log.
             */
            function log(message) {
                console.log(`[AudioMixer]: ${message}`);
            }

            /**
             * Displays warnings in the console with a consistent prefix.
             * @param {string} message - The warning message.
             */
            function warn(message) {
                console.warn(`[AudioMixer Warning]: ${message}`);
            }
        </script>
</AudioMixer>


<playback>
    <script>
        // Global variables are defined elsewhere:
        // let isPlaying = false;
        // let isToggleInProgress = false;
        // let isFirstLoopCompleted = false;


        // Only proceed with playback logic after the "Continue" button is pressed
        document.getElementById('continue-button').addEventListener('click', async () => {
            // Ensure data is properly loaded and available for playback
            if (!globalJsonData || !globalJsonData.projectSequences) {
                console.log("Cannot start playback: Song data has not been loaded.");
                return;
            }

            await initializePlayback();
        });

        // Function to start the playback loop
        function startPlaybackLoop() {
            if (globalJsonData && globalJsonData.projectSequences) {
                bpm = globalJsonData.projectBPM;
                const sequenceKeys = Object.keys(globalJsonData.projectSequences);
                totalSequencesInNewSong = sequenceKeys.length;  // Total number of sequences in the song

                console.log(`Starting playback of song with ${totalSequencesInNewSong} sequences.`);

                // Play the first sequence if available
                if (totalSequencesInNewSong > 0) {
                    playSequence(sequenceKeys[currentSequenceIndex]);
                } else {
                    console.error("No sequences found in the project data.");
                }
            } else {
                console.error("Playback cannot start because globalJsonData or projectSequences are undefined.");
            }
        }

        // Function to play a sequence
        function playSequence(sequenceKey) {
            const sequence = globalJsonData.projectSequences[sequenceKey];
            const channels = Object.keys(sequence);

            console.log(`Playing sequence ${sequenceKey} with ${channels.length} channels.`);
            totalStepsInCurrentSequence = channels.reduce((maxSteps, channel) => {
                const steps = sequence[channel].steps || [];
                return Math.max(maxSteps, steps.length); // Find the maximum number of steps in this sequence
            }, 0);

            playNextStep();
        }

        // Function to play the next step in the current sequence
        function playNextStep() {
          if (currentStepIndex < totalStepsInCurrentSequence && isPlaying) {
              // Play the current step for all channels
              console.log(`Playing step ${currentStepIndex + 1}/${totalStepsInCurrentSequence} in sequence ${currentSequenceIndex + 1}/${totalSequencesInNewSong}`);
              currentStepIndex++;

              // Schedule the next step playback based on the BPM and store the timeout ID
              const nextStepTime = 60 / bpm;
              playbackTimeoutId = setTimeout(playNextStep, nextStepTime * 1000);
          } else if (isPlaying) {
              // End of the current sequence
              currentStepIndex = 0;
              currentSequenceIndex++;

              const sequenceKeys = Object.keys(globalJsonData.projectSequences);

              if (currentSequenceIndex < sequenceKeys.length) {
                  // Play the next sequence
                  playSequence(sequenceKeys[currentSequenceIndex]);
              } else {
                  // End of the song; stop playback
                  console.log("Reached the end of the last sequence. Stopping playback.");
                  stopPlayback(); // Call the stopPlayback function to clean up
              }
          }
      }


        // Function to initialize playback
      async function initializePlayback(autoStart = false) {
          if (audioCtx.state === 'suspended') {
              await audioCtx.resume();
              console.log("AudioContext resumed:", audioCtx.state);
          }

          // Reset playback state variables
          currentSequenceIndex = 0;
          currentStepIndex = 0;
          isPlaying = true; // Set playing state to true
          console.log("Starting playback loop from the beginning.");

          // Update Play button to "Stop" and change color to indicate playing
          const playButton = document.getElementById('play-button');
          if (playButton) {
              playButton.textContent = "Stop";
              playButton.classList.add('playing');
          }

          startPlaybackLoop();

          // Start any additional workers or processes needed
          if (typeof startWorker === 'function') {
              startWorker();
          }
      }


        // Function to pause playback
        async function pausePlayback() {
          console.log("Pausing playback.");

          isPlaying = false; // Set playing state to false

          // Clear the scheduled timeout
          if (playbackTimeoutId !== null) {
              clearTimeout(playbackTimeoutId);
              playbackTimeoutId = null;
          }

          // Suspend the audio context to pause playback
          if (audioCtx.state === 'running') {
              await audioCtx.suspend();
              console.log("AudioContext suspended:", audioCtx.state);
          }

          // Update Play button to "Play" and change color back to blue
          const playButton = document.getElementById('play-button');
          if (playButton) {
              playButton.textContent = "Play";
              playButton.classList.remove('playing');
          }
      }


        // Optional: Function to resume playback
        async function resumePlayback() {
            if (audioCtx.state === 'suspended') {
                await audioCtx.resume();
                console.log("AudioContext resumed:", audioCtx.state);
            }

            if (!isPlaying) {
                isPlaying = true;
                console.log("Resuming playback.");
                playNextStep(); // Continue playback from the current step

                // Update Play button to "Stop" and change color to red
                const playButton = document.getElementById('play-button');
                if (playButton) {
                    playButton.textContent = "Stop";
                    playButton.classList.add('playing');
                }
            } else {
                console.log("Playback is already running.");
            }
        }

        // Function to stop playback
        async function stopPlayback() {
          console.log("Stopping playback...");
          isPlaying = false;  // Ensure playback stops

          // Clear the scheduled timeout
          if (playbackTimeoutId !== null) {
              clearTimeout(playbackTimeoutId);
              playbackTimeoutId = null;
          }

          // Stop all active audio sources with fade-out effect
          for (const a in activeSources) {
              activeSources[a].forEach(({ source, gainNode }) => {
                  const currentTime = audioCtx.currentTime;
                  gainNode.gain.cancelScheduledValues(currentTime);
                  gainNode.gain.setValueAtTime(gainNode.gain.value, currentTime);
                  gainNode.gain.linearRampToValueAtTime(0, currentTime + fadeDuration);
                  source.stop(currentTime + fadeDuration);
                  source.disconnect();
                  gainNode.disconnect();
              });
              activeSources[a] = [];
          }

          // Suspend the audio context after stopping playback
          setTimeout(async () => {
              if (audioCtx.state === 'running') {
                  await audioCtx.suspend();
                  console.log("AudioContext suspended:", audioCtx.state);
              }
              resetPlaybackState();  // Ensure the playback state is fully reset
          }, 50);

          // Reset global state variables
          currentSequenceIndex = 0;
          currentStepIndex = 0;
          isFirstLoopCompleted = false; // Reset the loop completion state

          // Update Play button to "Play" and change color back to blue
          const playButton = document.getElementById('play-button');
          if (playButton) {
              playButton.textContent = "Play";
              playButton.classList.remove('playing');
          }
      }


        // Function to toggle playback
        async function togglePlayback() {
            if (!isToggleInProgress) {
                isToggleInProgress = true;
                try {
                    if (isPlaying) {
                        // Stop the playback if it is currently playing
                        await stopPlayback();
                    } else {
                        // Start playback from the beginning or resume if paused
                        await initializePlayback();
                    }
                } catch (error) {
                    console.error("Error during playback toggle:", error);
                } finally {
                    isToggleInProgress = false;
                }
            }
        }

        // Optional: Add a "Resume" button event listener if you implement resume functionality
        document.getElementById('resume-button').addEventListener('click', async () => {
            await resumePlayback();
        });
    </script>
</playback>

    <eventListeners>
    <script>
        // Function to toggle the mixer visibility on one side of the screen
        function toggleMixer() {
            const mixerOverlay = document.getElementById('mixer-overlay');
            const isVisible = mixerOverlay.style.display === 'block';

            if (isVisible) {
                mixerOverlay.style.right = '-50%';  // Slide mixer out
                setTimeout(() => {
                    mixerOverlay.style.display = 'none';  // Hide mixer after sliding out
                }, 300);  // Adjust timing to match CSS transition
            } else {
                mixerOverlay.style.display = 'block';  // Make mixer visible
                setTimeout(() => {
                    mixerOverlay.style.right = '0';  // Slide mixer in from the right
                }, 10);  // Slight delay to allow the transition to apply
            }
        }

        // Listen for 'M' key press to toggle mixer
        document.addEventListener('keydown', (e) => {
            if (e.key === 'm' || e.key === 'M') {
                toggleMixer();
            }
        });

        // Ensure that clicking outside the mixer closes it
        const mixerOverlay = document.getElementById('mixer-overlay');
        mixerOverlay.addEventListener('click', (e) => {
            if (e.target === mixerOverlay) {
                toggleMixer();
            }
        });

        // Stop propagation of clicks inside the mixer container
        const mixerContainer = document.querySelector('.mixer-container');
        mixerContainer.addEventListener('click', (e) => {
            e.stopPropagation();
        });

        // **Modify the global click event to prevent unintended playback toggles**
        document.getElementById('play-button').addEventListener("click", async () => {
            if (typeof window.ensureAudioContextState === "function") {
                try {
                    await window.ensureAudioContextState();
                    await togglePlayback();  // Toggle playback when the button is clicked
                    document.dispatchEvent(new CustomEvent("playbackStarted"));
                } catch (e) {
                    console.error("[eventListeners] Error during playback toggle:", e);
                }
            } else {
                console.error("[eventListeners] ensureAudioContextState is not defined or not a function");
            }
        });

        // Event listeners to handle playback state changes
        document.addEventListener("playbackStarted", () => {
            log("Playback started. Displaying seed.");
            const seedDisplay = document.getElementById("seed-display");
            if (seedDisplay) {
                seedDisplay.textContent = `Seed: ${window.seed}`;
                seedDisplay.style.opacity = "1";
                setTimeout(() => {
                    seedDisplay.style.opacity = "0";
                }, 10000);
            }
            window.psTime = Date.now();
            setPlaybackStatus(true);
            if (typeof displayPlayText === "function") {
                displayPlayText();
            }

            // Hide the "Resume" button when playback starts
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'none';
            }
        });

        document.addEventListener("playbackStopped", () => {
            setPlaybackStatus(false);
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'none';
            }
        });

        document.addEventListener("dataLoadingComplete", () => {
            console.log("Received dataLoadingComplete event. Starting local data processing.");
            processSerializedDataPart2();
        });

        window.addEventListener("load", async () => {
            log("Window load event triggered. Starting app initialization.");
            try {
                await initApp();
                log("initApp function execution complete.");
            } catch (e) {
                console.error("[eventListeners] Error during app initialization:", e);
            }
        });

        document.addEventListener("sequenceUpdated", ({ detail: { currentSequence, currentStep } }) => {
            // Handle sequence updates, if necessary
            console.log(`Sequence updated: Current Sequence: ${currentSequence}, Current Step: ${currentStep}`);
        });

        // Show the "Resume" button when playback is paused
        document.addEventListener("playbackPaused", () => {
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'inline-block';
            }
        });

        // Hide the "Resume" button when playback starts or stops
        document.addEventListener("playbackStarted", () => {
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'none';
            }
        });

        document.addEventListener("playbackStopped", () => {
            const resumeButton = document.getElementById('resume-button');
            if (resumeButton) {
                resumeButton.style.display = 'none';
            }
        });

        // Add this function if it's not already defined
    function log(e) {
        console.log(`[${(new Date).toISOString()}] ${e}`);
    }

    // Event listener for the "Next" button
    document.getElementById('next-seed-button').addEventListener('click', async () => {
        log("Next button clicked. Generating new seed and resetting application.");
        // Generate a new random seed
        window.seed = window.generateRandomSeed();
        log(`New seed generated: ${window.seed}`);
        // Reset the application
        await window.AudioContextManager.resetApp();
    });
    </script>
    </eventListeners>

<audioBuffering>
<script>
function clampVolume(e){return Math.max(0,Math.min(e,3))}function parseVolumeLevel(e){const t="number"==typeof e?e:parseFloat(e);return clampVolume(isNaN(t)?defaultVolume:t)}function calculateReversedTrimTimes(e){return{startTrim:1-e.endTrim,endTrim:1-e.startTrim}}async function resumeAudioContext(){try{await audioCtx.resume(),console.log("AudioContext resumed:",audioCtx.state)}catch(e){console.error("Failed to resume AudioContext:",e)}}async function ensureAudioContextState(){"running"!==audioCtx.state&&await resumeAudioContext(),console.log("AudioContext state:",audioCtx.state)}function resetPlaybackState(){currentSequence=0,currentStep=0,isReversePlay=!1,nextNoteTime=0}function normalizeBuffer(e,t=.9){if(!(e instanceof AudioBuffer))return console.error("Invalid buffer provided to normalizeBuffer."),e;const o=e.numberOfChannels;let a=0;for(let t=0;t<o;t++){const o=e.getChannelData(t);for(let e=0;e<o.length;e++){const t=Math.abs(o[e]);t>a&&(a=t)}}const r=t/a;if(1!==r)for(let t=0;t<o;t++){const o=e.getChannelData(t);for(let e=0;e<o.length;e++)o[e]*=r}return e}async function loadAndNormalizeAudio(e){try{const t=await fetch(e);if(!t.ok)throw new Error(`Network response was not ok for ${e}: ${t.statusText}`);const o=await t.arrayBuffer();return normalizeBuffer(await audioCtx.decodeAudioData(o))}catch(t){throw console.error(`Error loading or decoding audio from ${e}:`,t),t}}async function waitForAudioContext(){if("running"!==audioCtx.state)return new Promise(((e,t)=>{const o=()=>{"running"===audioCtx.state?(audioCtx.removeEventListener("statechange",o),e()):"closed"===audioCtx.state&&(audioCtx.removeEventListener("statechange",o),t(new Error("AudioContext was closed.")))};audioCtx.addEventListener("statechange",o)}))}function playBuffer(e,{startTrim:t,endTrim:o},a,r){if(!e)return void console.error("Invalid audio buffer provided.");if(!(e instanceof AudioBuffer))return void console.error("Provided buffer is not an instance of AudioBuffer.");t=Math.max(0,Math.min(t,1)),o=Math.max(t,Math.min(o,1));const n=normalizeBuffer(e),i=t*n.duration,u=(o-t)*n.duration,c=audioCtx.createBufferSource();c.buffer=n,c.playbackRate.value=globalPlaybackSpeeds[a]||1;const s=audioCtx.createGain(),d=parseVolumeLevel(globalVolumeLevels[a]||defaultVolume)*globalVolumeMultiplier,l=audioCtx.currentTime;s.gain.cancelScheduledValues(l),s.gain.setValueAtTime(0,l),s.gain.linearRampToValueAtTime(d,l+fadeDuration),c.connect(s),s.connect(audioCtx.destination),c.start(r,i,u),activeSources[a]=activeSources[a]||[],activeSources[a].push({source:c,gainNode:s}),c.onended=()=>{activeSources[a]=activeSources[a].filter((e=>e.source!==c))}}const audioBuffers={};async function loadMultipleAudio(e){const t=e.map((async(e,t)=>{try{const o=await loadAndNormalizeAudio(e);audioBuffers[t]=o}catch(e){console.error(`Failed to load audio at index ${t}:`,e)}}));await Promise.all(t)}(async()=>{try{await waitForAudioContext();playBuffer(await loadAndNormalizeAudio(audioUrl),{startTrim:0,endTrim:1},0,audioCtx.currentTime)}catch(e){console.error("Failed to load and play audio:",e)}})();
</script>
</audioBuffering>



<resetVisualState>
<script>
function resetVisualState(){"undefined"!=typeof cci2&&"undefined"!=typeof initialCCI2&&(cci2=initialCCI2),isChannel11Active=!1,isPlaybackActive=!1,activeChannelIndex=null,activeArrayIndex={},renderingState={},"function"==typeof immediateVisualUpdate&&immediateVisualUpdate()}function resetAllStates(){resetPlaybackState(),resetVisualState()}
</script>
</resetVisualState>

<notifyVisualiser>
<script>
    function notifyVisualizer(channelIndex, step) {
        const message = { action: "activeStep", channelIndex, step };
        AudionalPlayerMessages.postMessage(message);
        document.dispatchEvent(new CustomEvent("internalAudioPlayback", { detail: message }));
    }
</script>
</notifyVisualiser>

<prcoessSteps>
<script>
function dispatchSequenceEvent(e,t){document.dispatchEvent(new CustomEvent(e,{detail:t}))}function playSequenceStep(e){if(!isReadyToPlay||!Object.keys(preprocessedSequences).length)return void console.error("Sequence data is not ready or empty.");const t=Object.keys(preprocessedSequences);currentSequence%=t.length;const n=t[currentSequence],o=preprocessedSequences[n];if(0===currentStep&&(console.log(`[${(new Date).toISOString()}] Now playing sequence ${currentSequence}`),globalJsonData&&globalJsonData.channelAdditionLog)){const e=globalJsonData.channelAdditionLog.find((e=>e.sequenceNumber===currentSequence));if(e){const{channelsAdded:t,totalChannels:n}=e;console.log(`Added ${t} channel(s) at sequence ${currentSequence} (total ${n} channels).`)}}o&&Object.keys(o).length&&(playSteps(o.normalSteps,e),playSteps(o.reverseSteps,e,!0)),incrementStepAndSequence(t.length)}function playSteps(e,t,n=!1){if(e&&"object"==typeof e)for(const[o,r]of Object.entries(e))if(Array.isArray(r)){const e=r.find((e=>e.step===currentStep));e&&playChannelStep(o,e,t,n)}else console.error(`[playSteps] Expected steps to be an array for channel "${o}", but got:`,r);else console.error("[playSteps] Invalid steps data:",e)}function playChannelStep(e,t,n,o){const r=globalAudioBuffers.find((t=>t.channel===e)),c=globalTrimTimes[e];if(r?.buffer&&c){const s=o?globalReversedAudioBuffers[e]:r.buffer,u=o?calculateReversedTrimTimes(c):c;playBuffer(s,u,e,n),notifyVisualizer(parseInt(e.slice(8))-1,t.step)}else console.error(`No audio buffer or trim times found for ${e}`)}function scheduleNotes(){const e=audioCtx.currentTime;for(nextNoteTime=Math.max(nextNoteTime,e);nextNoteTime<e+.1;)playSequenceStep(nextNoteTime),audioCtx.currentTime>nextNoteTime&&console.warn(`[scheduleNotes] Note scheduled for ${nextNoteTime.toFixed(3)} missed at ${audioCtx.currentTime.toFixed(3)}.`),nextNoteTime+=getStepDuration()}function incrementStepAndSequence(e){currentStep=(currentStep+1)%64,0===currentStep&&(currentSequence=(currentSequence+1)%e),dispatchSequenceEvent("sequenceUpdated",{currentSequence:currentSequence,currentStep:currentStep})}
</script>
</prcoessSteps>

<audioWebWorkers>
<script>
const LOOKAHEAD=.1,SCHEDULE_INTERVAL=25;let workerUrl,audioWorker,lastBPM;const debounce=(e,o)=>{let r;return(...t)=>{clearTimeout(r),r=setTimeout((()=>e(...t)),o)}},initializeWorker=()=>{if(!window.Worker)return void console.error("[AudioWorker] Web Workers not supported.");if(audioWorker)return void console.warn("[AudioWorker] Worker already initialized.");workerUrl=URL.createObjectURL(new Blob(["\n                self.onmessage = e => {\n                    const { action, stepDuration, lookahead, scheduleInterval } = e.data;\n                    try {\n                        if (action === 'start') {\n                            startScheduling(stepDuration, lookahead, scheduleInterval);\n                        } else if (action === 'stop') {\n                            stopScheduling();\n                        } else if (action === 'updateStepDuration') {\n                            stepDuration = stepDuration;\n                        } else {\n                            console.warn(\"[Worker] Unknown action:\", action);\n                        }\n                    } catch (error) {\n                        self.postMessage({ action: 'error', message: error.message });\n                    }\n                };\n                let stepDuration = 0.25, lookahead = 0.1, scheduleInterval = 25, timerID = null;\n                const startScheduling = (sd, la, si) => {\n                    stepDuration = sd; lookahead = la; scheduleInterval = si;\n                    stopScheduling();\n                    timerID = setInterval(() => self.postMessage({ action: 'scheduleNotes' }), scheduleInterval);\n                };\n                const stopScheduling = () => {\n                    if (timerID) { clearInterval(timerID); timerID = null; }\n                };\n            "],{type:"application/javascript"}));try{audioWorker=new Worker(workerUrl),audioWorker.onmessage=handleWorkerMessage,window.addEventListener("bpmChanged",debounce(updateWorkerStepDuration,100)),console.log("[AudioWorker] Worker initialized.")}catch(e){console.error("[AudioWorker] Initialization failed:",e)}},handleWorkerMessage=e=>{const{action:o,message:r}=e.data;"scheduleNotes"===o?"function"==typeof scheduleNotes?scheduleNotes():console.error("[AudioWorker] 'scheduleNotes' is not defined."):"error"===o?console.error("[AudioWorker] Worker Error:",r):console.warn("[AudioWorker] Unknown action from worker:",o)},startWorker=()=>{if(!audioWorker)return void console.error("[AudioWorker] Initialize worker first.");const e=getStepDuration();audioWorker.postMessage({action:"start",stepDuration:e,lookahead:.1,scheduleInterval:25})},stopWorker=()=>{audioWorker?audioWorker.postMessage({action:"stop"}):console.warn("[AudioWorker] Worker not initialized.")},getStepDuration=()=>{const e=window.globalJsonData?.projectBPM||120;return e!==lastBPM&&(lastBPM=e),60/(4*lastBPM)},cleanUpWorker=async()=>{if(audioWorker&&(audioWorker.postMessage({action:"stop"}),audioWorker.terminate(),audioWorker=null),workerUrl&&(URL.revokeObjectURL(workerUrl),workerUrl=null),"undefined"!=typeof audioCtx&&"closed"!==audioCtx.state)try{await audioCtx.close()}catch(e){console.error("[AudioWorker] Closing AudioContext failed:",e)}window.removeEventListener("bpmChanged",updateWorkerStepDuration),console.log("[AudioWorker] Cleanup completed.")},updateWorkerStepDuration=()=>{if(audioWorker){const e=getStepDuration();audioWorker.postMessage({action:"updateStepDuration",stepDuration:e})}else console.error("[AudioWorker] Initialize worker first.")};window.addEventListener("beforeunload",cleanUpWorker),document.getElementById("loadVisualizerButton")?.addEventListener("click",initializeWorker),document.getElementById("visualizerCanvas")?.addEventListener("click",startWorker);
</script>
</audioWebWorkers>




<loadVisualiserScripts>
<script>
function loadScript(e){return new Promise(((c,t)=>{const a=document.createElement("script");a.src=e,a.onload=c,a.onerror=t,document.body.appendChild(a)}))}async function loadAllScripts(){const e=["/content/c7c92a81d5279950be7d0bd3e755ad620551bc65e6e514d6f7c29b4c24465d0ai0","/content/305829e076d38130be65851c79241929983f16d679822015ff237029f67d5d9ei0","/content/0d8309856ec04e8ab5bd6aa4689429102378fb45368ad0e2787f0dfc72c66152i0","/content/287c837ecffc5b80d8e3c92c22b6dbf0447a3d916b95ee314c66909f6f2b2f3ci0","/content/97c042112c29d9a9ca1da99890542befdbffaec6ff17798897c187a617a62f79i0","/content/3ab9dda407f9c7f62b46401e2664bc1496247c8950620a11a36a8601267cb42fi0","/content/4a6164e05aee1d4ed77585bc85e4d4530801ef71e1c277c868ce374c4a7b9902i0","/content/0505ae5cebbe9513648fc8e4ecee22d9969764f3cdac9cd6ec33be083c77ae96i0","/content/87bb49f5617a241e29512850176e53169c3da4a76444d5d8fcd6c1e41489a4b3i0","/content/cea34b6ad754f3a4e992976125bbd1dd59213aab3de03c9fe2eb10ddbe387f76i0","/content/bcee9a2e880510772f0129c735a4ecea5bb45277f3b99ff640c1bd393dddd6dfi0","/content/90d910fe4088c53a16eb227ec2fe59802091dc4ea51564b2665090403c34f59ci0","/content/916fd1731cdecf82706a290d03448c6dc505c01d6ec44bbca20281a19723d617i0","/content/6a5e5c8b42793dd35512dfddd81dbbe211f052ac79839dd54b53461f5783a390i0","/content/c0ee69121238f6438be8398038301cf5b1d876cce30a0d45a3a5e0b927826940i0","/content/6f1def70a3290c50793773a8b1712c9a1b0561b3674ee50a06c13bc4e492f459i0","/content/99ecc0668e27f03cf202f9ebc49d0332ac8f594bc9b5483969108b83723a0e9di0","/content/214457a4f832847565746ecb0b9460ec7dc8ad93549a00a69f18b3d492c0e005i0"];for(const c of e)await loadScript(c),console.log(`Loaded: ${c}`);console.log("All scripts loaded successfully.")}!async function(){const e=document.createElement("canvas");e.id="cv",document.body.append(e),Object.assign(document.body.style,{display:"flex",justifyContent:"center",alignItems:"center",height:"100vh",margin:"0"});const c=async()=>{window.cci2=0,window.initialCCI2=0,resetAllStates(),loadJsonFromUrl(window.jsonDataUrl),initializeWorker(),await loadAllScripts()};try{await new Promise((e=>{const c=()=>window.jsonDataUrl?e():setTimeout(c,100);c()})),console.log("Fetching from URL:",window.jsonDataUrl);const e=await fetch(window.jsonDataUrl);if(!e.ok)throw new Error(`HTTP error! status: ${e.status}`);window.settings=await e.json(),console.log("Settings loaded:",window.settings),await ensureAudioContextState(),"loading"===document.readyState?document.addEventListener("DOMContentLoaded",c):c()}catch(e){console.error("Error initializing the app:",e)}console.log(`[${(new Date).toISOString()}] [debugScriptLoading] ScriptLoader initialized.`)}();
</script>
</loadVisualiserScripts>
   
<visualizerScripts>
<script>
    // visualizerScript.js

// Define the array of scripts to load globally
window.visualizerScripts = [
  "/content/c7c92a81d5279950be7d0bd3e755ad620551bc65e6e514d6f7c29b4c24465d0ai0",
  "/content/305829e076d38130be65851c79241929983f16d679822015ff237029f67d5d9ei0",
  "/content/0d8309856ec04e8ab5bd6aa4689429102378fb45368ad0e2787f0dfc72c66152i0",
  "/content/287c837ecffc5b80d8e3c92c22b6dbf0447a3d916b95ee314c66909f6f2b2f3ci0",
  "/content/97c042112c29d9a9ca1da99890542befdbffaec6ff17798897c187a617a62f79i0",
  "/content/3ab9dda407f9c7f62b46401e2664bc1496247c8950620a11a36a8601267cb42fi0",
  "/content/4a6164e05aee1d4ed77585bc85e4d4530801ef71e1c277c868ce374c4a7b9902i0",
  "/content/0505ae5cebbe9513648fc8e4ecee22d9969764f3cdac9cd6ec33be083c77ae96i0",
  "/content/87bb49f5617a241e29512850176e53169c3da4a76444d5d8fcd6c1e41489a4b3i0",
  "/content/cea34b6ad754f3a4e992976125bbd1dd59213aab3de03c9fe2eb10ddbe387f76i0",
  "/content/bcee9a2e880510772f0129c735a4ecea5bb45277f3b99ff640c1bd393dddd6dfi0",
  "/content/90d910fe4088c53a16eb227ec2fe59802091dc4ea51564b2665090403c34f59ci0",
  "/content/916fd1731cdecf82706a290d03448c6dc505c01d6ec44bbca20281a19723d617i0",
  "/content/6a5e5c8b42793dd35512dfddd81dbbe211f052ac79839dd54b53461f5783a390i0",
  "/content/c0ee69121238f6438be8398038301cf5b1d876cce30a0d45a3a5e0b927826940i0",
  "/content/6f1def70a3290c50793773a8b1712c9a1b0561b3674ee50a06c13bc4e492f459i0",
  "/content/99ecc0668e27f03cf202f9ebc49d0332ac8f594bc9b5483969108b83723a0e9di0",
  "/content/214457a4f832847565746ecb0b9460ec7dc8ad93549a00a69f18b3d492c0e005i0"
];

/**
 * Dynamically loads a single script.
 * @param {string} src - The source URL of the script to load.
 * @returns {Promise<void>}
 */
function loadScript(src) {
  return new Promise((resolve, reject) => {
    const script = document.createElement("script");
    script.src = src;
    script.async = true; // Optional: Load scripts asynchronously
    script.onload = () => {
      console.log(`Loaded: ${src}`);
      resolve();
    };
    script.onerror = () => {
      console.error(`Failed to load script: ${src}`);
      reject(new Error(`Failed to load script: ${src}`));
    };
    document.body.appendChild(script);
  });
}

/**
 * Loads all required visualizer scripts sequentially.
 * @returns {Promise<void>}
 */
async function loadAllScripts() {
  const scriptUrls = window.visualizerScripts || [];
  for (const url of scriptUrls) {
    try {
      await loadScript(url);
    } catch (error) {
      console.error(`Error loading script ${url}:`, error);
      // Optionally, decide whether to continue loading other scripts or abort
    }
  }
  console.log("All scripts loaded successfully.");
}

/**
 * Initializes the visualizer application.
 */
(async function initializeVisualizer() {
  // Create and configure the canvas element
  const canvas = document.createElement("canvas");
  canvas.id = "cv";
  document.body.appendChild(canvas);
  Object.assign(document.body.style, {
    display: "flex",
    justifyContent: "center",
    alignItems: "center",
    height: "100vh",
    margin: "0"
  });

  /**
   * Core initialization function.
   */
  const coreInit = async () => {
    window.cci2 = 0;
    window.initialCCI2 = 0;

    // Ensure these functions are defined elsewhere in your project
    if (typeof resetAllStates === "function") {
      resetAllStates();
    } else {
      console.warn("Function resetAllStates is not defined.");
    }

    if (typeof loadJsonFromUrl === "function") {
      loadJsonFromUrl(window.jsonDataUrl);
    } else {
      console.warn("Function loadJsonFromUrl is not defined.");
    }

    if (typeof initializeWorker === "function") {
      initializeWorker();
    } else {
      console.warn("Function initializeWorker is not defined.");
    }

    // Load all scripts
    await loadAllScripts();
  };

  try {
    // Wait until window.jsonDataUrl is available
    await new Promise((resolve) => {
      const checkJsonDataUrl = () => {
        if (window.jsonDataUrl) {
          resolve();
        } else {
          setTimeout(checkJsonDataUrl, 100);
        }
      };
      checkJsonDataUrl();
    });

    console.log("Fetching from URL:", window.jsonDataUrl);

    // Fetch and load settings
    const response = await fetch(window.jsonDataUrl);
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    window.settings = await response.json();
    console.log("Settings loaded:", window.settings);

    // Ensure the AudioContext is in the correct state
    if (typeof ensureAudioContextState === "function") {
      await ensureAudioContextState();
    } else {
      console.warn("Function ensureAudioContextState is not defined.");
    }

    // Initialize when the document is ready
    if (document.readyState === "loading") {
      document.addEventListener("DOMContentLoaded", coreInit);
    } else {
      await coreInit();
    }
  } catch (error) {
    console.error("Error initializing the app:", error);
  }

  console.log(`[${new Date().toISOString()}] [debugScriptLoading] ScriptLoader initialized.`);
})();

</script>
</visualizerScripts>

<visualizerLoader>
<script>
// visualizerLoader.js
/**
 * Loader Checker Script
 * 
 * This script checks if there are visualizer scripts to load.
 * If the `window.visualizerScripts` array exists and contains scripts,
 * it ensures that the Visualizer Script (Script A) is loaded
 * before proceeding with initialization.
 * 
 * If no scripts are present, it gracefully skips the visualizer.
 */

// Function to check if the visualizerScripts array exists and is non-empty
function shouldLoadVisualizer() {
  return Array.isArray(window.visualizerScripts) && window.visualizerScripts.length > 0;
}

// Function to dynamically load a script
function loadScript(src) {
  return new Promise((resolve, reject) => {
    const script = document.createElement("script");
    script.src = src;
    script.async = true; // Optional: Load scripts asynchronously
    script.onload = () => {
      console.log(`Loader Checker: Loaded script ${src}`);
      resolve();
    };
    script.onerror = () => {
      console.error(`Loader Checker: Failed to load script ${src}`);
      reject(new Error(`Failed to load script: ${src}`));
    };
    document.body.appendChild(script);
  });
}

// Function to initialize the visualizer if needed
async function initializeVisualizerIfNeeded() {
  if (shouldLoadVisualizer()) {
    console.log("Loader Checker: Visualizer scripts detected. Initializing visualizer...");
    
    // Path to Script A (Visualizer Script)
    const visualizerScriptPath = "/path/to/visualizerScript.js"; // Update this path accordingly

    try {
      await loadScript(visualizerScriptPath);
      console.log("Loader Checker: Visualizer initialized successfully.");
    } catch (error) {
      console.error("Loader Checker: Error initializing visualizer:", error);
    }
  } else {
    console.log("Loader Checker: No visualizer scripts to load. Skipping visualizer initialization.");
  }
}

// Execute the checker once the DOM is fully loaded
if (document.readyState === "loading") {
  document.addEventListener("DOMContentLoaded", initializeVisualizerIfNeeded);
} else {
  initializeVisualizerIfNeeded();
}

</script>
</visualizerLoader>
</body>
</html>