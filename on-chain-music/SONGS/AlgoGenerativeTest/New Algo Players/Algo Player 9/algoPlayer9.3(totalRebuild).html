    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
        <title>? ? ? ? ? ? ?</title>
<script>
            window.seed = 0;  // Default seed
</script>

<script>
// Placeholder function to prevent errors from missing enforceDocumentTitle definition in other files.
// This function might be used to update the document title, but currently does nothing meaningful.
// It is here for future reference in case document title management is needed.
function enforceDocumentTitle() {
    // Placeholder logic to avoid throwing an error in external files that expect this function.
    // If title management is needed in the future, it can be implemented here.
    // console.log("[enforceDocumentTitle] This is a placeholder function to prevent errors.");
}

</script> 

<style>
body, html {
    height: 100%;
    margin: 0;
    display: flex;
    align-items: center;
    justify-content: center;
    background-color: #000000;
    position: relative;
    transform: scale(0.7);
}

body {
    margin: 0;
    padding: 0;
    width: 100%;
    height: 100%;
    overflow: hidden;
    display: flex;
    justify-content: center;
    align-items: center;
}

#canvas-container {
    width: 50vmin;
    height: 50vmin;
    display: flex;
    justify-content: center;
    align-items: center;
    background-color: white;
    position: relative;
}

.text-element, .play-text {
    position: fixed;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    text-align: center;
    z-index: 10001;
    opacity: 1;
    transition: opacity 5s ease-in-out;
}

.play-text {
    font-size: 125px;
    font-style: bold;
    font-weight: 700;
    color: #ff00bf;
    z-index: 10001;
    opacity: 1;
    transition: opacity 30s ease-in-out;
}

.sqyzy {
    font-family: Arial, bold, sans-serif;
    font-size: 96px;
    font-weight: 500;
    color: #000000;
}

.freedom {
    font-size: 125px;
    font-weight: 700;
    font-style: bold;
}

.melophonic {
    font-family: "Trebuchet MS", bold, sans-serif;
    font-size: 65px;
    color: #000;
}

.fade-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: #000;
    z-index: 10000;
    opacity: 1;
    transition: opacity 10s ease-in-out;
}
        
        /* New Styles to Handle Canvas */
        canvas#cv {
            position: absolute; /* Ensure it's not affecting the flow of the document */
            top: 50%; /* Center vertically */
            left: 50%; /* Center horizontally */
            transform: translate(-50%, -50%); /* Translate it back to the center */
            z-index: 9999; /* Place it below the text elements but above other content */
            pointer-events: none; /* Prevent the canvas from intercepting any pointer events */
        }

       /* Styles for the Continue and Reset buttons */
        #continue-button, #reset-button {
            position: fixed;
            right: 10px;
            padding: 10px 20px;
            font-size: 18px;
            font-weight: bold;
            color: white;
            border: none;
            cursor: pointer;
            z-index: 10002;
            transition: background-color 0.3s;
        }

        /* Stack the buttons vertically */
        #continue-button {
            top: 60px; /* Adjust this value as needed for desired spacing */
            background-color: #ff00bf;
        }

        #reset-button {
            top: 10px;
            background-color: #2200ff;
        }

        #continue-button:hover {
            background-color: #ff33c9;
        }

        /* New Styles for Seed Display */
        #seed-display {
            position: fixed;
            bottom: 10px;
            left: 50%;
            transform: translateX(-50%);
            background-color: rgba(255, 255, 255, 0.8);
            padding: 10px 20px;
            border-radius: 8px;
            font-size: 20px;
            color: #000;
            opacity: 0; /* Initially hidden */
            transition: opacity 2s ease-in-out;
            z-index: 10002;
        }

</style>
<!-- Continue button to resume code execution -->
<button id="reset-button">Reset</button>
<button id="continue-button">Continue</button>
<!-- Div to Display Seed -->
<div id="seed-display">Seed: 0</div>
<seedAndInitialise>
    <script>


        const VOLUME_CONTROLS = [   [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // TRUTH
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // On-Chain in the Membrane
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHEESE
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 0.5, 1, 1, 1, 1, 1, 1, 1, 1], // KORA
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHOPPIN' IT UP
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // MLK I HAVE A DREAM
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // ModernProgress
                                    [0.4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 2, 1, 1, 1], // HUMANITY
                                    [0.5, 1, 1, 1, 0.5, 1, 1, 1, 1, 1, 0.7, 0.7, 1, 1, 1, 1, 1], // MintyFresh Vibes
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 1, 1, 1, 1], // ON DAY ONE
                                    [0.25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0.3, 1, 1], // Rhythm and Bass 240
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 0.5, 0.5, 1, 0.01, 1, 1, 1, 1], // Crazy Ass Bitch (Channel 12 muted)
                                    [0.5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Rhythm and Bass 60 
                                ];

        const SPEED_CONTROLS = [    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // TRUTH
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // On-Chain in the Membrane
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHEESE
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // KORA
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // CHOPPIN' IT UP
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // MLK I HAVE A DREAM
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // ModernProgress
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // HUMANITY
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 0.9, 0.9, 1, 1, 1, 1, 1, 1], // MintyFresh Vibes
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // ON DAY ONE
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Rhythm and Bass 240
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Crazy Ass Bitch
                                    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], // Rhythm and Bass 60
                                ];

        let seedSet = false;  // Track seed state
        let arraysInitialized = false;  // Track array initialization state
        let audioElements = []; // Array to hold all audio elements


       // Generate a random seed with up to 16 digits
    function generateRandomSeed() {
        return Math.floor(Math.random() * 1e16);
    }

  // Set the seed; if it's 0, generate a random seed

// Set the seed; if it's 0, generate a random seed
async function setSeed() {
    console.log(`[${new Date().toISOString()}] Starting seed generation...`);
    
    if (window.seed === 0) {
        window.seed = generateRandomSeed();
        console.log(`[${new Date().toISOString()}] New seed generated: ${window.seed}`);
    } else {
        console.log(`[${new Date().toISOString()}] Using existing seed: ${window.seed}`);
    }
    
    seedSet = true;

    // Display the seed in the seed-display div (but delay showing it until playback starts)
    const seedDisplay = document.getElementById('seed-display');

    // Wait for the playback to start to trigger the display and countdown
    document.addEventListener('playbackStarted', () => {
        console.log(`[${new Date().toISOString()}] Playback started. Displaying seed.`);

        seedDisplay.textContent = `Seed: ${window.seed}`;
        seedDisplay.style.opacity = '1';  // Show the seed display

        // Fade out the seed display after 10 seconds
        setTimeout(() => {
            seedDisplay.style.opacity = '0';  // Fade out effect
        }, 10000);  // 10 seconds before fade out
    });

    return window.seed;
}

    // Initialize multiplier arrays
    async function initializeMultiplierArrays() {
        try {
            console.log(`[${new Date().toISOString()}] Multiplier arrays initialized.`);
            arraysInitialized = true;
            return true;
        } catch (error) {
            console.error(`[${new Date().toISOString()}] Error initializing arrays:`, error);
            throw error;
        }
    }

// Pause execution until the Continue button is clicked
function pauseBeforeContinue() {
    return new Promise((resolve) => {
        const continueButton = document.getElementById('continue-button');
        continueButton.style.display = 'block';  // Show the Continue button
        
        // Log the current state of the program before continuing
        console.log(`[${new Date().toISOString()}] Pausing before continuing...`);
        
        // Log AudioContext state
        console.log(`[${new Date().toISOString()}] AudioContext state: ${audioCtx.state}`);
        
        // Log current seed
        console.log(`[${new Date().toISOString()}] Current seed: ${window.seed}`);
        
        // Log multiplier arrays initialization state
        console.log(`[${new Date().toISOString()}] Multiplier arrays initialized: ${arraysInitialized}`);
        
        // Log the state of active audio sources (if any)
        if (activeSources.length > 0) {
            console.log(`[${new Date().toISOString()}] Active audio sources:`);
            activeSources.forEach((source, index) => {
                console.log(`Source ${index}:`, source);
            });
        } else {
            console.log(`[${new Date().toISOString()}] No active audio sources at this moment.`);
        }
        
        // Log any other relevant state variables
        console.log(`[${new Date().toISOString()}] Is Ready to Play: ${isReadyToPlay}`);
        console.log(`[${new Date().toISOString()}] Current step: ${currentStep}`);
        console.log(`[${new Date().toISOString()}] Bar count: ${barCount}`);
        console.log(`[${new Date().toISOString()}] Current sequence: ${currentSequence}`);
        
        // Add the event listener for the "Continue" button
        continueButton.addEventListener('click', () => {
            continueButton.style.display = 'none';  // Hide the button after it's clicked
            
            // Log the point where the user clicked "Continue"
            console.log(`[${new Date().toISOString()}] Continue button clicked. Resuming execution...`);
            
            resolve();
        }, { once: true });  // Ensure the event only fires once
    });
}

// Main initialization function (executed step by step)
async function initApp() {
    console.log(`[${new Date().toISOString()}] App initialization started.`);

    // Step 1: Set seed
    console.log(`[${new Date().toISOString()}] Setting seed...`);
    await setSeed();
    console.log(`[${new Date().toISOString()}] Seed set successfully.`);

    // Step 2: Initialize multiplier arrays
    console.log(`[${new Date().toISOString()}] Initializing multiplier arrays...`);
    await initializeMultiplierArrays();
    console.log(`[${new Date().toISOString()}] Multiplier arrays initialized successfully.`);

    // Step 3: Pause and wait for user input (Continue button)
    console.log(`[${new Date().toISOString()}] Pausing for user to click the "Continue" button.`);
    await pauseBeforeContinue();
    console.log(`[${new Date().toISOString()}] Continue button clicked. Proceeding with app initialization.`);

    // Step 4: Proceed with the remaining app initialization
    console.log(`[${new Date().toISOString()}] Proceeding to init function for core logic...`);
    init();  // Call the main app logic here after the Continue button is pressed
}
</script>
</seedAndInitialise>

<loadSongFiles>
<script>
    // Init function, which contains the main application logic
    function init() {
        console.log(`[${new Date().toISOString()}] init function called. Preparing to process song data URLs...`);
        
        const songDataUrls = [
            "/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0", // TRUTH
            "/content/b22f1c85371b58a9cdac19b2baa50b1f9025a28d44cdfaad539d0527aa7d894ei0", // On-Chain in the Membrane
            "/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0", // CHEESE
            "/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", // KORA
            "/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0", // CHOPPIN' IT UP
            "/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0", // MLK I HAVE A DREAM
            "/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0", // ModernProgress
            "/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0", // HUMANITY
            "/content/3359ce42359274ddbd2184d9f75a38b7e59b1d5f24512959e29c377fc8ca604ai0", // MintyFresh Vibes
            "/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0", // ON DAY ONE
            "/content/85436950f53c57aa0c510071d2d5f1c187e1d21e4e57210fcae152c4c7b6a768i0", // Rhythm and Bass 240
            "/content/e3ca12dd7516b4e486af4e3fa7f4ebc535d825034ff3c9da4954f354572dcf61i0", // Crazy Ass Bitch
            "/content/d0496a8e1657ce470807c8d47dcb5f1018a32d8ec8e50d490ad49411ffee1457i0", // Rhythm and Bass 60
        ];


        // Logging the length of songDataUrls array
            console.log(`[${new Date().toISOString()}] Found ${songDataUrls.length} song data URLs to process.`);

        // Checking if there are song data URLs to process
        if (songDataUrls.length > 0) {
            console.log(`[${new Date().toISOString()}] Beginning processing of songDataUrls...`);
            processSerializedData(songDataUrls, VOLUME_CONTROLS, SPEED_CONTROLS);
        } else {
            console.warn(`[${new Date().toISOString()}] songDataUrls array is empty. No data to process.`);
        }

        console.log(`[${new Date().toISOString()}] init function execution complete.`);
        }


    // On window load, trigger the initial app setup
        window.addEventListener("load", async () => {
            console.log(`[${new Date().toISOString()}] Window load event triggered. Starting app initialization.`);
            await initApp();  // Start the initialization process
            console.log(`[${new Date().toISOString()}] initApp function execution complete.`);
        });

</script>
</loadSongFiles>
    </head>
     
    <body>
        <script>
    async function safeSuspendAudioContext() {
        console.log(`[${new Date().toISOString()}] [safeSuspendAudioContext] AudioContext state: ${audioCtx.state}`);
        
        if (audioCtx.state === 'running') {
            console.log(`[${new Date().toISOString()}] Suspending AudioContext...`);
            await audioCtx.suspend();
            console.log(`[${new Date().toISOString()}] AudioContext suspended. State: ${audioCtx.state}`);
        } else if (audioCtx.state === 'suspended') {
            console.log(`[${new Date().toISOString()}] AudioContext is already suspended.`);
        } else if (audioCtx.state === 'closed') {
            console.warn(`[${new Date().toISOString()}] AudioContext is closed, cannot suspend.`);
        }
    }

            
    async function stopPlayback() {
        Object.keys(activeSources).forEach(a => {
            activeSources[a].forEach(({ source, gainNode }) => {
                gainNode.gain.cancelScheduledValues(audioCtx.currentTime);
                gainNode.gain.setValueAtTime(gainNode.gain.value, audioCtx.currentTime);
                gainNode.gain.linearRampToValueAtTime(0, audioCtx.currentTime + fadeDuration);
                source.stop(audioCtx.currentTime + fadeDuration);
                source.disconnect();
                gainNode.disconnect();
            });
            activeSources[a] = [];
        });

        // Delay suspension to allow fade-out
        setTimeout(async () => {
            // Safely suspend the AudioContext using our wrapper
            if (audioCtx.state !== 'closed') { // Ensure we're not suspending a closed AudioContext
                await safeSuspendAudioContext();
            }
            resetPlaybackState();
        }, 50);
    }


    !function () {
    if (!window.AudioContextManager) {
        class AudioContextManager {
            constructor() {
                if (!AudioContextManager.instance) {
                    // Initialize without AudioContext initially, assign to global `audioCtx` variable
                    window.audioCtx = null;
                    console.log(`[constructor] AudioContextManager initialized with no AudioContext.`);
                    AudioContextManager.instance = this;
                }
                return AudioContextManager.instance;
            }

            // Initialize the AudioContext when needed
            initializeAudioContext() {
                if (!window.audioCtx || window.audioCtx.state === "closed") {
                    window.audioCtx = new (window.AudioContext || window.webkitAudioContext)();
                    this.registerStateChangeListener();
                    console.log(`[initializeAudioContext] New AudioContext created. State: ${window.audioCtx.state}`);
                }
            }

            getAudioContext() {
                // Ensure AudioContext is initialized before returning it
                if (!window.audioCtx) {
                    this.initializeAudioContext();
                }
                return window.audioCtx;
            }

            // Log state changes to track AudioContext transitions
            registerStateChangeListener() {
                if (window.audioCtx) {
                    window.audioCtx.onstatechange = () => {
                        console.log(`[AudioContext state change] New state: ${window.audioCtx.state}`);
                    };
                }
            }

            // Resume the AudioContext if suspended, reset if closed
            async resume() {
                this.initializeAudioContext(); // Ensure AudioContext exists

                if (window.audioCtx.state === "suspended") {
                    console.log(`[resume] AudioContext is suspended, resuming...`);
                    await window.audioCtx.resume();
                    console.log(`[resume] AudioContext resumed. Current state: ${window.audioCtx.state}`);
                } else if (window.audioCtx.state === "running") {
                    console.log(`[resume] AudioContext is already running. No action needed.`);
                } else if (window.audioCtx.state === "closed") {
                    console.log(`[resume] AudioContext is closed, resetting...`);
                    await this.resetAudioContext();
                }
            }

            // Safely suspend the AudioContext if it is running
            async suspend() {
                console.log(`[suspend] Attempting to suspend. Current state: ${window.audioCtx?.state}`);

                if (window.audioCtx && window.audioCtx.state === "running") {
                    await window.audioCtx.suspend();
                    console.log(`[suspend] AudioContext suspended. Current state: ${window.audioCtx.state}`);
                } else if (window.audioCtx && window.audioCtx.state === "suspended") {
                    console.log(`[suspend] AudioContext is already suspended.`);
                } else {
                    console.warn(`[suspend] AudioContext is closed or not initialized. Cannot suspend.`);
                }
            }

            // Reset the AudioContext if closed, ensuring it resumes properly
            async resetAudioContext() {
                console.log(`[resetAudioContext] Current AudioContext state: ${window.audioCtx?.state}`);

                // Only close the context if it's not already closed
                if (window.audioCtx && window.audioCtx.state !== "closed") {
                    await window.audioCtx.close();
                    console.log(`[resetAudioContext] AudioContext closed.`);
                }

                // Recreate the AudioContext
                this.initializeAudioContext();
                console.log(`[resetAudioContext] New AudioContext created. State: ${window.audioCtx.state}`);

                // Ensure the new AudioContext is running (resume if needed)
                if (window.audioCtx.state === "suspended") {
                    console.log(`[resetAudioContext] New AudioContext is suspended, resuming...`);
                    await window.audioCtx.resume();
                    console.log(`[resetAudioContext] New AudioContext resumed. State: ${window.audioCtx.state}`);
                }
            }

            // Completely reset the manager (called when the reset button is pressed)
            async resetApp() {
                console.log(`[resetApp] Resetting the entire application state.`);
                window.seed += 1;  // Increment the seed
                console.log(`[resetApp] New seed: ${window.seed}`);

                // Reset AudioContext
                await this.resetAudioContext();

                // Clear other global states (arrays, audio elements, etc.)
                window.audioElements = [];
                window.activeSources = [];
                window.arraysInitialized = false;
                window.isReadyToPlay = false;
                console.log(`[resetApp] Application reset complete.`);

                // Re-initialize the app
                await initApp();  // Call initApp function to reinitialize the app
            }
        }

        window.AudioContextManager = new AudioContextManager();
    }
}();

// Attach the reset functionality to the reset button
document.getElementById('reset-button').addEventListener('click', async () => {
    console.log(`[Reset Button Clicked] Resetting the app...`);
    await window.AudioContextManager.resetApp();
});




            
            </script>
            
            <script>
            let globalVolumeMultiplier = 1;
            let globalJsonData = null;
            let bpm = 0;
            const sourceChannelMap = new Map();
            let globalTrimTimes = {};
            let globalVolumeLevels = {};
            let globalPlaybackSpeeds = {};
            let activeSources = [];
            let globalGainNodes = new Map();
            let globalAudioBuffers = [];
            let globalReversedAudioBuffers = {};
            let isReversePlay = false;
            let isToggleInProgress = false;
            const gainNodes = {};
            const audioCtx = window.AudioContextManager.getAudioContext();
            
            let audioWorker;
            let preprocessedSequences = {};
            let isReadyToPlay = false;
            let currentStep = 0;
            let beatCount = 0;
            let barCount = 0;
            let currentSequence = 0;
            let isPlaying = false;
            let playbackTimeoutId = null;
            let nextNoteTime = 0;
            let totalSequences = 0;
            
            const AudionalPlayerMessages = new BroadcastChannel("channel_playback");
            
          
            </script>
            

     <script>
        async function fetchAndProcessAudioData(e){await Promise.all(e.map(((e,t)=>processAudioUrl(e,t+1,audioCtx)))),createReversedBuffersForChannelsWithReverseSteps()}function getOrCreateGainNode(e){return gainNodes[e]||(gainNodes[e]=audioCtx.createGain(),gainNodes[e].connect(audioCtx.destination)),gainNodes[e]}async function processAudioUrl(e,t,r){try{const o=await fetch(e);if(!o.ok)throw new Error(`Failed to fetch from URL: ${e}, Status: ${o.status}`);const a=o.headers.get("Content-Type"),n=await fetchAndDecodeAudio(o,a,r);if(n){const e=`Channel ${t}`,r=getOrCreateGainNode(e),o=parseVolumeLevel(globalVolumeLevels[e])*globalVolumeMultiplier;r.gain.value=o,globalAudioBuffers.push({buffer:n,gainNode:r,channel:e})}else console.error(`Failed to decode audio for ${channelName}:`,e)}catch(e){console.error(`Error processing audio URL for ${channelName}:`,e)}}function setGlobalVolumeMultiplier(e){globalVolumeMultiplier=Math.max(0,e),globalAudioBuffers.forEach((({gainNode:e,channel:t})=>{const r=parseVolumeLevel(globalVolumeLevels[t]);e.gain.value=r*globalVolumeMultiplier}))}async function fetchAndDecodeAudio(e,t,r){if(/audio\/(wav|mpeg|mp4)/.test(t)||/video\/mp4/.test(t)){const t=await e.arrayBuffer();return r.decodeAudioData(t)}const o=await e.text();let a=null;if(/application\/json/.test(t)?a=JSON.parse(o).audioData:/text\/html/.test(t)&&(a=extractBase64FromHTML(o)),a){const e=base64ToArrayBuffer(a.split(",")[1]);return r.decodeAudioData(e)}if(/audio\//.test(t)){const t=await e.arrayBuffer();return r.decodeAudioData(t)}return null}function createReversedBuffersForChannelsWithReverseSteps(){const e=new Set;for(const t of Object.values(globalJsonData.projectSequences))for(const[r,o]of Object.entries(t))o.steps.some((e=>e.reverse))&&e.add(`Channel ${parseInt(r.slice(2))+1}`);globalAudioBuffers.forEach((({buffer:t,channel:r})=>{e.has(r)&&(globalReversedAudioBuffers[r]=createReversedBuffer(t))}))}function createReversedBuffer(e){const t=audioCtx.createBuffer(e.numberOfChannels,e.length,e.sampleRate);for(let r=0;r<e.numberOfChannels;r++){const o=e.getChannelData(r);t.getChannelData(r).set([...o].reverse())}return t}function base64ToArrayBuffer(e){try{const t=window.atob(e),r=t.length,o=new Uint8Array(r);for(let e=0;e<r;e++)o[e]=t.charCodeAt(e);return o.buffer}catch(e){return console.error("[base64ToArrayBuffer] Error converting base64 to ArrayBuffer:",e),null}}function extractBase64FromHTML(e){try{const t=new DOMParser,r=t.parseFromString(e,"text/html").querySelector("audio[data-audionalSampleName] source");if(r){const e=r.getAttribute("src");if(/^data:audio\/(wav|mp3|mp4);base64,/.test(e.toLowerCase()))return e;if(/audio\//.test(e.toLowerCase()))return e;console.error("[extractBase64FromHTML] Audio data does not start with expected base64 prefix.")}else console.error("[extractBase64FromHTML] Could not find the audio source element in the HTML content.")}catch(e){console.error("[extractBase64FromHTML] Error parsing HTML content:",e)}return null}
        console.log("Audio processing script loaded.");

    // Function to load JSON data from a URL
    async function loadJsonFromUrl(url) {
        try {
            const response = await fetch(url);
            if (!response.ok) {
                throw new Error(`HTTP error! Status: ${response.status}`);
            }

            globalJsonData = await response.json();
            
            const analysisResults = {
                channelsWithUrls: 0,
                sequencesCount: 0,
                activeStepsPerSequence: {},
                activeChannelsPerSequence: {},
                types: {}
            };

            analyzeJsonStructure(globalJsonData, analysisResults);

            const preparedData = prepareForPlayback(globalJsonData, analysisResults);
            await fetchAndProcessAudioData(preparedData.channelURLs);
            preprocessAndSchedulePlayback(preparedData);

        } catch (error) {
            console.error("Could not load JSON data from URL:", error);
        }
    }

    // Analyze JSON structure to gather statistics and other details
    function analyzeJsonStructure(jsonData, analysisResults) {
        if (jsonData.projectSequences && typeof jsonData.projectSequences === "object") {
            for (const [sequenceKey, sequenceData] of Object.entries(jsonData.projectSequences)) {
                analysisResults.activeStepsPerSequence[sequenceKey] = 0;
                analysisResults.activeChannelsPerSequence[sequenceKey] = [];

                for (const [channelKey, channelData] of Object.entries(sequenceData)) {
                    const channelName = `Channel ${parseInt(channelKey.slice(2)) + 1}`;
                    analysisResults.activeStepsPerSequence[sequenceKey] += channelData.steps.length;
                    analysisResults.activeChannelsPerSequence[sequenceKey].push(channelName);
                }
            }
        }

        for (const [key, value] of Object.entries(jsonData)) {
            if (key !== "projectSequences") {
                const valueType = Array.isArray(value) ? "array" : typeof value;
                analysisResults.types[valueType] = (analysisResults.types[valueType] || 0) + 1;

                if (valueType === "object" || valueType === "array") {
                    analyzeJsonStructure(value, analysisResults);
                }
            }
        }
    }

    // Set the last non-empty sequence as the end sequence
    function findAndSetEndSequence(data) {
        if (data && data.sequences) {
            let lastNonEmptySequence = null;
            let isEndSequenceSet = false;

            for (const [sequenceKey, sequenceData] of Object.entries(data.sequences)) {
                const isSequenceEmpty = Object.values(sequenceData.normalSteps).every(steps => steps.length === 0);

                if (isSequenceEmpty && lastNonEmptySequence) {
                    data.endSequence = lastNonEmptySequence;
                    isEndSequenceSet = true;
                    console.log("End sequence set to:", lastNonEmptySequence);
                    break;
                }

                if (!isSequenceEmpty) {
                    lastNonEmptySequence = sequenceData;
                }
            }

            if (!isEndSequenceSet && lastNonEmptySequence) {
                data.endSequence = lastNonEmptySequence;
                console.log("End sequence set to the last non-empty sequence:", lastNonEmptySequence);
            }
        }
    }

    // Prepare the data for playback
    function prepareForPlayback(jsonData, analysisResults) {
        const { channelURLs, trimSettings, channelVolume, channelPlaybackSpeed, projectSequences, projectName, projectBPM, currentSequence } = jsonData;

        bpm = projectBPM;
        totalSequences = currentSequence;
        globalTrimTimes = {};
        globalVolumeLevels = {};
        globalPlaybackSpeeds = {};

        channelURLs.forEach((url, index) => {
            const channelIndex = index + 1;
            const trimSetting = trimSettings[index] || {};
            
            globalTrimTimes[`Channel ${channelIndex}`] = {
                startTrim: Number((trimSetting.startSliderValue || 0) / 100).toFixed(3),
                endTrim: Number((trimSetting.endSliderValue || 100) / 100).toFixed(3),
            };

            globalVolumeLevels[`Channel ${channelIndex}`] = Number(channelVolume[index] || 1).toFixed(3);
            globalPlaybackSpeeds[`Channel ${channelIndex}`] = Number(Math.max(0.1, Math.min(channelPlaybackSpeed[index], 100)) || 1).toFixed(3);
        });

        logVolumeSettings();

        const sequences = Object.entries(projectSequences).reduce((result, [sequenceKey, sequenceData]) => {
            const normalSteps = {};
            const reverseSteps = {};

            Object.entries(sequenceData).forEach(([channelKey, channelData]) => {
                const channelName = `Channel ${parseInt(channelKey.slice(2)) + 1}`;
                normalSteps[channelName] = [];
                reverseSteps[channelName] = [];

                channelData.steps.forEach(step => {
                    const stepIndex = typeof step === "object" ? step.index : step;
                    if (step.reverse) {
                        reverseSteps[channelName].push(stepIndex);
                    } else {
                        normalSteps[channelName].push(stepIndex);
                    }
                });
            });

            result[sequenceKey] = { normalSteps, reverseSteps };
            return result;
        }, {});

        const playbackData = {
            projectName,
            bpm: projectBPM,
            channels: channelURLs.length,
            channelURLs,
            trimTimes: globalTrimTimes,
            stats: {
                channelsWithUrls: analysisResults.channelsWithUrls,
                sequencesCount: analysisResults.sequencesCount,
                activeStepsPerSequence: analysisResults.activeStepsPerSequence,
                activeChannelsPerSequence: analysisResults.activeChannelsPerSequence,
            },
            sequences,
        };

        findAndSetEndSequence(playbackData);
        return playbackData;
    }

    // Preprocess steps for scheduling playback
    function preprocessAndSchedulePlayback(playbackData) {
        if (!playbackData || !playbackData.sequences) {
            return console.error("Playback data is not available or empty.");
        }

        bpm = playbackData.bpm;
        preprocessedSequences = Object.fromEntries(
            Object.entries(playbackData.sequences).map(([sequenceKey, sequenceData]) => [
                sequenceKey,
                {
                    normalSteps: processSteps(sequenceData.normalSteps),
                    reverseSteps: processSteps(sequenceData.reverseSteps),
                },
            ])
        );

        isReadyToPlay = Object.values(preprocessedSequences).some(
            sequence => Object.keys(sequence.normalSteps).length > 0 || Object.keys(sequence.reverseSteps).length > 0
        );
    }

    // Process steps to calculate timing
    function processSteps(steps) {
        return Object.fromEntries(
            Object.entries(steps)
                .filter(([, stepArray]) => Array.isArray(stepArray) && stepArray.length)
                .map(([channel, stepArray]) => [
                    channel,
                    stepArray.map(step => ({
                        step,
                        timing: Number(step * (60 / bpm)).toFixed(3),
                    })),
                ])
        );
    }

    // Log volume settings for debugging
    function logVolumeSettings() {
        for (const [channel, volume] of Object.entries(globalVolumeLevels)) {
            // Log volume levels for each channel
        }
    }
</script>



    <dataProcessingUtilities>
        <!-- <script src="/content/a802ec5558216e754e927a24b2b8b87180339a7a7cbf9d19d36bd6a6acd9846bi0"></script> -->
    <script>
    // Hashing and dataProcessingUtilities.js - Inscribed - a802ec5558216e754e927a24b2b8b87180339a7a7cbf9d19d36bd6a6acd9846bi0
    function hashString(e){console.log(`[${(new Date).toISOString()}] hashString function called with input:`,e);const t=parseInt(e.split("i")[1]);console.log(`[${(new Date).toISOString()}] Rotation count parsed:`,t),e=e.slice(t)+e.slice(0,t),console.log(`[${(new Date).toISOString()}] String after rotation:`,e);let n=0;for(let t=0;t<e.length;t++)n=(31*n+e.charCodeAt(t))%Number.MAX_SAFE_INTEGER;const a=n%14e8;return console.log(`[${(new Date).toISOString()}] Final hash calculated:`,a),a}const seedValue=hashString("4482324585393f1523e8c28a02605c0b1c95d2779510921da0f131a5e6da5843i0");function seededRandom(e){const t=1e4*Math.sin(e);return t-Math.floor(t)}function setPlaybackStatus(e){window.playbackStarted=e}function initializePlayback(){void 0===window.playbackStarted&&(window.playbackStarted=!1),document.addEventListener("playbackStarted",(()=>{window.psTime=Date.now(),setPlaybackStatus(!0),"function"==typeof displayPlayText&&displayPlayText()})),document.addEventListener("playbackStopped",(()=>{setPlaybackStatus(!1)}))}console.log(`[${(new Date).toISOString()}] Hash string returned seed value:`,seedValue);const keyMap={0:"projectName",1:"artistName",2:"projectBPM",3:"currentSequence",4:"channelURLs",5:"channelVolume",6:"channelPlaybackSpeed",7:"trimSettings",8:"projectChannelNames",9:"startSliderValue",10:"endSliderValue",11:"totalSampleDuration",12:"start",13:"end",14:"projectSequences",15:"steps"},reverseKeyMap=Object.fromEntries(Object.entries(keyMap).map((([e,t])=>[t,+e]))),channelMap=Array.from({length:26},((e,t)=>String.fromCharCode(65+t))),reverseChannelMap=Object.fromEntries(channelMap.map(((e,t)=>[e,t])));function decompressSteps(e){return e.flatMap((e=>{if("number"==typeof e)return e;if("object"==typeof e&&"r"in e){const[t,n]=e.r;return Array.from({length:n-t+1},((e,n)=>t+n))}return"string"==typeof e&&e.endsWith("r")?{index:parseInt(e.slice(0,-1),10),reverse:!0}:void 0}))}function deserialize(e){const t=e=>Array.isArray(e)?e.map((e=>"object"==typeof e?t(e):e)):"object"==typeof e&&null!==e?Object.entries(e).reduce(((e,[n,a])=>{const o=keyMap[n]??n;return e[o]="projectSequences"===o?Object.entries(a).reduce(((e,[t,n])=>(e[t.replace("s","Sequence")]=Object.entries(n).reduce(((e,[t,n])=>(e[`ch${reverseChannelMap[t]}`]={steps:decompressSteps(n[reverseKeyMap.steps]||[])},e)),{}),e)),{}):t(a),e}),{}):e;return t(e)}initializePlayback(),window.onload=function(){console.log(`[${(new Date).toISOString()}] window.onload triggered.`)},console.log(`[${(new Date).toISOString()}] ProcessingUtilities initialized.`);
    </script>
    </dataProcessingUtilities>

    <dataProcessingCore>
    <script>
    // loadPako and deserialise functions <dataProcessingCore> inscribed - 01341644e144bba44e6da53bc9ce2f4d29299e24a39e934cbc2d2eb81dd8eb7fi0
        async function loadPako(){
        try{
            const e=await fetch("/content/2109694f44c973892fb8152cf5c68607fb19288c045af1abc1716c1c3b4d69e6i0"),
            t=await e.text(),
            n=(new DOMParser).parseFromString(t,"text/html").querySelector("script");
            if(!n||!n.textContent.includes("pako")) throw new Error("Pako library not found in the HTML content.");
            document.head.append(Object.assign(document.createElement("script"),{textContent:n.textContent}));
        } catch(e){
            console.error("Error occurred during Pako loading:",e);
        }
    }

    async function fetchAndDeserialize(e){
        try{
            const t=await fetch(e);
            if(!t.ok) throw new Error(`Network response was not ok for URL: ${e}`);
            const n=await t.arrayBuffer(), 
                r=pako.inflate(new Uint8Array(n));
            return deserialize(JSON.parse(new TextDecoder("utf-8").decode(r)));
        } catch(e){
            throw console.error("Error in fetchAndDeserialize:",e),e;
        }
    }

    /**
     * Shuffles an array in place using a seeded random function.
     * @param {Array} array - The array to shuffle.
     * @param {number} seed - The seed value for consistent shuffling.
     * @returns {Array} - The shuffled array.
     */
    function shuffleArray(array, seed) {
        for (let i = array.length - 1; i > 0; i--) {
            const j = Math.floor(seededRandom(seed++) * (i + 1));
            [array[i], array[j]] = [array[j], array[i]];
        }
        console.log(`[${new Date().toISOString()}] After shuffling - Playback Speeds:`, array.map(item => item.speed), "Trim Settings:", array.map(item => item.trim));
        return array;
    }


    const BPM_VALUES = [80, 100, 120, 140, 160, 180, 240];

    /**
     * Selects a BPM value based on a seeded random function.
     * @param {number} seed - The seed value for consistent BPM selection.
     * @returns {number} - The selected BPM value.
     */
    function selectBPM(seed) {
        return BPM_VALUES[Math.floor(seededRandom(seed) * BPM_VALUES.length)];
    }


    /**
     * Fetches and processes data from a list of URLs.
     * @param {Array<string>} songDataUrls - Array of URLs to fetch data from.
     * @returns {Array<Object>} - Array of deserialized and validated data.
     * @throws {Error} - Throws an error if no valid data is processed.
     */
    async function fetchAndProcessData(songDataUrls) {
        const deserializedDataPromises = songDataUrls.map(async (url) => {
            try {
                const data = await fetchAndDeserialize(url);
                if (!data?.projectSequences) throw new Error(`Invalid data at URL ${url}`);
                console.log(`[${new Date().toISOString()}] Data fetched and deserialized for URL: ${url}`);
                return data;
            } catch (error) {
                console.error("Error processing URL:", error);
                return null;
            }
        });

        const deserializedDataResults = await Promise.all(deserializedDataPromises);
        const deserializedData = deserializedDataResults.filter(data => data !== null);

        if (!deserializedData.length) throw new Error("No valid data was processed.");

        return deserializedData;
    }
    /**
     * Adjusts channel playback speeds, trim settings, and volumes.
     * @param {Object} data - The song data object to adjust.
     * @param {number} dataIndex - Index of the song data in the array.
     * @param {number} selectedBPM - The BPM selected for this processing run.
     * @param {Array<Array<number>>} VOLUME_CONTROLS - The volume controls for each song and channel.
     * @param {Array<Array<number>>} SPEED_CONTROLS - The speed controls for each song and channel.
     * @param {string} songId - The ID or name of the song (extracted from the URL).
     */
    function adjustChannelData(data, dataIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS, songId) {
        const adjustmentFactor = selectedBPM / data.projectBPM;
        console.log(`[${new Date().toISOString()}] Adjustment Factor for song (${songId}): ${adjustmentFactor}`);

        data.channelPlaybackSpeed = data.channelPlaybackSpeed.map((speed, channelIndex) => {
            const speedControlMultiplier = SPEED_CONTROLS[dataIndex][channelIndex] || 1; // Use 1 as default if not specified
            const adjustedSpeed = speed * adjustmentFactor * speedControlMultiplier;
            console.log(`[${new Date().toISOString()}] Channel ${channelIndex} (Song: ${songId}): Original Speed: ${speed}, Speed Control Multiplier: ${speedControlMultiplier}, Adjusted Speed: ${adjustedSpeed}`);

            let trim = data.trimSettings[channelIndex] || { startSliderValue: 0, endSliderValue: 100 };
            const originalDuration = trim.endSliderValue - trim.startSliderValue;

            const adjustedDuration = adjustedSpeed > speed
                ? originalDuration / adjustedSpeed
                : originalDuration * (speed / adjustedSpeed);

            if (!isNaN(adjustedDuration) && adjustedDuration > 0) {
                trim.endSliderValue = Math.min(Math.max(trim.startSliderValue + adjustedDuration, 0), 100);
                console.log(`[${new Date().toISOString()}] Channel ${channelIndex} (Song: ${songId}): Adjusted Trim Start: ${trim.startSliderValue}, Adjusted Trim End: ${trim.endSliderValue}`);
            } else {
                console.warn(`[${new Date().toISOString()}] Channel ${channelIndex} (Song: ${songId}): Adjusted duration invalid or zero. Using default trim settings.`);
                trim = { startSliderValue: 0, endSliderValue: 100 };
            }

            return adjustedSpeed;
        });

        const volumeControls = VOLUME_CONTROLS[dataIndex] || [];
        const masterVolumeMultiplier = volumeControls[0] || 1;

        data.channelVolume = data.channelVolume.map((volume, channelIndex) => {
            const channelVolumeMultiplier = volumeControls[channelIndex + 1] || 1;
            const adjustedVolume = volume * masterVolumeMultiplier * channelVolumeMultiplier;
            console.log(`[${new Date().toISOString()}] Channel ${channelIndex} (Song: ${songId}): Original Volume: ${volume}, Adjusted Volume: ${adjustedVolume}`);
            return adjustedVolume;
        });

        console.log(`[${new Date().toISOString()}] After Adjustment for song (${songId}) - Playback Speeds:`, data.channelPlaybackSpeed, "Trim Settings:", data.trimSettings, "Volumes:", data.channelVolume);
    }

    /**
     * Assembles the processed song object after adjusting channels.
     * @param {Array<Object>} deserializedData - Array of deserialized and adjusted song data.
     * @param {number} selectedBPM - The BPM selected for this processing run.
     * @returns {Object} - The final processed song object.
     */
    function assembleProcessedSong(deserializedData, selectedBPM) {
        const flattenedChannels = deserializedData.flatMap((data, dataIndex) =>
            data.channelURLs.map((url, channelIndex) => ({
                url,
                volume: data.channelVolume[channelIndex],
                speed: data.channelPlaybackSpeed[channelIndex],
                trim: data.trimSettings[channelIndex],
                source: `data${dataIndex + 1}`,
                index: channelIndex
            }))
        );

        const shuffledChannels = shuffleArray(flattenedChannels, window.seed).slice(0, 24);

        console.log(`[${new Date().toISOString()}] Selected 24 Channels - Playback Speeds:`,
            shuffledChannels.map(channel => channel.speed),
            "Trim Settings:",
            shuffledChannels.map(channel => channel.trim)
        );

        const processedSong = {
            ...deserializedData[0],
            projectBPM: selectedBPM,
            channelURLs: shuffledChannels.map(channel => channel.url),
            channelVolume: shuffledChannels.map(channel => channel.volume),
            channelPlaybackSpeed: shuffledChannels.map(channel => channel.speed),
            trimSettings: shuffledChannels.map(channel => channel.trim),
            projectSequences: {}
        };

        const dataSourceMap = deserializedData.reduce((acc, data, index) => ({
            ...acc,
            [`data${index + 1}`]: data
        }), {});

        for (const sequenceKey in deserializedData[0].projectSequences) {
            processedSong.projectSequences[sequenceKey] = {};
            shuffledChannels.forEach((channel, newIndex) => {
                const originalSequence = dataSourceMap[channel.source]?.projectSequences[sequenceKey];
                processedSong.projectSequences[sequenceKey][`ch${newIndex}`] = originalSequence?.[`ch${channel.index}`] || { steps: [] };
            });
        }

        return processedSong;
    }

    /**
     * Main function to process serialized data for song generation.
     * @param {Array<string>} songDataUrls - Array of URLs to fetch data from.
     * @param {Array<Array<number>>} VOLUME_CONTROLS - Volume controls for each song and channel.
     * @param {Array<Array<number>>} SPEED_CONTROLS - Speed controls for each song and channel.
     */
    async function processSerializedData(songDataUrls, VOLUME_CONTROLS, SPEED_CONTROLS) {
        try {
            await loadPako();

            const deserializedData = await fetchAndProcessData(songDataUrls);

            const selectedBPM = selectBPM(window.seed);
            console.log(`[${new Date().toISOString()}] Selected Master BPM: ${selectedBPM}`);

            deserializedData.forEach((data, dataIndex) => {
                const songId = songDataUrls[dataIndex].split('/').pop(); // Extracts the file name or ID from the URL
                console.log(`[${new Date().toISOString()}] Processing data from song ${dataIndex + 1} (ID: ${songId})`);
                adjustChannelData(data, dataIndex, selectedBPM, VOLUME_CONTROLS, SPEED_CONTROLS, songId);
            });

            const processedSong = assembleProcessedSong(deserializedData, selectedBPM);

            window.jsonDataUrl = URL.createObjectURL(new Blob([JSON.stringify(processedSong)], { type: "application/json" }));
            document.dispatchEvent(new CustomEvent("dataProcessingComplete"));
            console.log(`[${new Date().toISOString()}] [debugScriptloading] Data processing complete.`);

        } catch (error) {
            console.error("Error processing data in processSerializedData:", error);
        }
    }

    console.log(`[${new Date().toISOString()}] DataProcessingCore initialized.`);

    </script>
    </dataProcessingCore>



    <defineScriptsToLoad>
        <script>
            // Embed the code from the external script here
            function startPlaybackLoop() {
                if (globalJsonData) {
                    bpm = globalJsonData.projectBPM;
                }
            }
        
            // Update the initializePlayback to directly call the embedded function
            async function initializePlayback() {
                await resumeAudioContext();
                startPlaybackLoop(); // Now directly calls the embedded function
                startWorker();
            }
        
            async function stopPlayback() {
                Object.keys(activeSources).forEach((a => {
                    activeSources[a].forEach((({ source: a, gainNode: e }) => {
                        e.gain.cancelScheduledValues(audioCtx.currentTime);
                        e.gain.setValueAtTime(e.gain.value, audioCtx.currentTime);
                        e.gain.linearRampToValueAtTime(0, audioCtx.currentTime + fadeDuration);
                        a.stop(audioCtx.currentTime + fadeDuration);
                        a.disconnect();
                        e.disconnect();
                    }));
                    activeSources[a] = [];
                }));
                setTimeout(async () => {
                    await audioCtx.suspend();
                    resetPlaybackState();
                }, 50);
            }
            </script>


    
<script>
    // Embed the playBuffer function in a dedicated script section
    function playBuffer(e, {startTrim: t, endTrim: a}, i, n) {
        t = Math.max(0, Math.min(t, 1));
        a = Math.max(t, Math.min(a, 1));
        const u = t * e.duration, 
              o = (a - t) * e.duration, 
              r = audioCtx.createBufferSource();
        
        r.buffer = e;
        const c = globalPlaybackSpeeds[i] || 1;
        r.playbackRate.value = c;
    
        const l = audioCtx.createGain(), 
              s = parseVolumeLevel(globalVolumeLevels[i] || defaultVolume) * globalVolumeMultiplier, 
              d = audioCtx.currentTime;
        
        l.gain.cancelScheduledValues(d);
        l.gain.setValueAtTime(0, d);
        l.gain.linearRampToValueAtTime(s, d + fadeDuration);
        
        r.connect(l);
        l.connect(audioCtx.destination);
        r.start(n, u, o / c);
    
        activeSources[i] || (activeSources[i] = []);
        activeSources[i].push({ source: r, gainNode: l });
    
        r.onended = () => {
            activeSources[i] = activeSources[i].filter(e => e.source !== r);
        };
    }
    
    function calculateReversedTrimTimes(e) {
        return { startTrim: 1 - e.endTrim, endTrim: 1 - e.startTrim };
    }
    
    function parseVolumeLevel(e) {
        const t = "number" == typeof e ? e : parseFloat(e);
        return clampVolume(isNaN(t) ? defaultVolume : t);
    }
    
    function clampVolume(e) {
        return Math.max(0, Math.min(e, 3));
    }
    
    async function resumeAudioContext() {
        await window.AudioContextManager.resume();
    }
    
    async function ensureAudioContextState() {
        await resumeAudioContext();
        console.log("AudioContext state:", audioCtx.state);
    }
    
    function resetPlaybackState() {
        currentSequence = 0;
        currentStep = 0;
        isReversePlay = !1;
        nextNoteTime = 0;
        resetVisualState();
    }
    
    function resetAllStates() {
        resetPlaybackState();
        resetVisualState();
    }
    
    function resetVisualState() {
        if (typeof cci2 !== 'undefined' && typeof initialCCI2 !== 'undefined') {
            cci2 = initialCCI2;
        }
        isChannel11Active = !1;
        isPlaybackActive = !1;
        activeChannelIndex = null;
        activeArrayIndex = {};
        renderingState = {};
    
        if (typeof immediateVisualUpdate === 'function') {
            immediateVisualUpdate();
        }
    }
    </script>

    <script>
const fadeDuration=.01;function notifyVisualizer(e,n){AudionalPlayerMessages.postMessage({action:"activeStep",channelIndex:e,step:n}),document.dispatchEvent(new CustomEvent("internalAudioPlayback",{detail:{action:"activeStep",channelIndex:e,step:n}}))}document.addEventListener("click",(async()=>{"function"==typeof window.ensureAudioContextState?(await window.ensureAudioContextState(),await togglePlayback(),document.dispatchEvent(new CustomEvent("playbackStarted"))):console.error("[fileAndAudioHandling.js] ensureAudioContextState is not defined or not a function")}));const defaultVolume=1;async function togglePlayback(){isToggleInProgress,isToggleInProgress=!0;try{isPlaying?(await stopPlayback(),isPlaying=!1):(await initializePlayback(),isPlaying=!0)}catch(e){console.error("Error during playback toggle:",e)}finally{isToggleInProgress=!1}}function cleanUpWorker(){clearInterval(intervalID),audioWorker?.terminate(),audioCtx.suspend().then((()=>console.log("AudioContext suspended successfully.")))}window.addEventListener("beforeunload",cleanUpWorker);
    </script>
    
    <script>
        function dispatchSequenceEvent(e,t){const n=new CustomEvent(e,{detail:t});document.dispatchEvent(n)}function playSequenceStep(e){if(!isReadyToPlay||!Object.keys(preprocessedSequences).length)return console.error("Sequence data is not ready or empty.");const t=Object.keys(preprocessedSequences);currentSequence%=t.length;const n=preprocessedSequences[t[currentSequence]];n&&Object.keys(n).length?(playSteps(n.normalSteps,e),playSteps(n.reverseSteps,e,!0),incrementStepAndSequence(t.length)):incrementStepAndSequence(t.length)}function playSteps(e,t,n=!1){if(!e||"object"!=typeof e)return console.error("[playSteps] Invalid steps data:",e);for(const[r,c]of Object.entries(e))if(Array.isArray(c)){const e=c.find((e=>e.step===currentStep));e&&playChannelStep(r,e,t,n)}else console.error(`[playSteps] Expected steps to be an array for channel "${r}", but got:`,c)}function playChannelStep(e,t,n,r){const c=globalAudioBuffers.find((t=>t.channel===e)),o=globalTrimTimes[e];if(c?.buffer&&o){const s=r?globalReversedAudioBuffers[e]:c.buffer,u=r?calculateReversedTrimTimes(o):o;playBuffer(s,u,e,n),notifyVisualizer(parseInt(e.slice(8))-1,t.step)}else console.error(`No audio buffer or trim times found for ${e}`)}function scheduleNotes(){const e=audioCtx.currentTime;for(nextNoteTime=Math.max(nextNoteTime,e);nextNoteTime<e+.1;){const e=nextNoteTime;playSequenceStep(e),audioCtx.currentTime>e&&console.warn(`[scheduleNotes] Note scheduled for ${e.toFixed(3)} missed at ${audioCtx.currentTime.toFixed(3)}.`),nextNoteTime+=getStepDuration()}}function incrementStepAndSequence(e){currentStep=(currentStep+1)%64,0===currentStep&&(currentSequence=(currentSequence+1)%e),dispatchSequenceEvent("sequenceUpdated",{currentSequence:currentSequence,currentStep:currentStep})}document.addEventListener("sequenceUpdated",(e=>{const{currentSequence:t,currentStep:n}=e.detail}));
    </script>
<script>
    
</script>

<script>
    // Embedded initializeWorker function directly in the HTML file
    function initializeWorker() {
        if (!window.Worker) {
            return console.error("Web Workers are not supported in your browser.");
        }

        const workerScript = `
            let stepDuration;
            let timerID;

            self.onmessage = ({ data }) => {
                if (data.action === 'start') {
                    stepDuration = data.stepDuration * 500; // Convert to milliseconds
                    startScheduling();
                } else if (data.action === 'stop') {
                    clearInterval(timerID);
                }
            };

            function startScheduling() {
                clearInterval(timerID);
                timerID = setInterval(() => postMessage({ action: 'scheduleNotes' }), stepDuration);
            }
        `;

        const blob = new Blob([workerScript], { type: "application/javascript" });
        const workerUrl = URL.createObjectURL(blob);
        audioWorker = new Worker(workerUrl);

        audioWorker.onmessage = ({ data }) => {
            if (data.action === 'scheduleNotes') {
                scheduleNotes();
            }
        };

        window.addEventListener("beforeunload", cleanUpWorker);
    }

    function startWorker() {
        audioWorker?.postMessage({ action: "start", stepDuration: getStepDuration() });
    }

    function stopWorker() {
        audioWorker?.postMessage({ action: "stop" });
    }

    function getStepDuration() {
        return 60 / (globalJsonData?.projectBPM || 120) / 4;
    }

    function cleanUpWorker() {
        clearInterval(intervalID);
        audioWorker?.terminate();
        audioCtx.suspend().then(() => console.log("AudioContext suspended successfully."));
    }

</script>

<script>
    // ScriptLoader.js logic refactored to remove script loading logic
    !async function() {
        const canvas = document.createElement("canvas");
        canvas.id = "cv";
        document.body.append(canvas);

        Object.assign(document.body.style, {
            display: "flex",
            justifyContent: "center",
            alignItems: "center",
            height: "100vh",
            margin: "0"
        });

        const initializeApp = () => {
            window.cci2 = 0;
            window.initialCCI2 = 0;
            resetAllStates();
            loadJsonFromUrl(window.jsonDataUrl);
            initializeWorker();  // Initialize the worker without loading from an external script
        };

        try {
            await new Promise((resolve) => {
                const checkJsonDataUrl = () => window.jsonDataUrl ? resolve() : setTimeout(checkJsonDataUrl, 100);
                checkJsonDataUrl();
            });

            console.log("Fetching from URL:", window.jsonDataUrl);
            const response = await fetch(window.jsonDataUrl);
            if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`);
            window.settings = await response.json();
            console.log("Settings loaded:", window.settings);

            await ensureAudioContextState();

            if (document.readyState === "loading") {
                document.addEventListener("DOMContentLoaded", initializeApp);
            } else {
                initializeApp();
            }
        } catch (error) {
            console.error("Error initializing the app:", error);
        }

        console.log(`[${(new Date()).toISOString()}] [debugScriptLoading] ScriptLoader initialized.`);
    }();
</script>
    </scriptLoader>
    
    

            
    </body>
    </html>