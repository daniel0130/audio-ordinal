<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Optimized Audio Player</title>
    <!-- Include Pako for GZIP decompression -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pako/1.0.11/pako.min.js" defer></script>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; }
        button { margin: 5px; padding: 10px 20px; }
        h1 { color: #333; }
        #loadingIndicator { display: none; margin-top: 10px; }
        #errorMessage { color: red; margin-top: 10px; }
    </style>
</head>
<body>

<h1>Optimized Audio Player</h1>
<button id="loadButton">Load</button>
<button id="playButton" disabled>Play</button>
<button id="stopButton" disabled>Stop</button>
<button id="skipForwardButton" disabled>Skip ></button>
<div id="loadingIndicator">Loading...</div>
<div id="errorMessage"></div>

<script>
const SONGS = [
    "https://ordinals.com/content/6d288c0c82653001bb32497889dd1486e8afec9b0671a95fa9e10f99c20737bbi0", 
    "https://ordinals.com/content/633100d631767ddb9a309f5a2a66f5a66d5abd839f3b1c55642690d484189971i0",
    "https://ordinals.com/content/5527d0cc95ce5ce6eedf4e275234da8b1fe087512d0db618b6de1aaad437c96bi0",
    "https://ordinals.com/content/07ff7bdc47e5272a3ff55cc46d2b189d510562a057a2c24112f3d0376950484di0",
    "https://ordinals.com/content/119a3ccd1dfd7e987cca139f86d16717d845a22dd6afc59ad492527b95ae9a91i0",
    "https://ordinals.com/content/db9131cfe8e933e8e639f007dcd2b582a80bfd2be42b0eafa4d2e206332d6785i0",
    "https://ordinals.com/content/fb0d2abcd1fa5bf2622579f0990435b48d41291f71626fc2e36a93e6ea6b3b85i0",
    "https://ordinals.com/content/8aec0a99a5617b9da98a5b63a11a5143f0cac3cfa662d9515c2285de03ef95d4i0"
];
let currentSongIndex = 0;  // Start at the first song in the array


document.addEventListener('DOMContentLoaded', () => {
    const keyMap = {
        "0": "projectName",
        "1": "artistName",
        "2": "projectBPM",
        "3": "currentSequence",
        "4": "channelURLs",
        "5": "channelVolume",
        "6": "channelPlaybackSpeed",
        "7": "trimSettings",
        "8": "projectChannelNames",
        "9": "startSliderValue",
        "10": "endSliderValue",
        "11": "totalSampleDuration",
        "12": "start",
        "13": "end",
        "14": "projectSequences",
        "15": "steps"
    };

    const reverseKeyMap = {};
    for (const key in keyMap) {
        reverseKeyMap[keyMap[key]] = key;
    }

    const decompressSteps = (stepData) => stepData.map(step => {
        if (typeof step === "number") {
            return { index: step, reverse: false };
        } else if (typeof step === "string" && step.endsWith("r")) {
            return { index: parseInt(step.slice(0, -1), 10), reverse: true };
        } else if (typeof step === "object" && step.r && Array.isArray(step.r)) {
            const [stepNumber, reverseFlag] = step.r;
            return { index: stepNumber, reverse: Boolean(reverseFlag) };
        } else {
            console.warn("Unknown step format:", step);
            return null;
        }
    }).filter(Boolean);

    const letterToNumber = (() => {
        const map = {};
        for (let i = 0; i < 16; i++) {
            map[String.fromCharCode(97 + i)] = i;
        }
        return (letter) => map[letter.toLowerCase()] ?? null;
    })();

    const deserialize = (data) => {
        const mappedData = {};
        for (const [key, value] of Object.entries(data)) {
            const mappedKey = keyMap[key] || key;
            if (mappedKey === "projectSequences") {
                mappedData[mappedKey] = {};
                for (const [seqKey, seqValue] of Object.entries(value)) {
                    const sequenceId = `Sequence${seqKey.replace(/^s/, "")}`;
                    mappedData[mappedKey][sequenceId] = {};
                    for (const [chanKey, chanData] of Object.entries(seqValue)) {
                        let channelNumber = parseInt(chanKey.replace(/^ch/, ""), 10);
                        if (isNaN(channelNumber)) {
                            channelNumber = letterToNumber(chanKey);
                            if (channelNumber === null) continue;
                        }
                        const channelName = `Channel ${channelNumber}`;
                        mappedData[mappedKey][sequenceId][channelName] = { steps: decompressSteps(chanData[reverseKeyMap.steps] || []) };
                    }
                }
            } else {
                mappedData[mappedKey] = value;
            }
        }
        return mappedData;
    };

    class AudioPlayer {
    constructor() {
        this.audioBuffers = []; // Array of { buffer, gainNode, channel, playbackSpeed }
        this.reversedAudioBuffers = {}; // { channelName: buffer }
        this.audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        this.isPlaying = false;
        this.currentSourceNodes = [];
        this.processedData = {};
        this.currentSequence = 0;
        this.startTime = 0;
        this.pendingTimeouts = []; // Array to keep track of active timeouts


        // Bind UI elements
        this.loadButton = document.getElementById('loadButton');
        this.playButton = document.getElementById('playButton');
        this.stopButton = document.getElementById('stopButton');
        this.skipForwardButton = document.getElementById('skipForwardButton');
        this.loadingIndicator = document.getElementById('loadingIndicator');
        this.errorMessage = document.getElementById('errorMessage');

        // Initialize event listeners
        this.initEventListeners();
    }

    initEventListeners() {
        this.loadButton.addEventListener('click', () => this.loadButtonHandler());
        this.playButton.addEventListener('click', () => this.play());
        this.stopButton.addEventListener('click', () => this.stop());
        this.skipForwardButton.addEventListener('click', () => this.skipForwardHandler());  // Update here
    }


    async loadButtonHandler() {
        this.reset();
        const url = SONGS[currentSongIndex];  // Load the current song based on index
        try {
            this.showLoading(true);
            await this.loadGzipSongFile(url);
            this.playButton.disabled = this.stopButton.disabled = this.skipForwardButton.disabled = false;
            alert("File loaded successfully!");
        } catch (e) {
            console.error("Error loading file:", e);
            this.displayError("Failed to load file. Check the console for details.");
        } finally {
            this.showLoading(false);
        }
    }

    async skipForwardHandler() {
        this.reset();  // Reset player state before loading the next song
        currentSongIndex = (currentSongIndex + 1) % SONGS.length;  // Increment song index with wrap-around
        const url = SONGS[currentSongIndex];
        try {
            this.showLoading(true);
            await this.loadGzipSongFile(url);
            this.playButton.disabled = this.stopButton.disabled = this.skipForwardButton.disabled = false;
            alert("Skipped to the next song!");
        } catch (e) {
            console.error("Error skipping to the next file:", e);
            this.displayError("Failed to skip to the next file. Check the console for details.");
        } finally {
            this.showLoading(false);
        }
    }


reset(){
    this.stop();
    this.audioBuffers = [];
    this.reversedAudioBuffers = {};
    this.currentSourceNodes.forEach(s => s.stop());
    this.currentSourceNodes = [];
    this.pendingTimeouts.forEach(t => clearTimeout(t));
    this.pendingTimeouts = [];
    this.processedData = {};
    this.currentSequence = this.startTime = 0;
    this.playButton.disabled = this.stopButton.disabled = true;
    console.log('AudioPlayer reset.');
}

showLoading(l){ this.loadingIndicator.style.display = l ? 'block' : 'none'; }

displayError(m){ this.errorMessage.textContent = m; }

async loadGzipSongFile(url) {
    const res = await fetch(url);
    if (!res.ok) throw new Error(`Network response not ok: ${res.statusText}`);
    
    const buf = pako.inflate(new Uint8Array(await res.arrayBuffer()));
    const data = deserialize(JSON.parse(new TextDecoder().decode(buf)));

    const md = {
        projectName: data.projectName,
        artistName: data.artistName,
        projectBPM: data.projectBPM,
        currentSequence: data.currentSequence,
        channelURLs: this.arrayToObject(data.channelURLs, 0, false),
        channelVolume: this.arrayToObject(data.channelVolume, 0, true),
        channelPlaybackSpeed: this.arrayToObject(data.channelPlaybackSpeed, 0, true),
        trimSettings: this.mapTrimSettings(data.trimSettings),
        projectChannelNames: data.projectChannelNames,
        projectSequences: data.projectSequences,
        globalPlaybackSpeed: data.globalPlaybackSpeed || 1,
    };

    this.processedData = {
        ...md,
        VOLUME_CONTROLS: md.channelVolume,
        SPEED_CONTROLS: md.channelPlaybackSpeed,
        songDataUrls: Object.values(md.channelURLs),
    };

    console.log(`Sequences loaded: ${Object.keys(this.processedData.projectSequences).length}`);

    if (this.processedData.songDataUrls.length === 16) {
        await this.fetchAndProcessAudioData(
            this.processedData.songDataUrls.map(u => `https://ordinals.com${u}`)
        );
    } else {
        throw new Error("Invalid channel URLs or channel count.");
    }
}


arrayToObject(a, s=0, p=false){
    return a.reduce((o,i,k)=>{o[`Channel ${s+k}`]=p?parseFloat(i)||1:i; return o},{})
}

mapTrimSettings(a){
    return a.reduce((o,i,k)=>{
        if(typeof i ==='object' && i){
            o[`Channel ${k}`] = {
                start: typeof i[9] === 'number' ? i[9] : 0,
                end: typeof i[10] === 'number' ? i[10] : 100
            };
        }
        else if(typeof i ==='number'){
            o[`Channel ${k}`] = {start:0, end:i};
        }
        else{
            o[`Channel ${k}`] = {start:0, end:100};
            console.warn(`Invalid trim for Channel ${k}.`);
        }
        return o;
    },{})
}

async fetchAndProcessAudioData(u){
    const r = await Promise.allSettled(u.map((url,i)=>this.processAudioUrl(url,i)));
    r.forEach((res,i)=>{ if(res.status==='rejected') console.error(`Failed Channel ${i} (${u[i]}):`, res.reason) });
    this.createReversedBuffers();
}

async processAudioUrl(u,i){
    const cn=`Channel ${i}`;
    try{
        const res = await fetch(u);
        if(!res.ok) throw new Error(`Fetch failed: ${u}, Status: ${res.status}`);
        const ct = res.headers.get("Content-Type");
        let ab;
        if(/audio\/(wav|mpeg|mp4)|video\/mp4/.test(ct)){
            ab = await this.fetchAndDecodeAudio(res, cn);
        }
        else if(/application\/json/.test(ct)){
            ab = await this.handleJsonResponse(res, cn);
        }
        else if(/text\/html/.test(ct)){
            ab = await this.handleHtmlResponse(res, cn);
        }
        else{
            throw new Error(`Unsupported type for ${cn}: ${ct}`);
        }
        if(ab){
            console.log(`AudioBuffer for ${cn}:`, {
                channels: ab.numberOfChannels,
                length: ab.length,
                sampleRate: ab.sampleRate,
                duration: ab.duration
            });
            for(let c=0; c < ab.numberOfChannels; c++) {
                console.log(`Channel ${c} data:`, ab.getChannelData(c).slice(0,10));
            }
            const vol = this.parseVolumeLevel(this.processedData.VOLUME_CONTROLS[cn]);
            const speed = this.processedData.SPEED_CONTROLS[cn] || 1;
            const trim = this.processedData.trimSettings[cn] || {start:0, end:100};
            const tb = this.applyTrim(ab, trim.start, trim.end);
            const gn = this.audioCtx.createGain();
            gn.gain.value = vol;
            gn.connect(this.audioCtx.destination);
            this.audioBuffers.push({buffer: tb, gainNode: gn, channel: cn, playbackSpeed: speed});
        }
    }
    catch(e){
        console.error(`Error processing ${cn}:`, e);
    }
}

async fetchAndDecodeAudio(res, cn){
    try{
        const ab = await this.audioCtx.decodeAudioData(await res.arrayBuffer());
        console.log(`Decoded ${cn}.`);
        return ab;
    }
    catch(e){
        console.error(`decodeAudioData failed for ${cn}:`, e);
        throw new Error(`Failed to decode audio for ${cn}.`);
    }
}





    async handleJsonResponse(response, channelName) {
        try {
            const jsonData = await response.json();
            if (jsonData.audioData) {
                const arrayBuffer = this.base64ToArrayBuffer(jsonData.audioData.split(",")[1]);
                try {
                    const audioBuffer = await this.audioCtx.decodeAudioData(arrayBuffer);
                    return audioBuffer;
                } catch (error) {
                    console.error(`decodeAudioData failed for JSON audio data in ${channelName}:`, error);
                    throw new Error(`Failed to decode JSON audio data for ${channelName}.`);
                }
            }
            throw new Error(`Invalid JSON structure for audio data in ${channelName}.`);
        } catch (error) {
            console.error(`Error handling JSON response for ${channelName}:`, error);
            throw error;
        }
    }


    async handleHtmlResponse(response, channelName) {
        try {
            const text = await response.text();
            const base64Audio = this.extractBase64FromHTML(text);
            if (base64Audio) {
                const arrayBuffer = this.base64ToArrayBuffer(base64Audio.split(",")[1]);
                try {
                    const audioBuffer = await this.audioCtx.decodeAudioData(arrayBuffer);
                    return audioBuffer;
                } catch (error) {
                    console.error(`decodeAudioData failed for HTML audio data in ${channelName}:`, error);
                    throw new Error(`Failed to decode HTML audio data for ${channelName}.`);
                }
            }
            throw new Error(`No valid audio data found in HTML for ${channelName}.`);
        } catch (error) {
            console.error(`Error handling HTML response for ${channelName}:`, error);
            throw error;
        }
    }

    base64ToArrayBuffer(base64) {
        try {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        } catch (error) {
            console.error("[base64ToArrayBuffer] Conversion error:", error);
            return null;
        }
    }

    extractBase64FromHTML(htmlContent) {
        try {
            const parser = new DOMParser();
            const doc = parser.parseFromString(htmlContent, "text/html");
            const audioSource = doc.querySelector("audio[data-audionalSampleName] source")?.getAttribute("src");
            if (/^data:audio\/(wav|mp3|mp4);base64,/.test(audioSource?.toLowerCase()) || /audio\//.test(audioSource?.toLowerCase())) {
                return audioSource;
            }
            console.error("[extractBase64FromHTML] Invalid audio source format.");
        } catch (error) {
            console.error("[extractBase64FromHTML] Parsing error:", error);
        }
        return null;
    }

    parseVolumeLevel(volume) {
        const parsed = parseFloat(volume);
        return isNaN(parsed) || parsed < 0 ? 1 : Math.min(parsed, 1);
    }

    applyTrim(buffer, startPercent, endPercent) {
        const totalSamples = buffer.length;
        const startSample = Math.floor(totalSamples * (startPercent / 100));
        const endSample = Math.floor(totalSamples * (endPercent / 100));

        if (startSample >= endSample || startSample < 0 || endSample > totalSamples) {
            console.warn(`Invalid trim settings: Start = ${startPercent}%, End = ${endPercent}%. Using full buffer.`);
            return buffer;
        }

        const trimmedBuffer = this.audioCtx.createBuffer(buffer.numberOfChannels, endSample - startSample, buffer.sampleRate);
        for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
            const channelData = buffer.getChannelData(channel).subarray(startSample, endSample);
            trimmedBuffer.copyToChannel(channelData, channel, 0);
        }
        return trimmedBuffer;
    }

    createReversedBuffers() {
        const channelsWithReverse = new Set();
        const { projectSequences } = this.processedData;

        console.debug("Starting createReversedBuffers");
        
        Object.values(projectSequences).forEach((sequence, seqIndex) => {
            console.debug(`Processing sequence ${seqIndex + 1}/${Object.values(projectSequences).length}`);
            
            Object.entries(sequence).forEach(([channelName, channelData]) => {
                channelData.steps.forEach((step, stepIndex) => {
                    if (step.reverse) {
                        channelsWithReverse.add(channelName);
                        console.debug(`  Step ${stepIndex + 1}: Reverse flag set for channel '${channelName}'`);
                    }
                });
            });
        });

        console.debug("Channels requiring reversal:", Array.from(channelsWithReverse));

        this.audioBuffers.forEach(({ buffer, channel }) => {
            if (channelsWithReverse.has(channel) && !this.reversedAudioBuffers[channel]) {
                console.debug(`Reversing buffer for channel: ${channel}`);
                this.reversedAudioBuffers[channel] = this.reverseBuffer(buffer);
            } else {
                if (channelsWithReverse.has(channel)) {
                    console.debug(`Buffer for channel ${channel} already reversed.`);
                }
            }
        });

        console.debug("Completed createReversedBuffers");
    }

    reverseBuffer(buffer) {
        console.debug("Starting reverseBuffer");
        const reversedBuffer = this.audioCtx.createBuffer(buffer.numberOfChannels, buffer.length, buffer.sampleRate);

        for (let channel = 0; channel < buffer.numberOfChannels; channel++) {
            const channelData = buffer.getChannelData(channel);
            const reversedData = reversedBuffer.getChannelData(channel);
            console.debug(`  Reversing data for channel ${channel + 1}/${buffer.numberOfChannels}`);
            
            for (let i = 0, len = buffer.length; i < len; i++) {
                reversedData[i] = channelData[len - i - 1];
            }
        }

        console.debug("Completed reverseBuffer");
        return reversedBuffer;
    }

    // Playback methods
    play() {
        if (this.isPlaying) return;
        this.isPlaying = true;
        this.startTime = this.audioCtx.currentTime;
        console.log(`Playback started at ${this.startTime.toFixed(3)} seconds`);
        this.scheduleSequences();
    }

    scheduleSequences() {
        const log = [];
        console.debug("Scheduling sequences...");
        Object.keys(this.processedData.projectSequences).forEach((id, i) => 
            this.scheduleSequence(id, this.calculateSequenceStartTime(i), log)
        );
        console.log('Scheduled Sequences:', log);
    }

    calculateSequenceStartTime(i) {
        const { projectBPM, globalPlaybackSpeed } = this.processedData;
        const stepDuration = 60 / projectBPM / 4;
        const startTime = this.startTime + (i * this.getStepsPerSequence() * stepDuration) / globalPlaybackSpeed;
        console.debug(`Start time for sequence ${i + 1}: ${startTime.toFixed(3)}s`);
        return startTime;
    }

    scheduleSequence(id, startTime, log) {
        const sequence = this.processedData.projectSequences[id];
        if (!sequence) { 
            console.error(`No data for ${id}.`); 
            return; 
        }

        const { projectBPM, globalPlaybackSpeed } = this.processedData;
        const stepDuration = 60 / projectBPM / 4;

        log.push({ id, startTime: startTime.toFixed(3) });
        console.debug(`Scheduled ${id} at ${startTime.toFixed(3)}s`);

        Object.entries(sequence).forEach(([channel, data]) => {
            const buf = this.audioBuffers.find(b => b.channel === channel);
            if (!buf) { 
                console.warn(`No buffer for ${channel}.`); 
                return; 
            }

            data.steps.forEach(({ index, reverse }) => {
                const when = startTime + ((index - 1) * stepDuration) / globalPlaybackSpeed;
                const source = this.audioCtx.createBufferSource();
                source.buffer = reverse && this.reversedAudioBuffers[channel] ? this.reversedAudioBuffers[channel] : buf.buffer;
                console.debug(`Using ${reverse && this.reversedAudioBuffers[channel] ? 'reversed' : 'original'} buffer for ${channel}`);
                source.playbackRate.value = buf.playbackSpeed * globalPlaybackSpeed;
                source.connect(buf.gainNode);
                source.start(when);
                this.currentSourceNodes.push(source);
            });
        });

        const delay = Math.max((startTime - this.audioCtx.currentTime) * 1000, 0);
        if (delay < Number.MAX_SAFE_INTEGER) {
            const tid = setTimeout(() => {
                if (this.isPlaying) console.log(`Now playing ${id}`);
                this.pendingTimeouts = this.pendingTimeouts.filter(t => t !== tid);
            }, delay);
            this.pendingTimeouts.push(tid);
        } else {
            console.warn(`Delay for ${id} too long. Skipping log.`);
        }
    }

    getStepsPerSequence() { 
        return 64; 
    }

    stop() {
        if (!this.isPlaying) return;
        this.currentSourceNodes.forEach(s => s.stop());
        this.currentSourceNodes = [];
        this.isPlaying = false;
        console.log('Playback stopped.');
        this.pendingTimeouts.forEach(clearTimeout);
        this.pendingTimeouts = [];
    }

    async extractAudioFromVideo(response, url, channel) {
        try {
            console.log(`Starting audio extraction for ${channel} from ${url}`);
            const videoBlob = await response.blob();
            console.log(`Fetched video Blob for ${channel}:`, videoBlob);
            const videoURL = URL.createObjectURL(videoBlob);
            const video = Object.assign(document.createElement('video'), {
                src: videoURL,
                crossOrigin: "anonymous",
                muted: true,
                style: 'display:none'
            });
            document.body.appendChild(video);

            await new Promise((res, rej) => {
                video.onloadedmetadata = () => {
                    console.log(`Metadata loaded for ${channel}: ${video.duration}s`);
                    res();
                };
                video.onerror = () => rej(new Error(`Error loading metadata for ${channel}.`));
            });

            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioCtx.createMediaElementSource(video);
            const scriptNode = audioCtx.createScriptProcessor(4096, 2, 2);
            const buffer = { left: [], right: [] };

            scriptNode.onaudioprocess = e => {
                buffer.left.push(new Float32Array(e.inputBuffer.getChannelData(0)));
                buffer.right.push(new Float32Array(e.inputBuffer.getChannelData(1)));
            };

            source.connect(scriptNode);
            scriptNode.connect(audioCtx.destination);

            await video.play().catch(err => { 
                throw new Error(`Error playing video: ${err.message}`); 
            });
            console.log(`Starting audio capture for ${channel}...`);

            return await new Promise((res, rej) => {
                video.onended = () => {
                    console.log(`Video ended for ${channel}. Processing audio...`);
                    scriptNode.disconnect();
                    source.disconnect();
                    audioCtx.close();

                    const left = this.concatenateFloat32Arrays(buffer.left);
                    const right = this.concatenateFloat32Arrays(buffer.right);
                    const offlineCtx = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(2, left.length, audioCtx.sampleRate);
                    const rendered = offlineCtx.createBuffer(2, left.length, audioCtx.sampleRate);
                    rendered.copyToChannel(left, 0);
                    rendered.copyToChannel(right, 1);
                    console.log(`Audio processed for ${channel}.`);
                    res(rendered);

                    URL.revokeObjectURL(videoURL);
                    document.body.removeChild(video);
                };
                video.onerror = e => {
                    console.error(`Playback error for ${channel}:`, e);
                    rej(new Error(`Playback error for ${channel}.`));
                };
            });
        } catch (error) {
            console.error(`Error extracting audio for ${channel}:`, error);
            throw new Error(`Failed to extract audio for ${channel}.`);
        }
    }

    concatenateFloat32Arrays(arrays) {
        const len = arrays.reduce((s, a) => s + a.length, 0);
        const res = new Float32Array(len);
        let off = 0;
        arrays.forEach(a => { res.set(a, off); off += a.length; });
        return res;
    }
}
// Initialize the AudioPlayer instance
new AudioPlayer();

});
</script>

</body>
</html>